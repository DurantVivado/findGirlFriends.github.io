

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=&quot;auto&quot;>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/favicon.png">
  <link rel="icon" type="image/png" href="/img/favicon.png">
  <meta name="viewport"
        content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="description" content="博主：来自华中科技大学国家光电研究中心的">
  <meta name="author" content="Durant">
  <meta name="keywords" content="">
  <title>视频压缩算法设计 - Durant Thorvalds 的米奇妙妙屋</title>

  <link  rel="stylesheet" href="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/css/bootstrap.min.css" />


  <link  rel="stylesheet" href="https://cdn.staticfile.org/github-markdown-css/4.0.0/github-markdown.min.css" />
  <link  rel="stylesheet" href="/lib/hint/hint.min.css" />

  
    
    
      
      <link  rel="stylesheet" href="https://cdn.staticfile.org/highlight.js/10.0.0/styles/github-gist.min.css" />
    
  

  
    <link  rel="stylesheet" href="https://cdn.staticfile.org/gitalk/1.6.2/gitalk.css" />
  


<!-- 主题依赖的图标库，不要自行修改 -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_pf9vaxs7x7b.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_kmeydafke9r.css">


<link  rel="stylesheet" href="/css/main.css" />

<!-- 自定义样式保持在最底部 -->


  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
<meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Durant Thorvalds 的米奇妙妙屋" type="application/atom+xml">
</head>


<body>
  <header style="height: 70vh;">
    <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand"
       href="/">&nbsp;<strong>Fluid</strong>&nbsp;</a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                联系我
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" data-toggle="modal" data-target="#modalSearch">&nbsp;<i
                class="iconfont icon-search"></i>&nbsp;</a>
          </li>
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" href="javascript:">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

    <div class="banner intro-2" id="background" parallax=true
         style="background: url('/img/default.png') no-repeat center center;
           background-size: cover;">
      <div class="full-bg-img">
        <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
          <div class="container page-header text-center fade-in-up">
            <span class="h2" id="subtitle">
              
            </span>

            
              <div class="mt-3">
  
  
    <span class="post-meta">
      <i class="iconfont icon-date-fill" aria-hidden="true"></i>
      <time datetime="2020-12-23 00:00" pubdate>
        2020年12月23日 凌晨
      </time>
    </span>
  
</div>

<div class="mt-1">
  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-chart"></i>
      4.9k 字
    </span>
  

  
    
    <span class="post-meta mr-2">
      <i class="iconfont icon-clock-fill"></i>
      
      
      54
       分钟
    </span>
  

  
  
    
      <!-- 不蒜子统计文章PV -->
      <span id="busuanzi_container_page_pv" style="display: none">
        <i class="iconfont icon-eye" aria-hidden="true"></i>
        <span id="busuanzi_value_page_pv"></span> 次
      </span>
    
  
</div>

            
          </div>

          
        </div>
      </div>
    </div>
  </header>

  <main>
    
      

<div class="container-fluid">
  <div class="row">
    <div class="d-none d-lg-block col-lg-2"></div>
    <div class="col-lg-8 nopadding-md">
      <div class="container nopadding-md" id="board-ctn">
        <div class="py-5" id="board">
          <article class="post-content mx-auto" id="post">
            <!-- SEO header -->
            <h1 style="display: none">视频压缩算法设计</h1>
            
            <div class="markdown-body" id="post-body">
              <h1 id="视频压缩算法设计"><a href="#视频压缩算法设计" class="headerlink" title="视频压缩算法设计"></a>视频压缩算法设计</h1><h2 id="一-课题背景："><a href="#一-课题背景：" class="headerlink" title="一. 课题背景："></a>一. 课题背景：</h2><p>本实验是设计并实现一种视频的压缩算法，包括颜色特征提取，图像分块，预测编码，统计编码等</p>
<h2 id="二-实验要求"><a href="#二-实验要求" class="headerlink" title="二. 实验要求"></a>二. 实验要求</h2><p>视频数据采用 “test.mp4” 视频，设计压缩和解压两个模块。</p>
<h2 id="三-实验评估"><a href="#三-实验评估" class="headerlink" title="三. 实验评估"></a>三. 实验评估</h2><p>本实验采用（编码后的视频和原始视频的）压缩比和（解码后的视频和原始视频的）信噪比来评价压缩效果</p>
<h2 id="四-视频压缩代码示例："><a href="#四-视频压缩代码示例：" class="headerlink" title="四. 视频压缩代码示例："></a>四. 视频压缩代码示例：</h2><pre><code class="hljs plain"></code></pre>
<hr>
<h2 id="S1-理论基础"><a href="#S1-理论基础" class="headerlink" title="$\S1$ 理论基础"></a>$\S1$ 理论基础</h2><p>研究发现，多媒体数据中存在大量的冗余数据，比如空间冗余，时间冗余以及结构冗余和知识冗余等等。</p>
<p>例如高清视频 1.5Gbps，4K视频 12Gbps，压缩为MPEG-2 后采样率分别为20Mbps和160Mbps，相当于压缩75倍，压缩到HEVC/265或者AVS2、VP9为5Mbps和40Mbps，相当于压缩300倍。如下面图表所示：</p>
<p><img src="视频压缩算法设计/image-20201221151830695.png" srcset="/img/loading.gif" alt="image-20201221151830695" style="zoom: 67%;" /></p>
<p>按照信息是否有损可以分为无损压缩和有损压缩。而编码方法有三种：</p>
<ul>
<li>熵编码：不考虑数据源的无损压缩技术；</li>
<li>源编码：考虑数据源的无损压缩技术。</li>
<li>混合编码：组合熵编码与源编码。</li>
</ul>
<p>根据是否自适应又分为自适应编码和非自适应编码。</p>
<p><img src="视频压缩算法设计/image-20201221152527369.png" srcset="/img/loading.gif" alt="image-20201221152527369" style="zoom:80%;" /></p>
<p>PCM：脉冲编码调制。</p>
<p>统计编码的理论基础是信息论，理论依据是<strong>变字长编码理论</strong>。</p>
<p>编码器的编码输出码字是字长不等的码字：</p>
<ul>
<li>按照编码输入信息符号出现的概率，给输出码字以不同的字长：<ul>
<li>大概率赋予小字长</li>
<li>小概率赋予大字长</li>
</ul>
</li>
</ul>
<p>信息熵$I_i=-\log p_i $，$p_i$表示第i个事件的概率。根据香农信息论，信源的熵定义为：$H(S)=\eta=\sum_i p_i\log(1/p_i) = \sum_i p_i I_i$</p>
<p>其中$H(S)$表示编码的最小长度，$p_i$是符号$s_i$在S中出现的概率，$I_i$表示包含在$s_i$中的信息量也就是编码所需的位数。</p>
<h3 id="香农-范诺-Shannon-Fano-编码"><a href="#香农-范诺-Shannon-Fano-编码" class="headerlink" title="香农-范诺(Shannon-Fano)编码"></a>香农-范诺(Shannon-Fano)编码</h3><ul>
<li><p>采用从上到下的方法进行编码</p>
</li>
<li><p>使用递归的方法分为两个部分，每个部分具有近似相等的概率</p>
</li>
</ul>
<p>下面举例子来分析，假设某灰度图像有40个像素，灰度等级为5，分别用A，B，C，D，E来表示：</p>
<p><img src="视频压缩算法设计/image-20201221162704365.png" srcset="/img/loading.gif" alt="image-20201221162704365" style="zoom:80%;" /></p>
<p>构建范诺树</p>
<p><img src="视频压缩算法设计/image-20201221162822702.png" srcset="/img/loading.gif" alt="image-20201221162822702" style="zoom:67%;" /></p>
<p><img src="视频压缩算法设计/image-20201221162836224.png" srcset="/img/loading.gif" alt="image-20201221162836224" style="zoom:67%;" /></p>
<p><img src="视频压缩算法设计/image-20201221162847644.png" srcset="/img/loading.gif" alt="image-20201221162847644" style="zoom:67%;" /></p>
<p><img src="视频压缩算法设计/image-20201221162857345.png" srcset="/img/loading.gif" alt="image-20201221162857345" style="zoom:67%;" /></p>
<h3 id="哈夫曼Huffman编码"><a href="#哈夫曼Huffman编码" class="headerlink" title="哈夫曼Huffman编码"></a>哈夫曼Huffman编码</h3><p>迄今为止，这是最著名也是最高效的熵编码方法。</p>
<p>算法思想是按照概率的大小进行排序，对输出码分配不同码字长度的变字长编码方法；输出码字的平均长度最短，与信息熵值接近，编码方法最佳。</p>
<p>但是哈夫曼编码没有错误保护功能，同时想进行查询某个数据也很困难。</p>
<h3 id="算术编码"><a href="#算术编码" class="headerlink" title="算术编码"></a>算术编码</h3><p>这是JPEG图像用到的经典算法。消息用0到1之间的实数进行编码，依据两个基本参数：<strong>符号概率</strong>和<strong>编码间隔</strong>。</p>
<p><img src="视频压缩算法设计/image-20201221164145724.png" srcset="/img/loading.gif" alt="image-20201221164145724" style="zoom:67%;" /></p>
<p>算术译码对错误敏感！</p>
<h3 id="行程编码（RLE）"><a href="#行程编码（RLE）" class="headerlink" title="行程编码（RLE）"></a>行程编码（RLE）</h3><p><img src="视频压缩算法设计/image-20201221164618685.png" srcset="/img/loading.gif" alt="image-20201221164618685" style="zoom:50%;" /></p>
<h3 id="词典编码"><a href="#词典编码" class="headerlink" title="词典编码"></a>词典编码</h3><p>第一类词典编码：查找正在压缩的字符序列是否在以前输入的数据中出现过。</p>
<p>第二类词典法：用一个词典记录出现过的字符，编码数据过程中当遇到以前出现的“短语时”，编码器就输出这个词典    中短语的索引号。</p>
<h3 id="变换编码"><a href="#变换编码" class="headerlink" title="变换编码"></a>变换编码</h3><p>其理论核心是信号理论中的离散信号傅里叶变换。</p>
<h3 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="- 傅里叶变换"></a>- 傅里叶变换</h3><p>具体可以参见 奥本海默《信号与系统》这里不细讲。</p>
<p>比较有用的是<strong>离散余弦-DCT变换</strong>，离散余弦变换具有很强的“能量集中特性”，i.e.：</p>
<ul>
<li>大部分自然信号的能量集中在离散余弦变换的低频部分；</li>
<li>高频部分描述信号的细节。</li>
</ul>
<p>离散余弦变换在数字图像压缩中可与最佳变换K-L变换媲美。因而应用广泛：JPEG、MPEG、H.26x。</p>
<p>二维的DCT公式是对每个单独的彩色图像分量，把整个分量图像空间分成一个8x8的图像块，并作为二维离散余弦变换DCT的输入；</p>
<p>变换公式为：</p>
<script type="math/tex; mode=display">
F(u,v)=\frac{1}{4}C(u)C(v)(\sum\limits_{i=0}^{7}\sum\limits_{i=0}^{7}f(i,j)cos\frac{(2i+1)u\pi}{16}cos\frac{(2j+1)v\pi}{16})\\
f(i,j)=\frac{1}{4}C(u)C(v)(\sum\limits_{u=0}^{7}\sum\limits_{v=0}^{7}F(u,v)cos\frac{(2i+1)u\pi}{16}cos\frac{(2j+1)v\pi}{16})\\

where, C(u)=C(v)=\begin{cases}
1/\sqrt{2},&if \ u,v = 0\\
1, &otherwise
\end{cases}</script><p><img src="视频压缩算法设计/image-20201222142033770.png" srcset="/img/loading.gif" alt="image-20201222142033770" style="zoom:67%;" /></p>
<p>理论上最理想的变换应该使得信号在变换域中的样本相互统计独立。</p>
<h2 id="S2-图像编码标准JPEG"><a href="#S2-图像编码标准JPEG" class="headerlink" title="$\S2$ 图像编码标准JPEG"></a>$\S2$ 图像编码标准JPEG</h2><p>全称是Joint Photographic Experts Group, 是连续色调、多级灰度、静止图像的数字图像压缩编码标准。也是目前应用极为广泛的通用标准，其压缩方法主要有两种：</p>
<ul>
<li>以DCT为基础的有损压缩算法</li>
<li>以预测技术为基础的无损压缩算法</li>
</ul>
<p>它利用人的视觉特性使用量化和无损压缩来去掉视觉的冗余信息以及数据本身的冗余信息。</p>
<h3 id="编码步骤"><a href="#编码步骤" class="headerlink" title="编码步骤"></a>编码步骤</h3><p><img src="视频压缩算法设计/image-20201222142813006.png" srcset="/img/loading.gif" alt="image-20201222142813006" style="zoom:67%;" /></p>
<ol>
<li>使用正向离散余弦函数（FDCT）把图像（8x8大小）从空间域变到频域；</li>
<li><p>使用加权函数对DCT系数$F(u,v)$进行量化（这个加权函数对于人的视觉特性是最佳的）；</p>
</li>
<li><p>Z字形编码，量化后的DCT系数需要重新编排，目的是为了增加连续“0”的个数，把8x8矩阵变成一个1x64矢量，频率低的系数放在矢量顶部；</p>
</li>
</ol>
<p><img src="视频压缩算法设计/image-20201222144019683.png" srcset="/img/loading.gif" alt="image-20201222144019683" style="zoom:67%;" /></p>
<ol>
<li><p>使用差分脉冲编码调制（DPCM）对直流系数（DC）进行编码，DC系数有两个特点：一是系数的数值比较大，二是相邻图像块的数值变化不大，因而使用DPCM对相邻图像块DC系数的差值进行编码；</p>
</li>
<li><p>使用行程编码（RLE）对交流系数（AC）进行编码，因为量化后AC系数特点是1*63矢量中含有许多数字“0”，并且许多“0”是连续的；</p>
</li>
</ol>
<p>JPEG使用了一个字节的高四位来表示连续“0”的个数，而使用它的第四位来表示下个非“0”系数所需要的位数，跟在它后面的是量化AC系数的数值；</p>
<p><img src="视频压缩算法设计/image-20201222144557187.png" srcset="/img/loading.gif" alt="image-20201222144557187" style="zoom: 50%;" /></p>
<ol>
<li>熵编码：使用哈夫曼编码器对量化系数进行编码；</li>
<li>组成位数据流（JPEG bitstream），把各种标记代码和编码后的图像数据组成一帧帧数据。</li>
</ol>
<p>译码和解压缩过程则刚好相反。其中量化处理是导致信息损失的根源。</p>
<hr>
<h2 id="图像相似度衡量"><a href="#图像相似度衡量" class="headerlink" title="图像相似度衡量"></a>图像相似度衡量</h2><blockquote>
<p>图像PSNR和SSIM</p>
<h2 id="PSNR-Peak-Signal-to-Noise-Ratio"><a href="#PSNR-Peak-Signal-to-Noise-Ratio" class="headerlink" title="PSNR (Peak Signal to Noise Ratio)"></a><strong>PSNR (Peak Signal to Noise Ratio)</strong></h2><p>峰值信噪比PSNR衡量图像失真或是噪声水平的客观标准。2个图像之间PSNR值越大，则越相似。普遍基准为30dB，30dB以下的图像劣化较为明显。定义为，</p>
<script type="math/tex; mode=display">
PSNR=10log_{10}（\frac{MAX^{2}}{MSE}）</script><p>代码实现</p>
<pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_psnr</span>(<span class="hljs-params">self, target, ref</span>):</span>
    <span class="hljs-keyword">import</span>  math
    <span class="hljs-comment"># 将图像格式转为float64</span>
    target_data = np.array(target, dtype=np.float64)
    ref_data = np.array(ref, dtype=np.float64)
    <span class="hljs-comment"># 直接相减，求差值</span>
    diff = ref_data - target_data
    <span class="hljs-comment"># 按第三个通道顺序把三维矩阵拉平</span>
    diff = diff.flatten(<span class="hljs-string">&#x27;C&#x27;</span>)
    <span class="hljs-comment"># 计算MSE值</span>
    rmse = math.sqrt(np.mean(diff ** <span class="hljs-number">2.</span>))
    <span class="hljs-comment"># 精度</span>
    eps = np.finfo(np.float64).eps
    <span class="hljs-keyword">if</span> (rmse == <span class="hljs-number">0</span>):
        rmse = eps
    <span class="hljs-keyword">return</span> <span class="hljs-number">20</span> * math.log10(<span class="hljs-number">255.0</span> / rmse)</code></pre>
<h2 id="SSIM-Structural-SIMilarity-结构相似性"><a href="#SSIM-Structural-SIMilarity-结构相似性" class="headerlink" title="SSIM (Structural SIMilarity) 结构相似性"></a>SSIM (Structural SIMilarity) 结构相似性</h2><p>SSIM公式基于样本x和y之间的三个比较衡量：亮度 (luminance)、对比度 (contrast) 和结构 (structure)。</p>
<p><img src="https://www.zhihu.com/equation?tex=l%28x%2Cy%29+%3D+%5Cfrac%7B2%5Cmu_x+%5Cmu_y+%2B+c_1%7D%7B%5Cmu_x%5E2%2B+%5Cmu_y%5E2+%2B+c_1%7D" srcset="/img/loading.gif" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=c%28x%2Cy%29+%3D+%5Cfrac%7B2%5Csigma_x+%5Csigma_y+%2B+c_2%7D%7B%5Csigma_x%5E2%2B+%5Csigma_y%5E2+%2B+c_2%7D" srcset="/img/loading.gif" alt="[公式]"><img src="https://www.zhihu.com/equation?tex=s%28x%2Cy%29+%3D+%5Cfrac%7B%5Csigma_%7Bxy%7D+%2B+c_3%7D%7B%5Csigma_x+%5Csigma_y+%2B+c_3%7D" srcset="/img/loading.gif" alt="[公式]"></p>
<p>一般取<img src="https://www.zhihu.com/equation?tex=c_3+%3D+c_2+%2F+2" srcset="/img/loading.gif" alt="[公式]">。</p>
<ul>
<li><img src="https://www.zhihu.com/equation?tex=%5Cmu_x" srcset="/img/loading.gif" alt="[公式]">为<img src="https://www.zhihu.com/equation?tex=x" srcset="/img/loading.gif" alt="[公式]">的均值</li>
<li><img src="https://www.zhihu.com/equation?tex=%5Cmu_y" srcset="/img/loading.gif" alt="[公式]">为<img src="https://www.zhihu.com/equation?tex=y" srcset="/img/loading.gif" alt="[公式]">的均值</li>
<li><img src="https://www.zhihu.com/equation?tex=%5Csigma_x%5E2" srcset="/img/loading.gif" alt="[公式]">为<img src="https://www.zhihu.com/equation?tex=x" srcset="/img/loading.gif" alt="[公式]">的方差</li>
<li><img src="https://www.zhihu.com/equation?tex=%5Csigma_y%5E2" srcset="/img/loading.gif" alt="[公式]">为<img src="https://www.zhihu.com/equation?tex=y" srcset="/img/loading.gif" alt="[公式]">的方差</li>
<li><img src="https://www.zhihu.com/equation?tex=%5Csigma_%7Bxy%7D" srcset="/img/loading.gif" alt="[公式]">为<img src="https://www.zhihu.com/equation?tex=x" srcset="/img/loading.gif" alt="[公式]">和<img src="https://www.zhihu.com/equation?tex=y" srcset="/img/loading.gif" alt="[公式]">的协方差</li>
<li><img src="https://www.zhihu.com/equation?tex=c_1+%3D+%28k_1L%29%5E2%2C+c_2+%3D+%28k_2L%29%5E2" srcset="/img/loading.gif" alt="[公式]">为两个常数，避免除零</li>
<li><img src="https://www.zhihu.com/equation?tex=L" srcset="/img/loading.gif" alt="[公式]">为像素值的范围，<img src="https://www.zhihu.com/equation?tex=2%5EB-1" srcset="/img/loading.gif" alt="[公式]"></li>
<li><img src="https://www.zhihu.com/equation?tex=k_1%3D0.01%2C+k_2%3D0.03" srcset="/img/loading.gif" alt="[公式]">为默认值</li>
</ul>
<p>那么</p>
<p><img src="https://www.zhihu.com/equation?tex=SSIM%28x%2C+y%29+%3D+%5Bl%28x%2Cy%29%5E%7B%5Calpha%7D+%5Ccdot+c%28x%2Cy%29%5E%7B%5Cbeta%7D+%5Ccdot+s%28x%2Cy%29%5E%7B%5Cgamma%7D%5D" srcset="/img/loading.gif" alt="[公式]"></p>
<p>将<img src="https://www.zhihu.com/equation?tex=%5Calpha%2C%5Cbeta%2C%5Cgamma" srcset="/img/loading.gif" alt="[公式]">设为 1，可以得到</p>
<p><img src="https://www.zhihu.com/equation?tex=SSIM%28x%2C+y%29+%3D+%5Cfrac%7B%282%5Cmu_x+%5Cmu_y+%2B+c_1%29%282%5Csigma_%7Bxy%7D%2Bc_2%29%7D%7B%28%5Cmu_x%5E2%2B+%5Cmu_y%5E2+%2B+c_1%29%28%5Csigma_x%5E2%2B%5Csigma_y%5E2%2Bc_2%29%7D" srcset="/img/loading.gif" alt="[公式]"></p>
<p>每次计算的时候都从图片上取一个<img src="https://www.zhihu.com/equation?tex=N%C3%97N" srcset="/img/loading.gif" alt="[公式]">的窗口，然后不断滑动窗口进行计算，最后取平均值作为全局的 SSIM。</p>
<pre><code class="hljs python"><span class="hljs-comment"># im1 和 im2 都为灰度图像，uint8 类型</span>
ssim = skimage.measure.compare_ssim(im1, im2, data_range=<span class="hljs-number">255</span>)</code></pre>
</blockquote>
<h2 id="量化"><a href="#量化" class="headerlink" title="量化"></a>量化</h2><p><a target="_blank" rel="noopener" href="https://www.impulseadventure.com/photo/jpeg-quantization.html">https://www.impulseadventure.com/photo/jpeg-quantization.html</a></p>
<p><img src="https://www.impulseadventure.com/photo/images/quant_matrix.gif" srcset="/img/loading.gif" alt="img"></p>
<p>所谓量化就是将DCT变换的临时结果，除以各自量化步长并四舍五入后得到结果，得到量化系数。</p>
<p>因为经过DCT后，数据就不同了，左上方都是大数值，右下方都是小数值。比如左上方都是几十几百的，右下方附近，都是个位数，那么，大数值和小数值就可以分别量化。</p>
<p>在术语里，左上方称为<strong>低频数据</strong>，右下方称为<strong>高频数据</strong>。 </p>
<p>JPEG系统分别规定了亮度分量和色度分量的量化表，色度分量相应的量化步长比亮度分量大。</p>
<p><strong>对量化系数的处理和组织</strong><br>思想：JPEG采用定长和变长相结合的编码方法。<br><strong>直流系数：</strong>通常相邻8*8图象块的DC分量很接近，因此JPEG对量化后的直流分量采用无失真DPCM编码。通常JPEG要保存所需比特数和实际差值。</p>
<p><strong>交流系数：</strong>经过量化后，AC分量出现较多的0。JPEG采用对0系数的行程长度编码。而对非0值，则要保存所需数和实际值。<br>ZIG-ZAG排序：为使连续的0个数增多，采用Z形编码。 </p>
<h2 id="交流直流编码"><a href="#交流直流编码" class="headerlink" title="交流直流编码"></a>交流直流编码</h2><p>JPEG 压缩的最后一步是对量化后的系数进行熵编码。这一步采用通用的无损数据压缩技术，对图像质量没有影响。在熵编码前，对63个交流系数先采用ZigZag排序，转变为一维向量。这样做的目的是为了将低频系数放在前面，高频系数放在后面，因为高频系数中有很多 0，为了 节约空间，所以交流系数的“中间符号”用零行程码 (Zero Run Length) 表示。</p>
<p>然后再对直流系数和行程编码之后的交流系数进行huffman编码。Huffman编码是一种变长编码，符号出现的频率越高，码字越短。其实现的细节不是本文的重点，可以参考这里<a target="_blank" rel="noopener" href="https://blog.csdn.net/FX677588/article/details/70767446">Huffman编码详细解释</a></p>
<hr>
<h2 id="S3-视频编码标准-H-26X和MPEG"><a href="#S3-视频编码标准-H-26X和MPEG" class="headerlink" title="$\S3$ 视频编码标准 H.26X和MPEG"></a>$\S3$ 视频编码标准 H.26X和MPEG</h2><h3 id="标准介绍"><a href="#标准介绍" class="headerlink" title="标准介绍"></a>标准介绍</h3><p>H.26X主要应用于实时视频通信系统；MPEG主要应用于数字监控、视频存储、广播电视等领域；</p>
<p><img src="视频压缩算法设计/image-20201222145146342.png" srcset="/img/loading.gif" alt="image-20201222145146342" style="zoom: 50%;" /></p>
<p><img src="视频压缩算法设计/image-20201222145238108.png" srcset="/img/loading.gif" alt="image-20201222145238108"></p>
<p><img src="视频压缩算法设计/image-20201222145340229.png" srcset="/img/loading.gif" alt="image-20201222145340229"></p>
<h3 id="技术原理"><a href="#技术原理" class="headerlink" title="技术原理"></a>技术原理</h3><h2 id="S3-1-MPEG"><a href="#S3-1-MPEG" class="headerlink" title="$\S3.1$ MPEG"></a>$\S3.1$ MPEG</h2><p>在空间上采用MPEG压缩算法来去掉冗余的信息；</p>
<p>在时间的方向上采用运动补偿（Motion Compensation）算法来去掉冗余信息；</p>
<p>为了在保证图像质量基本不降低而又能获得高的压缩比，MPEG专家组定义了三种图像：</p>
<ul>
<li>帧内图（Intra pictures，I）</li>
<li>预测图（Predicted pictures，P）</li>
<li>插补图，即双向预测图（Bidirectional Prediction，B）</li>
</ul>
<p>帧间预测编码时要用到先前的图，当前的预测图作为后面预测图的参考值。双向预测图压缩效果显著，需要先前和后续的信息，双向预测图不能作为其它图的预测参考图。</p>
<p>三种参考图在时间上排序为：</p>
<pre><code class="hljs armasm">I <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> I <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> B</code></pre>
<p>三者之间存在明显的因果关系：如第四帧的P图是由第一帧的I图的预测，第一帧I图和第四帧P图共同预测出它们之间的双向预测B图。</p>
<p>因此接收端解码器输入不能按照时间的顺序，而应按照</p>
<pre><code class="hljs armasm">I P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> P <span class="hljs-keyword">B</span> <span class="hljs-keyword">B</span> I <span class="hljs-keyword">B</span> B...</code></pre>
<h3 id="I图编码"><a href="#I图编码" class="headerlink" title="I图编码"></a>I图编码</h3><p><img src="视频压缩算法设计/image-20201222150632046.png" srcset="/img/loading.gif" alt="image-20201222150632046" style="zoom:67%;" /></p>
<blockquote>
<p>补充：</p>
<p>YCbCr或Y’CbCr有的时候会被写作：YCBCR或是Y’CBCR，是<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/色彩空间/4615427">色彩空间</a>的一种，通常会用于影片中的影像连续处理，或是数字摄影系统中。Y’为颜色的亮度(luma)成分、而CB和CR则为蓝色和红色的浓度偏移量成份。Y’和Y是不同的，而Y就是所谓的亮度(<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/luminance/8678317">luminance</a>)，表示光的浓度且为非线性，使用伽马修正(gamma correction)编码处理。</p>
<p>YUV：“Y”表示明亮度（Luminance或Luma），也就是灰阶值，“U”和“V”表示的则是色度（Chrominance或Chroma），作用是描述影像色彩及饱和度，用于指定像素的颜色。Y’UV, YUV, <a target="_blank" rel="noopener" href="https://baike.baidu.com/item/YCbCr">YCbCr</a>，<a target="_blank" rel="noopener" href="https://baike.baidu.com/item/YPbPr">YPbPr</a>等专有名词都可以称为YUV。</p>
</blockquote>
<h3 id="P图编码"><a href="#P图编码" class="headerlink" title="P图编码"></a>P图编码</h3><p>预测图像的编码也是以图像宏块（macro block）为基本单元。一般取16x16. 预测图像编码宏块称为MPI，而参考图像中参考宏块称为MRJ。</p>
<p>预测图像P用两种类型的参数来表示：</p>
<ul>
<li>一种是当前要编码的图像宏块和参考图像宏块的差值；</li>
<li>宏块的运动矢量；</li>
</ul>
<p>对运动图像的编码其实就是寻找最佳的匹配图像宏块，找到最佳宏块之后就找到了最佳运动矢量d(dx,dy).</p>
<p><img src="视频压缩算法设计/image-20201222151154068.png" srcset="/img/loading.gif" alt="image-20201222151154068"></p>
<p><img src="视频压缩算法设计/image-20201222151547886.png" srcset="/img/loading.gif" alt="image-20201222151547886" style="zoom:67%;" /></p>
<p>那么我们如何求解运动矢量呢？</p>
<p>要使预测图像更精确，就要找到与MRJ最佳匹配的MPI。这通常以绝对值AE（Absolute difference）最小作为匹配依据：</p>
<script type="math/tex; mode=display">
AE=\sum\limits_{i=0}^{15}\sum\limits_{j=0}^{15}|f(i,j)-g(i-d_x,j-d_y)|</script><p>其中$d_x,d_y$分别是MRJ上的移动矢量d(dx,dy)在x，y方向的矢量。</p>
<p><img src="视频压缩算法设计/image-20201222152643104.png" srcset="/img/loading.gif" alt="image-20201222152643104"></p>
<p>MPEG允许选择I图像的频率和位置</p>
<ul>
<li>I图像频率指每秒出现I图像的次数（一般为2）；</li>
<li>位置指时间方向上I帧所在的位置；</li>
</ul>
<p>MPEG编码允许在一对I图像或者P图像之间选择B图像的数目。对于快速运动图像，B帧数目少一些，对于快速运动的图像，B帧数目多一些。</p>
<h2 id="预测编码"><a href="#预测编码" class="headerlink" title="预测编码"></a>预测编码</h2><p>In video compression “<strong>prediction</strong>“ of a block means finding the most“<strong>similar</strong>” block to the current one among the surrounding blocks.</p>
<p>在视频压缩技术中，“预测”一词指的是在当前像素块周围的一些像素块中找出（或者用一定的方法构造一个）与当前块最“接近”的像素块。</p>
<p>预测编码可以用于处理视频中的时间和空间域的冗余。视频处理中的预测编码主要分为两大类：帧内预测和帧间预测。</p>
<p>帧内预测：预测值与实际值位于同一帧内，用于消除图像的空间冗余；帧内预测的特点是压缩率相对较低，然而可以独立解码，不依赖其他帧的数据；通常视频中的关键帧都采用帧内预测。<br>帧间预测：帧间预测的实际值位于当前帧，预测值位于参考帧，用于消除图像的时间冗余；帧间预测的压缩率高于帧内预测，然而不能独立解码，必须在获取参考帧数据之后才能重建当前帧。</p>
<p>通常在视频码流中，I帧全部使用<strong>帧内</strong>编码，P帧/B帧中的数据可能使用<strong>帧内或者帧间</strong>编码。</p>
<p>运动估计（Motion Estimation）和运动补偿（Motion Compensation）是消除图像序列时间方向相关性的有效手段。上文介绍的DCT变换、量化、熵编码的方法是在一帧图像的基础上进行，通过这些方法可以消除图像内部各像素间在空间上的相关性。实际上图像信号除了空间上的相关性之外，还有时间上的相关性。例如对于像新闻联播这种背景静止，画面主体运动较小的数字视频，每一幅画面之间的区别很小，画面之间的相关性很大。对于这种情况我们没有必要对每一帧图像单独进行编码，而是可以只对相邻视频帧中变化的部分进行编码，从而进一步减小数据量，这方面的工作是由运动估计和运动补偿来实现的。</p>
<p><strong>运动估计</strong>技术一般将当前的输入图像分割成若干彼此不相重叠的小图像子块，例如一帧图像的大小为1280<em>720，首先将其以网格状的形式分成40</em>45个尺寸为16<em>16的彼此没有重叠的图像块，然后在前一图像或者后一个图像某个搜索窗口的范围内为每一个图像块寻找一个与之最为相似的图像块。这个搜寻的过程叫做运动估计。通过计算最相似的图像块与该图像块之间的位置信息，可以得到一个<strong>运动矢量</strong>。这样在编码过程中就可以将当前图像中的块与参考图像运动矢量所指向的最相似的图像块相减，得到一个<strong>残差图像块</strong>，由于残差图像块中的每个像素值很小，所以在压缩编码中可以获得更高的压缩比。这个相减过程叫<em>*运动补偿</em></em>。</p>
<p>由于编码过程中需要使用参考图像来进行运动估计和运动补偿，因此参考图像的选择显得很重要。一般情况下编码器的将输入的每一帧图像根据其参考图像的不同分成3种不同的类型：I（Intra）帧、B（Bidirection prediction）帧、P（Prediction）帧。如图所示。</p>
<p><img src="https://pic2.zhimg.com/80/v2-765f92a473a8241b057b7128b0b3e18d_720w.jpg" srcset="/img/loading.gif" alt="img"></p>
<p>如图所示，I帧只使用本帧内的数据进行编码，在编码过程中它不需要进行运动估计和运动补偿。显然，由于I帧没有消除时间方向的相关性，所以压缩比相对不高。P帧在编码过程中使用一个前面的I帧或P帧作为参考图像进行运动补偿，实际上是对当前图像与参考图像的差值进行编码。B帧的编码方式与P帧相似，惟一不同的地方是在编码过程中它要使用一个前面的I帧或P帧和一个后面的I帧或P帧进行预测。由此可见，每一个P帧的编码需要利用一帧图像作为参考图像，而B帧则需要两帧图像作为参考。相比之下，B帧比P帧拥有更高的压缩比。</p>
<h3 id="音频压缩"><a href="#音频压缩" class="headerlink" title="音频压缩"></a>音频压缩</h3><p>MPEG利用人的听觉特性来达到压缩声音数据的目的；这种压缩编码称为<strong>感知声音编码</strong>（Perceptual Coding）。</p>
<p>这种“听觉特性”表现在三个方面：<strong>响度，音调和掩蔽效应</strong>。</p>
<p>对于音调，人耳的听觉范围20-20000Hz。主观听觉单位Mel = 1000log(1+f).所谓的掩蔽效应指一种频率的声音阻碍另一种频率声音被听到的现象。</p>
<p><img src="视频压缩算法设计/image-20201222153455563.png" srcset="/img/loading.gif" alt="image-20201222153455563"></p>
<p><img src="视频压缩算法设计/image-20201222153710385.png" srcset="/img/loading.gif" alt="image-20201222153710385" style="zoom: 67%;" /></p>
<p>MPEG采用两种类型的感知编码：</p>
<ul>
<li>感知子带编码</li>
</ul>
<p><img src="视频压缩算法设计/image-20201222153929601.png" srcset="/img/loading.gif" alt="image-20201222153929601" style="zoom:67%;" /></p>
<ul>
<li><p>Dolby AC-3编码</p>
<p><img src="视频压缩算法设计/image-20201222154011808.png" srcset="/img/loading.gif" alt="image-20201222154011808" style="zoom:67%;" /></p>
</li>
</ul>
<hr>
<h1 id="实践部分"><a href="#实践部分" class="headerlink" title="实践部分"></a>实践部分</h1><h2 id="I帧的JPEG编码"><a href="#I帧的JPEG编码" class="headerlink" title="I帧的JPEG编码"></a>I帧的JPEG编码</h2><p>首先，我们将BGR图像转换为YCbCr图像。</p>
<p>原始图像：</p>
<p><img src="视频压缩算法设计/rgb_in.jpg" srcset="/img/loading.gif" alt="rgb_in"></p>
<p>Y通道图</p>
<p><img src="视频压缩算法设计/Y.jpg" srcset="/img/loading.gif" alt="Y"></p>
<p>Cb通道图</p>
<p><img src="视频压缩算法设计/V.jpg" srcset="/img/loading.gif" alt="V"></p>
<p>Cr通道图</p>
<p><img src="视频压缩算法设计/U.jpg" srcset="/img/loading.gif" alt="U"></p>
<h2 id="DCT"><a href="#DCT" class="headerlink" title="DCT"></a>DCT</h2><p>需要先将图片格式从<code>CV_8UC3</code>转换为<code>CV_64FC3</code>。这里8C表示像素数据类型unit8，C3表示三个通道。发现三个通道图像基本上是黑色，初始怀疑自己是否犯了技术性错误，后来尝试重构图像，还是能得到原图，说明没有错误，DCT得到本来就是稀疏矩阵。</p>
<p>重建的Y图</p>
<p><img src="视频压缩算法设计/Recoverd_Y_image.jpg" srcset="/img/loading.gif" alt="Recoverd_Y_image"></p>
<p>重建Cb图</p>
<p><img src="视频压缩算法设计/Recoverd_V_image.jpg" srcset="/img/loading.gif" alt="Recoverd_V_image"></p>
<p>重建的Cr图</p>
<p><img src="视频压缩算法设计/Recoverd_U_image.jpg" srcset="/img/loading.gif" alt="Recoverd_U_image"></p>
<p>最终合成的BGR</p>
<p><img src="视频压缩算法设计/Recovered_DstImage-1609051779633.jpg" srcset="/img/loading.gif" alt="Recovered_DstImage"></p>
<p>可以看到明显有失真。</p>
<p>我们在通道压缩时定义了一个阈值T，低于此阈值的像素会被设为0.我们将其从40改为10，发现图像质量明显改善。</p>
<p><img src="视频压缩算法设计/Recovered_DstImage-1609053088968.jpg" srcset="/img/loading.gif" alt="Recovered_DstImage"></p>
<blockquote>
</blockquote>

            </div>
            <hr>
            <div>
              <div class="post-metas mb-3">
                
                  <div class="post-meta mr-3">
                    <i class="iconfont icon-category"></i>
                    
                      <a class="hover-with-bg" href="/categories/%E7%AE%97%E6%B3%95/">算法</a>
                    
                  </div>
                
                
                  <div class="post-meta">
                    <i class="iconfont icon-tags"></i>
                    
                      <a class="hover-with-bg" href="/tags/%E6%95%B0%E6%8D%AE%E5%8E%8B%E7%BC%A9/">数据压缩</a>
                    
                      <a class="hover-with-bg" href="/tags/%E5%A4%9A%E5%AA%92%E4%BD%93%E6%8A%80%E6%9C%AF/">多媒体技术</a>
                    
                  </div>
                
              </div>
              
                <p class="note note-warning">本博客所有文章除特别声明外，均采用 <a target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/deed.zh" rel="nofollow noopener noopener">CC BY-SA 4.0 协议</a> ，转载请注明出处！</p>
              
              
                <div class="post-prevnext row">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2020/12/23/%E3%80%8CML%20vol.3%E3%80%8D%E6%84%9F%E7%9F%A5%E6%9C%BA/">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">「ML vol.1」kNN算法</span>
                        <span class="visible-mobile">上一篇</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2020/12/15/Ceph%20%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">
                        <span class="hidden-mobile">「参考」Ceph配置参数conf</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
              <!-- Comments -->
              <article class="comments" id="comments">
                
                
  <div id="vcomments"></div>
  <script type="text/javascript">
    function loadValine() {
      addScript('https://cdn.staticfile.org/valine/1.4.14/Valine.min.js', function () {
        new Valine({
          el: "#vcomments",
          app_id: "8oX7VCxy9tyFQIvF8qwLorP0-gzGzoHsz",
          app_key: "F0939INl4cKXpCw2HgTIUb6B",
          placeholder: "说点什么,（支持Markdown）",
          path: window.location.pathname,
          avatar: "retro",
          meta: ["nick","mail","link"],
          pageSize: "10",
          lang: "zh-CN",
          highlight: false,
          recordIP: false,
          serverURLs: "https://8ox7vcxy.lc-cn-n1-shared.com",
        });
      });
    }
    waitElementVisible('vcomments', loadValine);
  </script>
  <noscript>Please enable JavaScript to view the <a target="_blank" href="https://valine.js.org" rel="nofollow noopener noopener">comments
      powered by Valine.</a></noscript>


              </article>
            
          </article>
        </div>
      </div>
    </div>
    
      <div class="d-none d-lg-block col-lg-2 toc-container" id="toc-ctn">
        <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div id="tocbot"></div>
</div>

      </div>
    
  </div>
</div>

<!-- Custom -->


    
  </main>

  
    <a id="scroll-top-button" href="#" role="button">
      <i class="iconfont icon-arrowup" aria-hidden="true"></i>
    </a>
  

  
    <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v"
                 for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>
  

  

  

  <footer class="mt-5">
  <div class="text-center py-3">
    <div>
      <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a>
      <i class="iconfont icon-love"></i>
      <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener">
        <span>Fluid</span></a>
    </div>
    
  <div class="statistics">
    
    

    
      
        <!-- 不蒜子统计PV -->
        <span id="busuanzi_container_site_pv" style="display: none">
            总访问量 
            <span id="busuanzi_value_site_pv"></span>
             次
          </span>
      
      
        <!-- 不蒜子统计UV -->
        <span id="busuanzi_container_site_uv" style="display: none">
            总访客数 
            <span id="busuanzi_value_site_uv"></span>
             人
          </span>
      
    
  </div>


    

    
  </div>
</footer>

<!-- SCRIPTS -->
<script  src="https://cdn.staticfile.org/jquery/3.4.1/jquery.min.js" ></script>
<script  src="https://cdn.staticfile.org/twitter-bootstrap/4.4.1/js/bootstrap.min.js" ></script>
<script  src="/js/debouncer.js" ></script>
<script  src="/js/main.js" ></script>

<!-- Plugins -->


  
    <script  src="/js/lazyload.js" ></script>
  



  



  <script defer src="https://cdn.staticfile.org/clipboard.js/2.0.6/clipboard.min.js" ></script>
  <script  src="/js/clipboard-use.js" ></script>



  <script defer src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js" ></script>





  <script  src="https://cdn.staticfile.org/tocbot/4.11.1/tocbot.min.js" ></script>
  <script>
    $(document).ready(function () {
      var boardCtn = $('#board-ctn');
      var boardTop = boardCtn.offset().top;

      tocbot.init({
        tocSelector: '#tocbot',
        contentSelector: '#post-body',
        headingSelector: 'h1,h2,h3,h4,h5,h6',
        linkClass: 'tocbot-link',
        activeLinkClass: 'tocbot-active-link',
        listClass: 'tocbot-list',
        isCollapsedClass: 'tocbot-is-collapsed',
        collapsibleClass: 'tocbot-is-collapsible',
        collapseDepth: 0,
        scrollSmooth: true,
        headingsOffset: -boardTop
      });
      if ($('.toc-list-item').length > 0) {
        $('#toc').css('visibility', 'visible');
      }
    });
  </script>



  <script  src="https://cdn.staticfile.org/typed.js/2.0.11/typed.min.js" ></script>
  <script>
    var typed = new Typed('#subtitle', {
      strings: [
        '  ',
        "视频压缩算法设计&nbsp;",
      ],
      cursorChar: "_",
      typeSpeed: 70,
      loop: false,
    });
    typed.stop();
    $(document).ready(function () {
      $(".typed-cursor").addClass("h2");
      typed.start();
    });
  </script>



  <script  src="https://cdn.staticfile.org/anchor-js/4.2.2/anchor.min.js" ></script>
  <script>
    anchors.options = {
      placement: "right",
      visible: "hover",
      
    };
    var el = "h1,h2,h3,h4,h5,h6".split(",");
    var res = [];
    for (item of el) {
      res.push(".markdown-body > " + item)
    }
    anchors.add(res.join(", "))
  </script>



  <script  src="/js/local-search.js" ></script>
  <script>
    var path = "/local-search.xml";
    var inputArea = document.querySelector("#local-search-input");
    inputArea.onclick = function () {
      searchFunc(path, 'local-search-input', 'local-search-result');
      this.onclick = null
    }
  </script>



  <script  src="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.js" ></script>
  <link  rel="stylesheet" href="https://cdn.staticfile.org/fancybox/3.5.7/jquery.fancybox.min.css" />

  <script>
    $('#post img:not(.no-zoom img, img[no-zoom]), img[zoom]').each(
      function () {
        var element = document.createElement('a');
        $(element).attr('data-fancybox', 'images');
        $(element).attr('href', $(this).attr('src'));
        $(this).wrap(element);
      }
    );
  </script>







  
  
    <script>
      !function (e, t, a) {
        function r() {
          for (var e = 0; e < s.length; e++) s[e].alpha <= 0 ? (t.body.removeChild(s[e].el), s.splice(e, 1)) : (s[e].y--, s[e].scale += .004, s[e].alpha -= .013, s[e].el.style.cssText = "left:" + s[e].x + "px;top:" + s[e].y + "px;opacity:" + s[e].alpha + ";transform:scale(" + s[e].scale + "," + s[e].scale + ") rotate(45deg);background:" + s[e].color + ";z-index:99999");
          requestAnimationFrame(r)
        }

        function n() {
          var t = "function" == typeof e.onclick && e.onclick;
          e.onclick = function (e) {
            t && t(), o(e)
          }
        }

        function o(e) {
          var a = t.createElement("div");
          a.className = "heart", s.push({
            el: a,
            x: e.clientX - 5,
            y: e.clientY - 5,
            scale: 1,
            alpha: 1,
            color: c()
          }), t.body.appendChild(a)
        }

        function i(e) {
          var a = t.createElement("style");
          a.type = "text/css";
          try {
            a.appendChild(t.createTextNode(e))
          } catch (t) {
            a.styleSheet.cssText = e
          }
          t.getElementsByTagName("head")[0].appendChild(a)
        }

        function c() {
          return "rgb(" + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + "," + ~~(255 * Math.random()) + ")"
        }

        var s = [];
        e.requestAnimationFrame = e.requestAnimationFrame || e.webkitRequestAnimationFrame || e.mozRequestAnimationFrame || e.oRequestAnimationFrame || e.msRequestAnimationFrame || function (e) {
          setTimeout(e, 1e3 / 60)
        }, i(".heart{width: 10px;height: 10px;position: fixed;background: #f00;transform: rotate(45deg);-webkit-transform: rotate(45deg);-moz-transform: rotate(45deg);}.heart:after,.heart:before{content: '';width: inherit;height: inherit;background: inherit;border-radius: 50%;-webkit-border-radius: 50%;-moz-border-radius: 50%;position: fixed;}.heart:after{top: -5px;}.heart:before{left: -5px;}"), n(), r()
      }(window, document);
    </script>
  








  <script  src="https://cdn.staticfile.org/mermaid/8.5.0/mermaid.min.js" ></script>
  <script>
    if (window.mermaid) {
      mermaid.initialize({"theme":"default"});
    }
  </script>




  

  

  

  

  

  





<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<!--<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>-->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>
</html>
