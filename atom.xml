<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Durant Thorvalds 的米奇妙妙屋</title>
  
  <subtitle>在这里，您能感受算法和大数据及存储的魅力！</subtitle>
  <link href="http://durantthorvalds.top/atom.xml" rel="self"/>
  
  <link href="http://durantthorvalds.top/"/>
  <updated>2020-12-16T08:38:32.218Z</updated>
  <id>http://durantthorvalds.top/</id>
  
  <author>
    <name>Durant</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>「置顶」本博客导航！</title>
    <link href="http://durantthorvalds.top/2025/12/31/2020-10-8-article_navigator/"/>
    <id>http://durantthorvalds.top/2025/12/31/2020-10-8-article_navigator/</id>
    <published>2025-12-30T16:00:00.000Z</published>
    <updated>2020-12-16T08:38:32.218Z</updated>
    
    <content type="html"><![CDATA[<div class="note note-warning">            <p>若您的网页显示mathjax公式出现问题，导致无法阅读，请在任意Mathjax公式上点击右键，<code>Math settings</code>-&gt;<code>Math renderer</code>-&gt;更改为<code>HTML-CSS</code>即可解决。</p>          </div><div class="note note-primary">            <p>因博主水平有限，不足之处请直接在评论区指出，博主将感激不尽！</p>          </div><p>欢迎您光顾本博客！</p><p>本博客 包括<strong>LeetCode</strong>刷题记录和经验，机器学习，以及硕士专业研究课题方面。</p><p>本人硕士研究课题是 <u><strong>纠删码</strong>及<strong>去重</strong>在Ceph分布式存储集群上的应用</u>。对此研究方向感兴趣的道友欢迎一起交流。</p><hr><h2 id="👌LeetCode刷题记录"><a href="#👌LeetCode刷题记录" class="headerlink" title="👌LeetCode刷题记录"></a>👌LeetCode刷题记录</h2><h3 id="A-动态规划"><a href="#A-动态规划" class="headerlink" title="A. 动态规划"></a>A. 动态规划</h3><ul><li><p>动态规划 <a href="https://durantthorvalds.top/2020/07/21/2020-07-21-dynamic-planning/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>动态规划是将问题分解为更易解决的子问题的一类方法，本blog由浅入深介绍动态规划的常见题型，dp是笔试最常考的问题之一。</p></blockquote></li></ul><ul><li><p>做一只可爱的小🐖背包 Cover「背包九讲」 <a href="https://durantthorvalds.top/2020/07/25/2020-07-27-backpack-problem/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>背包问题是很经典的一类dp问题。本blog介绍9种类型的背包问题。面试者若能举一反三，必将事半功倍。</p></blockquote></li></ul><h3 id="B-树类问题"><a href="#B-树类问题" class="headerlink" title="B. 树类问题"></a>B. 树类问题</h3><ul><li><p>必须掌握的数据结构-树 <a href="https://durantthorvalds.top/2020/09/23/2020-9-23-binary_tree/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>如果你还不知道什么是树，没有关系！我们将从零开始介绍，1. 二叉树的表示 2.二叉树的遍历 3. 二叉树序列化以及反序列化 4. 树形dp  5.线索二叉树 等。使得你对树类问题有基本认识。</p></blockquote></li></ul><ul><li><p>树状数组和线段树 <a href="https://durantthorvalds.top/2020/07/17/2020-07-17-fenwicktree-segmentTree/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>树状数组和线段树都是用于维护数列信息的数据结构，支持单点/区间修改，单点/区间询问信息。以增加权值与询问区间权值和为例，其余的信息需要维护也都类似。时间复杂度均为$O(logn)$。</p></blockquote></li></ul><ul><li><p>Google划词搜索的秘密——前缀树 <a href="https://durantthorvalds.top/2020/07/21/2020-8-20-what-is-Trie/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>前缀树又名<strong>Tries树</strong>、<strong>字典</strong>树、单词查找树等，常用于快速检索，大量字符串的排序和统计等。Trie相比于哈希表存储多个具有相同前缀的键时所用空间较少。因此前缀树只需要$O(m)$的空间，m为键长度。在字符串问题中很常见。</p></blockquote></li></ul><ul><li><p>花拳绣腿学红黑树 <a href="https://durantthorvalds.top/2020/05/10/2020-05-10-red-black-tree/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>红黑树的结点增删改查效率非常优良，都为$log(n) $, 应用方面：1. Linux内核进程调度由红黑树管理进程控制块。 2. Epoll用红黑树管理事件块。 3. nginx服务器用红黑树管理定时器。 4. C++ STL中的map和set的底层实现为红黑树。 5. Java中的TreeMap和TreeSet由红黑树实现。 6. Java8开始，HashMap中，当一个桶的链表长度超过8，则会改用红黑树。红黑树在面试中会出现，笔试中可不会出现哦。</p></blockquote></li></ul><ul><li><p>全手写实现AVL树 <a href="https://durantthorvalds.top/2020/05/10/2020-04-30-avl-tree/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>AVL树是严格平衡的二叉树，红黑树是弱平衡的二叉树。和红黑树相比，AVL树是严格的平衡二叉树，平衡条件必须满足（所有节点的左右子树高度差不超过1）。通过对任何一条从根到叶子的路径上各个节点着色的方式的限制，红黑树确保没有一条路径会比其它路径长出两倍，因此相同节点数的前提下，AVL树的高度往往低于红黑树。同样，在笔试中不会出现，面试时可能会问概念。有兴趣的读者可以自己实现。</p></blockquote></li></ul><h3 id="C-模拟问题"><a href="#C-模拟问题" class="headerlink" title="C. 模拟问题"></a>C. 模拟问题</h3><ul><li><p>神奇的多指针 <a href="https://durantthorvalds.top/2020/07/21/2020-7-30-pointers/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>很多时候多指针（双指针，三指针，快慢指针）能极大的帮助我们降低时间复杂度和空间复杂度，比如从$O(n^2)$降低到$O(n)$。例如求链表到数第N个节点，以及判断链表中是否有环，神奇的Floyd判圈法。</p></blockquote></li></ul><ul><li><p>「面试向」排序算法 <a href="https://durantthorvalds.top/2020/07/21/2020-7-30-sorting-magic/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>包括冒泡排序，选择排序，插入排序，希尔排序，归并排序，快速排序，堆排序，计数排序，桶排序，基数排序。研究它们算法，以及最好最坏平均时间复杂度和空间复杂度，是否为就地替换以及稳定性。</p></blockquote></li></ul><ul><li><p>解空间极大问题通用策略 <a href="https://durantthorvalds.top/2020/08/01/2020-8-1-common-way-solve-big-problem/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>如果输出有非常的项（比如求子集，全排列），要确保结果<strong>完整</strong>且不<strong>重复</strong>，有多种策略：1. 递归，2. 回溯，3. 字典， 4. 数学， 5. 状态压缩， 6. 剪枝技巧</p></blockquote></li></ul><ul><li><p>滑动窗口，滑动的艺术 <a href="https://durantthorvalds.top/2020/07/21/2020-8-1-sliding-windows/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>在滑动窗口中有两个指针，一个指针静止，而另一个指针保持移动。我们在s上滑动窗口，如果能够包含整个T（<strong>注意</strong>，T可能有重复字符），如果能收缩，我们就收缩窗口直到得到最小窗口。</p></blockquote></li></ul><ul><li><p>红尘客栈之单调栈 <a href="https://durantthorvalds.top/2020/07/21/2020-8-17-recognition-monostack/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>单调栈内元素保持<strong>非递减顺序</strong>，在特定的应用背景下，比如一维参量在一个<strong>连续</strong>范围变化，温度在一段时间变化，股价的增减，柱状图。请考虑单调栈。</p></blockquote></li></ul><ul><li><p>数组和字符串的🆒skr操作——前缀和 <a href="https://durantthorvalds.top/2020/10/16/2020-10-16-prefix_sum/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>前缀和的本质是一维或二维差分数组，对区间的查询和修改，比树状数组和线段树相比，不需要特定的数据结构，更加容易使用。</p></blockquote></li></ul><ul><li><p>一句话能打败 99.99999%的程序员的位操作代码 <a href="https://durantthorvalds.top/2020/08/23/2020-8-23-bitoperation/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>位操作是计算机最基本的操作之一，它可以与很多问题进行结合，从而优化解法空间复杂度，比如在状态压缩中利用左移，数组low_bit以及<strong>Brian kernighan算法</strong>.</p></blockquote></li></ul><h3 id="D-贪心算法"><a href="#D-贪心算法" class="headerlink" title="D. 贪心算法"></a>D. 贪心算法</h3><ul><li><p>贪婪而巧妙的贪心算法 <a href="https://durantthorvalds.top/2020/09/02/2020-8-25-greedy/">&gt;&gt;传送门&lt;&lt;</a></p><blockquote><p>贪心算法（又称贪婪算法）是指，在对问题求解时，总是做出在当前看来是最好的选择。也就是说，不从整体最优上加以考虑，他所做出的是在某种意义上的局部最优解。</p></blockquote></li></ul><h3 id="E-数学"><a href="#E-数学" class="headerlink" title="E. 数学"></a>E. 数学</h3><ul><li>数学和线性代数用于解题 <a href="https://durantthorvalds.top/2020/09/02/2020-8-25-math/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>数论，求质因数,最大公因数（GCD）,最小公倍数（LCM）, 快速幂算法, Gauss消元法, 几何，排列组会问题等</p></blockquote><h3 id="F-字符串"><a href="#F-字符串" class="headerlink" title="F. 字符串"></a>F. 字符串</h3><ul><li>臭名昭著的KMP算法<a href="https://durantthorvalds.top/2020/07/21/2020-8-29-KMP/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p><strong>KMP</strong>算法是用于字符串匹配，十分巧妙，也极难理解。</p></blockquote><ul><li>东方不败——回文问题<a href="https://durantthorvalds.top/2020/07/21/2020-08-19-manacher/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>回文指正反读都一样的字符串，<strong>Manacher</strong>算法专门用于解决回文问题。当然，<strong>Rabin-Karp</strong>编码在一定条件下也是不错的解决问题的方法。</p></blockquote><h3 id="G-图论"><a href="#G-图论" class="headerlink" title="G. 图论"></a>G. 图论</h3><ul><li>再也不想做图类题目了 <a href="https://durantthorvalds.top/2020/07/21/2020-08-1-representation_of_graph/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>本博客介绍了四种图的表示方法，包括 邻接矩阵表示法，关联矩阵表示法，邻接表表示法，弧表示法，星形表示法。以及图的典型算法，包括Dijkstra, Floyd, Bellman-Ford以及SPFA算法。</p></blockquote><ul><li>双胞胎DFS与BFS <a href="https://durantthorvalds.top/2020/09/27/2020-8-12-dfs-bfs/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>二叉树里面的三种遍历既可以用DFS（递归写法），也可以用BFS（迭代+栈），而层序遍历对应的就是BFS。</p><p>在图和树类型题目，以及部分数组题目，都可以时不时看到两种算法同时出现。递归注意1. 触发条件 2. 终止条件 3. 剪枝问题。</p></blockquote><ul><li>浅析最小生成树  <a href="https://durantthorvalds.top/2020/09/18/2020-9-12-minimal-Spanning-tree/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>最小生成树（$Minimal  Spanning  Tree,MST$）：有 n 个结点的<a href="https://baike.baidu.com/item/连通图/6460995">连通图</a>的生成树是原图的极小连通子图，且包含原图中的所有 n 个结点，并且有保持图连通的最少的边。比较常用的有两种算法：$Kruskal$算法和$Prim$算法。</p></blockquote><ul><li>优雅而巧妙的并查集 <a href="https://durantthorvalds.top/2020/08/14/2020-8-14-what-is-UnionSet/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>并查集被许多$OIers$认为是简洁而高雅的数据结构之一，主要用于解决一些<strong>元素分组</strong>的问题，它管理一系列<strong>不相交</strong>的集合，并支持两种操作。即<strong>查询</strong>和<strong>合并</strong>。在求联通/合并问题能大显身手。</p></blockquote><ul><li>求解欧拉通路<a href="https://durantthorvalds.top/2020/08/27/2020-8-27-some_tricks/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>给定一个 <em>n</em> 个点 <em>m</em> 条边的图，要求从指定的顶点出发，经过所有的边恰好一次（可以理解为给定起点的「一笔画」问题），使得路径的字典序最小。常见算法有$Hierholzer$算法。</p></blockquote><ul><li>抛砖引玉析回溯 <a href="https://durantthorvalds.top/2020/08/02/2020-8-2-trackback-demo/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>回溯法，通常以dfs或bfs为载体，在特定的问题下，通过试错，得到所有可能状态，当然有些状态是多余的，因此<strong>剪枝</strong>显得极为重要。</p></blockquote><ul><li>距离向量路由选择算法——DV <a href="https://durantthorvalds.top/2020/12/15/%E8%B7%9D%E7%A6%BB%E5%90%91%E9%87%8F%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95DV/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>目前的路由器都在运行的算法，你一定不想不知道！</p></blockquote><h3 id="H-综合应用"><a href="#H-综合应用" class="headerlink" title="H. 综合应用"></a>H. 综合应用</h3><ul><li>买股票问题 <a href="https://durantthorvalds.top/2020/08/26/2020-8-26-lotus/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>这类问题涉及很多知识，可能包括dp，单调栈，有限状态自动机等。</p></blockquote><ul><li>权力的游戏之零和博弈  <a href="https://durantthorvalds.top/2020/07/21/2020-9-1-what-is-zero-sum/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>在零和博弈中，让自己最优和让对手最差其实是相同的目标！原因还是那句话，两人的总得分不会变化，自己多了，对手必然减少。没有人是傻子，但是赢者通常会利用游戏规则!</p></blockquote><h3 id="G-其它"><a href="#G-其它" class="headerlink" title="G. 其它"></a>G. 其它</h3><ul><li>有限状态自动机（DSA）<a href="https://durantthorvalds.top/2020/09/02/2020-9-2-fsm/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>确定有限状态自动机（以下简称「自动机」）是一类计算模型。它包含一系列状态，这些状态中：有一个特殊的状态，被称作「初始状态」。还有一系列状态被称为「接受状态」，它们组成了一个特殊的集合。其中，一个状态可能既是「初始状态」，也是「接受状态」。</p></blockquote><ul><li>代码优化系列<a href="https://durantthorvalds.top/2020/09/18/%E4%BB%A3%E7%A0%81%E4%BC%98%E5%8C%96%E7%B3%BB%E5%88%97/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>包括C++,Java, Python代码中很容易遇见的坑，类似于错别字和陷阱，一定要注意。</p></blockquote><ul><li>设计类问题 <a href="">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>Leetcode 上典型设计问题的赏析。举一反三，触类旁通。</p></blockquote><ul><li>「研究向」Redis中跳表实现原理<a href="https://durantthorvalds.top/2020/12/01/%E3%80%90%E7%A0%94%E7%A9%B6%E5%90%91%E3%80%91Redis%E4%B8%AD%E8%B7%B3%E8%A1%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>在分布式存储系统Redis中一个非常优秀的算法，跳表，LC上也有对应的题目。</p></blockquote><h2 id="🤖机器学习系列"><a href="#🤖机器学习系列" class="headerlink" title="🤖机器学习系列"></a>🤖机器学习系列</h2><blockquote><p>以周志华老师《机器学习》为基准，力争从算法角度解释机器学习的所有问题。</p></blockquote><ul><li>机器学习I 基本概念 <a href="https://durantthorvalds.top/2020/08/04/2020-05-10-ML1/">&gt;&gt;传送门&lt;&lt;</a></li><li>机器学习II 模型评估与选择<a href="https://durantthorvalds.top/2020/08/04/2020-08-4-ML2/">&gt;&gt;传送门&lt;&lt;</a></li><li>机器学习III 线性模型 <a href="https://durantthorvalds.top/2020/08/23/2020-08-23-ML3/">&gt;&gt;传送门&lt;&lt;</a></li><li>机器学习算法I 决策树 <a href="https://durantthorvalds.top/2020/09/27/ML4_DecisionTree/">&gt;&gt;传送门&lt;&lt;</a></li><li>机器学习算法II 神经网络 <a href="[https://durantthorvalds.top/2020/10/02/20201002-%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%97%E6%B3%95II-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/](https://durantthorvalds.top/2020/10/02/20201002-机器学习算法II-神经网络/">&gt;&gt;传送门&lt;&lt;</a>)</li></ul><h2 id="🚀大数据与分布式存储系列"><a href="#🚀大数据与分布式存储系列" class="headerlink" title="🚀大数据与分布式存储系列"></a>🚀大数据与分布式存储系列</h2><blockquote><p>以云存储和大数据为研究背景。辐射包括Ceph，Hadoop，纠删码研究等方方面面。</p><p>其中「入门部署」表示初始部署集群，「高级部署」表示有一定挑战性的部署，比如手动部署，「参考」表示一些非核心的帮助理解的内容，「核心」表示深入理解原理，并且熟练操作。「综述」表示一些学术性总结内容。「研究向」表示需要很多时间和兴趣来研究的内容，面试一般不会考到，但很经典。</p></blockquote><h2 id="入门"><a href="#入门" class="headerlink" title="入门"></a>入门</h2><ul><li>「高级部署」ceph手动部署集群<a href="https://durantthorvalds.top/2020/10/21/Ceph%E6%89%8B%E5%8A%A8%E9%85%8D%E7%BD%AE%E9%9B%86%E7%BE%A4%E9%83%A8%E7%BD%B2/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>包括手动部署，存储集群配置以及<strong>源码编译</strong>等。</p></blockquote><ul><li>「入门理论」ceph基础理论——<a href="https://durantthorvalds.top/2020/10/28/CEPH%E8%B8%A9%E5%9D%91%E5%AD%A6%E4%B9%A0/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>ceph的基本原理，供读者有一个大致了解。</p></blockquote><ul><li>「入门部署」ceph-ansible部署踩坑日记——<a href="https://durantthorvalds.top/2020/11/25/Ceph-ansible%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>ceph-ansible是目前用的最广的ceph部署工具，功能远超ceph-deploy。建议采用此方式。</p></blockquote><ul><li>「入门部署」Ceph-deploy流程 <a href="https://durantthorvalds.top/2020/11/19/Ceph-deploy%E6%B5%81%E7%A8%8B/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>完整的ceph-deploy部署流程。</p></blockquote><ul><li>「综述」纠删码在存储系统的应用——<a href="https://durantthorvalds.top/2020/11/15/%E7%BA%A0%E5%88%A0%E7%A0%81%E5%9C%A8%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BA%94%E7%94%A8/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>最最最最最最新的纠删码综述，包括RS码，包括RS码，MSR，LRC等。不断更新，引领前沿。</p></blockquote><h2 id="进阶"><a href="#进阶" class="headerlink" title="进阶"></a>进阶</h2><ul><li>「核心」Ceph三部曲之一：浅析CRUSH算法———<a href="https://durantthorvalds.top/2020/11/27/A%20first%20glance%20at%20CRUSH/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>介绍Ceph核心算法，CRUSH算法。以及相关实践。</p></blockquote><ul><li>「核心」Ceph三部曲之二：ceph纠删码部署——<a href="https://durantthorvalds.top/2020/11/26/ceph%E7%BA%A0%E5%88%A0%E7%A0%81%E9%83%A8%E7%BD%B2/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>ceph中纠删码部署。从原理到五种库源码，笔者研究重点，因为目前Ceph纠删码还有很多待完善的地方。</p></blockquote><ul><li>「核心」Ceph三部曲之三：迁移之美——PG读写流程与状态迁移详解 ———<a href="https://durantthorvalds.top/2020/12/15/%E8%BF%81%E7%A7%BB%E4%B9%8B%E7%BE%8EPG%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B%E4%B8%8E%E7%8A%B6%E6%80%81%E8%BF%81%E7%A7%BB%E8%AF%A6%E8%A7%A3/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>ceph最难理解也最有趣的概念，PG。深入学习必看!</p></blockquote><ul><li>「核心」Ceph三部曲之四:下一代对象存储引擎BlueStore ———<a href="https://durantthorvalds.top/2020/12/27/%E4%B8%8B%E4%B8%80%E4%BB%A3%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8EBlueStore/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>目前的存储介质已经由传统的机械硬盘hdd升级到SSD和NVME，这为下一代对象存储BlueStore提供了基础，相比于目前FileStore，BlueStore拥有无与伦比的优势。</p></blockquote><ul><li>「核心」Ceph学习三部曲之五:控制先行——Ceph的QoS策略</li></ul><blockquote><p>详细介绍Ceph QoS策略，讲解dmClock等算法实现和操作。</p></blockquote><ul><li>「参考」Ceph pool  ———<a href="https://durantthorvalds.top/2020/12/14/ceph%20pool/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>Ceph的池是理解PG，OSD的桥梁，可以直接操作的对象！</p></blockquote><ul><li>「参考」Ceph配置文件conf ———<a href="https://durantthorvalds.top/2020/12/15/Ceph%20%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>ceph文件配置参考。</p></blockquote><ul><li>「参考」Ceph-Mon详解 ———<a href="https://durantthorvalds.top/2020/11/03/2020113-Ceph-Mon-%E8%AF%A6%E8%A7%A3/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>对Ceph的管理者Monitor进行理解。监视器们维护着集群运行图的“主副本”，就是说客户端连到一个监视器并获取当前运行图就能确定所有监视器、 OSD 和元数据服务器的位置。</p></blockquote><h2 id="大师"><a href="#大师" class="headerlink" title="大师"></a>大师</h2><h2 id="🍜文化"><a href="#🍜文化" class="headerlink" title="🍜文化"></a>🍜文化</h2><blockquote><p>看看就好，笔者的一些随笔和感想。涵盖方面及其广泛。</p></blockquote><ul><li>小白投资入门（煎炸卤炖）———<a href="https://durantthorvalds.top/2020/12/14/%E5%B0%8F%E7%99%BD%E6%8A%95%E8%B5%84%E5%85%A5%E9%97%A8/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>看知乎，学炒股。</p></blockquote><ul><li>日语名谚语系列 ———<a href="https://durantthorvalds.top/2020/11/19/%E6%AF%8E%E6%97%A5%E6%94%BE%E9%80%81%EF%BC%8D%E6%97%A5%E6%9C%AC%E3%81%AE%E8%AB%BA/">&gt;&gt;传送门&lt;&lt;</a></li></ul><blockquote><p>笔者对日语文化有浓厚兴趣，立志考过N1，いしょうに頑張ってなあ！</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note note-warning&quot;&gt;
            &lt;p&gt;若您的网页显示mathjax公式出现问题，导致无法阅读，请在任意Mathjax公式上点击右键，&lt;code&gt;Math settings&lt;/code&gt;-&amp;gt;&lt;code&gt;Math rend</summary>
      
    
    
    
    <category term="导航" scheme="http://durantthorvalds.top/categories/%E5%AF%BC%E8%88%AA/"/>
    
    
  </entry>
  
  <entry>
    <title>「核心」Ceph学习三部曲之四:下一代对象存储引擎BlueStore</title>
    <link href="http://durantthorvalds.top/2020/12/27/%E4%B8%8B%E4%B8%80%E4%BB%A3%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8EBlueStore/"/>
    <id>http://durantthorvalds.top/2020/12/27/%E4%B8%8B%E4%B8%80%E4%BB%A3%E5%AF%B9%E8%B1%A1%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8EBlueStore/</id>
    <published>2020-12-26T16:00:00.000Z</published>
    <updated>2020-12-16T08:34:05.805Z</updated>
    
    <content type="html"><![CDATA[<div class="note note-primary">            <p>本blog包括理论和实践两个部分，实践部分需要您事先部署成功Ceph集群！</p><p>参考《Ceph设计与实现》谢型果等，第二章。以及<a href="https://docs.ceph.com/en/latest/rados/operations/bluestore-migration/">官方BlueStore教程</a>。</p><p>推荐博客<a href="http://www.itworld123.com/2019/06/04/storage/ceph/Ceph%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8EBlueStore%E7%AE%80%E6%9E%90/">Ceph存储引擎BlueStore简析</a></p>          </div><h1 id="下一代对象存储引擎BlueStore"><a href="#下一代对象存储引擎BlueStore" class="headerlink" title="下一代对象存储引擎BlueStore"></a>下一代对象存储引擎BlueStore</h1><p>相比于目前FileStore，BlueStore拥有无与伦比的优势：</p><ul><li>充分考虑下一代全SSD以及NVMe SSD闪存阵列的适配。例如将高效索引元数据的引擎由LevelDB替换为RocksDB。</li><li>传统的基于POSIX接口的FileStore需要通过操作系统自带的文件系统间接管理磁盘。BlueStore选择绕开文件系统，从而使得I/O路径大大减小。</li><li>在设计中将元素据和用户数据严格分离，因此元素据可以单独采用高速固态存储设备，诸如NVMe SSD，以实现性能加速。</li><li>与传统机械硬盘相比，SSD普遍采用4k 或者更大的块大小，因此采用位图进行管理可以获得更高的空间收益。</li></ul><h2 id="1-设计理念"><a href="#1-设计理念" class="headerlink" title="1 设计理念"></a>1 设计理念</h2><p>在存储系统中，所有读操作都是同步的，即除非在缓存命中，否则必须从磁盘中读到指定内容才向客户端返回。而写操作则不一样，一般处于效率考虑，所有写操作都会在内存中进行缓存，由文件系统进行组织后再批量写入磁盘。</p><p>数据可靠性：我们考虑写的期间发生断电的情况，因为内存是易失性的，所有数据会丢失。针对这个问题，有人提出用一个掉电不丢失的中间设备作为过渡设备，等数据写入普通磁盘后再释放中间设备上的空间，这个写中间设备的过程被称为<strong>写日志</strong>。中间设备被称为日志设备。但这样会消耗额外硬件资源。</p><p> 数据一致性：数据修改要么全部完成，要么没有变化（All or nothing）. 具体而言，我们用ACID（A: Atomicity, C: Consistency, I:Isolation, D:Durability）来描述这种系统，即<strong>事务型系统</strong>。</p><p><strong>术语</strong></p><p>块大小： 指对磁盘进行操作的最小粒度。 对普通机械硬盘为512字节，而SSD为4KB。</p><p>RMW：覆盖写。 如果本次改写的内容不足一个块，那么需要将对应的块读进来，将待修改的内容与原先内容进行合并。它的问题在于：额外的读惩罚，以及潜在的数据丢失风险。</p><p>COW：写时重定向。在磁盘分配新的空间，再写入，写完成后再释放旧数据。</p><h2 id="2-BlueStore写策略"><a href="#2-BlueStore写策略" class="headerlink" title="2 BlueStore写策略"></a>2 BlueStore写策略</h2><p>BlueStore综合运用了RMW和COW，任何一个写请求，根据磁盘块大小，分为三个部分，即首尾非块大小对齐部分和中间块大小对齐部分，针对两边RMW，针对中间采用COW。</p><p>BlueStore提供的读写访问接口都是基于PG粒度的。</p><h2 id="3-缓存替换机制"><a href="#3-缓存替换机制" class="headerlink" title="3 缓存替换机制"></a>3 缓存替换机制</h2><p>LRU算法：最近最少使用，时间局部性原理。</p><p>LFU算法：最近不经常使用，SDD访问模型。</p><p>ARC算法，同时考虑了LRU和LFU的长处，同时使用两个队列对缓存中页面进行管理：</p><ul><li>MRU (Most Recently Used) 队列保存最近访问过的页面</li><li><p>MFU（Most Frequently Used）队列保存最近一段时间<strong>至少被访问过两次</strong>的界面。</p></li><li><p>两个队列的长度是可变的，会根据请求队列的特征自动进行调整，取LRU和LFU共同之所长。</p><ul><li>当系统中请求序列呈现明显的时间局部性，MFU队列长度变为0，从而退化为LRU。</li><li>当系统中请求序列呈现明显的空间局部性，MRU队列长度变为0，从而退化为LFU。</li></ul></li></ul><p>2Q算法：双队列热点算法，一种针对数据库特别是关系数据库系统优化的缓存淘汰算法：</p><p>数据库系统由于需要保证每个操作的原子性，所以经常存在多个事务操作同一块热点数据的场景，因此针对数据库系统的缓存淘汰算法主要关注如何识别多个并发事务之间的数据相关性。</p><p>与ARC类似，2Q也使用了多个队列来管理整个缓存空间，分布称为$A1in,A1out,Am$。这些队列都是LRU队列，其中$A1in$与$Am$是真正的缓存队列，$A1out$是影子队列，i.e.只保存相关页面的管理结构。</p><ul><li>新的页面一开始总是被加入A1in，当某个页面被频繁访问，2Q认为这些访问是相关的，不会针对该页面执行任何热度提升的操作，直到其被正常淘汰至Aout。这个时间间隔被称为“相关时间间隔”。</li><li>当A1out中某个页面被再次访问时，2Q认为这些访问不再相关，此时执行页面热度提升，将其加入Am头部。Am队列中的页面再次被命中时，同样将其加入Am队列头部进行页面热度提升。从Am中淘汰的页面也进入A1out。这个时间间隔被称为“热度保留间隔”。</li></ul><h2 id="4-缓存管理"><a href="#4-缓存管理" class="headerlink" title="4 缓存管理"></a>4 缓存管理</h2><p>BlueStore 目前采用了LRU和2Q两种算法。</p><p>参考Theodore和Dennis的测试结论，推荐A1in和Am队列的容量配比1:1.</p><p>BlueStore的cache既可以用于缓存用户数据，也可以用于缓存元数据。bluestore中默认元数据的比重位90%。</p><p>BlueStore中元素据分为两类：Collection和Onode. Collection是PG在BlueStore中内存管理结构。每个OSD最多承载100个PG而且Collection管理结构本身比较小，故被设计成常驻内存。而Onode的数量和其管理的磁盘空间成正比，因而不可能常驻内存，需要引入淘汰机制。Onode采用LRU。</p><h2 id="5-BlueFS"><a href="#5-BlueFS" class="headerlink" title="5 BlueFS"></a>5 BlueFS</h2><p>诞生于2011年的LevelDB是基于Google的BigTable数据库系统发展而来。然而随着SSD普及，LevelDB无法发挥SSD全部性能，因而诞生了RocksDB。</p><ul><li><p>RocksDB适合存储小型或者中型键值对；性能随着键值对长度上升下降很快。</p></li><li><p>性能随CPU核数以及后端存储设备的I/O能力呈线性扩展。</p></li></ul><p>传统的本地文件系统（XFS，ext4，ZFS）等不能与RocksDB完全兼容，因而专门为其量身打造一款本地文件系统——BlueFS。在逻辑空间上分为三个层次 </p><p>（1）慢速空间 </p><p> 主要用于存储对象数据，可由大容量机械硬盘担任存储。</p><p>（2）高速空间（DB）</p><p>主要存储BlueStore内部的元素据，比如Onode。 可以由SSD提供。</p><p>（3）超高速（WAL）</p><p>WAL(Write Ahead Log)指日志。 可以由NVMe SSD或NVRAM等高速设备充当。</p><p>BlueFS上的磁盘数据包括文件、目录、日志三种类型。其定位文件分为两步：1. 通过<code>dir_map</code>找到文件的最底层文件夹 2.通过<code>file_map</code>找到对应的文件。其磁盘数据结构如下：</p><div class="table-container"><table><thead><tr><th style="text-align:center">成员</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">ino</td><td style="text-align:center">唯一标识一个fnode</td></tr><tr><td style="text-align:center">size</td><td style="text-align:center">文件大小</td></tr><tr><td style="text-align:center">mtime</td><td style="text-align:center">文件上一次被修改时间</td></tr><tr><td style="text-align:center">prefer_bdev</td><td style="text-align:center">存储该文件优先使用的设备</td></tr><tr><td style="text-align:center">extents</td><td style="text-align:center">磁盘上物理段集合包括{bdev，offset，length}</td></tr></tbody></table></div><p><img src="/img/image-20201202001057524.png" alt="image-20201202001057524"></p><h2 id="6-ObjectStore-OS"><a href="#6-ObjectStore-OS" class="headerlink" title="6 ObjectStore(OS)"></a>6 ObjectStore(OS)</h2><p>Ceph是一个指导原则是所有存储的不管是块设备、对象存储、文件存储最后都转化成了底层的对象object，这个object包含3个元素data，xattr，omap。data是保存对象的数据；xattr是保存对象的扩展属性，每个对象文件都可以设置文件的属性，这个属性是一个key/value值对，这类操作的特征是kv对并且与某一个Object关联，但是受到文件系统的限制，key/value对的个数和每个value的大小都进行了限制。如果要设置的对象的key/value不能存储在文件的扩展属性中；还存在另外一种方式保存omap(在Ceph中称为omap)，omap实际上是保存到了key/vaule  值对的RocksDB中，在这里value的值限制要比xattr中好的多。</p><p>对于FileStore实现，每个Object在FileStore层会被看成是一个文件，Object的属性(xattr)会利用文件的xattr属性存取，因为有些文件系统(如Ext4)对xattr的长度有限制，因此超出长度的Metadata会被存储在DBObjectMap里。而Object的omap则直接利用DBObjectMap实现。因此，可以看出xattr和omap操作是互通的，在用户角度来说，前者可以看作是受限的长度，后者更宽泛(API没有对这些做出硬性要求)。目前纠删码还不支持omap。</p><p>而在BlueStore则没有这种限制。</p><hr><h1 id="部署和操作BlueStore"><a href="#部署和操作BlueStore" class="headerlink" title="部署和操作BlueStore"></a>部署和操作BlueStore</h1><h1 id="BLUESTORE迁移"><a href="#BLUESTORE迁移" class="headerlink" title="BLUESTORE迁移"></a>BLUESTORE迁移</h1><p>每个OSD都可以运行BlueStore或FileStore，并且单个Ceph集群可以包含两者的混合。先前已部署FileStore的用户可能希望过渡到BlueStore，以利用改进的性能和健壮性。有几种策略可以实现这种过渡。</p><p>单个OSD不能单独进行原地转换，但是：BlueStore和FileStore根本不同，以致于无法实用。“转换”将依靠群集的正常复制和修复支持，或者依靠将OSD内容从旧的（FileStore）设备复制到新的（BlueStore）设备的工具和策略。</p><h2 id="部署新的OSD与BLUESTORE"><a href="#部署新的OSD与BLUESTORE" class="headerlink" title="部署新的OSD与BLUESTORE"></a>部署新的OSD与BLUESTORE</h2><p>可以使用BlueStore部署任何新的OSD（例如，在扩展群集时）。这是默认行为，因此不需要进行特定更改。</p><p>同样，更换故障驱动器后重新配置的任何OSD都可以使用BlueStore。</p><h2 id="将现有的OSD"><a href="#将现有的OSD" class="headerlink" title="将现有的OSD"></a>将现有的OSD</h2><h3 id="标记并替换"><a href="#标记并替换" class="headerlink" title="标记并替换"></a>标记并替换</h3><p>最简单的方法是依次标记每个设备，等待数据在群集中复制，重新配置OSD，然后再次将其标记回。它很容易实现自动化。但是，它需要的数据迁移量超出了必要，因此不是最佳选择。</p><ol><li><p>确定要替换的FileStore OSD：</p><pre><code class="hljs ini"><span class="hljs-attr">ID</span>=&lt;osd-id-number&gt;<span class="hljs-attr">DEVICE</span>=&lt;disk-device&gt;</code></pre><p>您可以使用以下命令判断给定的OSD是FileStore还是BlueStore：</p><pre><code class="hljs perl">ceph osd metadata $ID | <span class="hljs-keyword">grep</span> osd_objectstore</code></pre><p>您可以使用以下命令获取文件存储与bluestore的当前计数：</p><pre><code class="hljs applescript">ceph osd <span class="hljs-built_in">count</span>-metadata osd_objectstore</code></pre></li><li><p>将文件存储OSD标记为：</p><pre><code class="hljs nginx"><span class="hljs-attribute">ceph</span> osd out <span class="hljs-variable">$ID</span></code></pre></li><li><p>等待数据从有问题的OSD迁移：</p><pre><code class="hljs bash"><span class="hljs-keyword">while</span> ! ceph osd safe-to-destroy <span class="hljs-variable">$ID</span> ; <span class="hljs-keyword">do</span> sleep 60 ; <span class="hljs-keyword">done</span></code></pre></li><li><p>停止OSD：</p><pre><code class="hljs bash">systemctl <span class="hljs-built_in">kill</span> ceph-osd@<span class="hljs-variable">$ID</span></code></pre></li><li><p>记下此OSD使用的设备：</p><pre><code class="hljs crystal">mount | grep /var/<span class="hljs-class"><span class="hljs-keyword">lib</span>/<span class="hljs-title">ceph</span>/<span class="hljs-title">osd</span>/<span class="hljs-title">ceph</span>-$<span class="hljs-title">ID</span></span></code></pre></li><li><p>卸载OSD：</p><pre><code class="hljs crystal">umount /var/<span class="hljs-class"><span class="hljs-keyword">lib</span>/<span class="hljs-title">ceph</span>/<span class="hljs-title">osd</span>/<span class="hljs-title">ceph</span>-$<span class="hljs-title">ID</span></span></code></pre></li><li><p>销毁OSD数据。请<em>格外小心，</em>因为这会破坏设备的内容；在继续操作之前，请确保不需要设备上的数据（即，群集运行状况良好）。</p><pre><code class="hljs dockerfile">ceph-<span class="hljs-keyword">volume</span><span class="bash"> lvm zap <span class="hljs-variable">$DEVICE</span></span></code></pre></li><li><p>告诉集群OSD已被破坏（并且可以使用相同的ID重新配置新的OSD）：</p><pre><code class="hljs nginx"><span class="hljs-attribute">ceph</span> osd destroy <span class="hljs-variable">$ID</span> --<span class="hljs-literal">yes</span>-i-really-mean-it</code></pre></li><li><p>使用相同的OSD ID在其位置重新配置BlueStore OSD。这要求您确实根据上面看到的内容确定要擦除的设备。小心！</p><pre><code class="hljs dockerfile">ceph-<span class="hljs-keyword">volume</span><span class="bash"> lvm create --bluestore --data <span class="hljs-variable">$DEVICE</span> --osd-id <span class="hljs-variable">$ID</span></span></code></pre></li><li><p>重复。</p></li></ol><p>您可以允许替换OSD的重新填充与下一个OSD的排空同时进行，或者对多个OSD并行执行相同的步骤，只要确保在销毁群集之前群集是完全干净的（所有数据具有所有副本）即可。任何OSD。否则，将减少数据的冗余，并增加（甚至可能导致）数据丢失的风险。</p><p>优点：</p><ul><li>简单。</li><li>可以逐个设备完成。</li><li>不需要备用设备或主机。</li></ul><p>缺点：</p><ul><li>数据通过网络复制了两次：一次复制到集群中的其他OSD（以保持所需的副本数），然后再次返回到重新配置的BlueStore OSD。</li></ul><h3 id="整个主机更换"><a href="#整个主机更换" class="headerlink" title="整个主机更换"></a>整个主机更换</h3><p>如果集群中有一个备用主机，或者有足够的可用空间来疏散整个主机以用作备用主机，则可以在每个主机的基础上使用存储的每个数据副本进行转换仅迁移一次。</p><p>首先，您需要有一个没有数据的空主机。有两种方法可以执行此操作：从尚未包含在群集中的新的空主机开始，或者从群集中现有主机上卸载数据。</p><h4 id="使用新的，空的主机"><a href="#使用新的，空的主机" class="headerlink" title="使用新的，空的主机"></a>使用新的，空的主机</h4><p>理想情况下，主机应具有与将要转换的其他主机大致相同的容量（尽管并不严格）。</p><pre><code class="hljs ini"><span class="hljs-attr">NEWHOST</span>=&lt;empty-host-name&gt;</code></pre><p>将主机添加到CRUSH层次结构，但不要将其附加到根目录：</p><pre><code class="hljs smali">ceph osd crush<span class="hljs-built_in"> add-bucket </span>$NEWHOST host</code></pre><p>确保已安装ceph软件包。</p><h4 id="使用现有的主机"><a href="#使用现有的主机" class="headerlink" title="使用现有的主机"></a>使用现有的主机</h4><p>如果要使用已经是群集一部分的现有主机，并且该主机上有足够的可用空间，以便可以迁移其所有数据，则可以执行以下操作：</p><pre><code class="hljs autoit">OLDHOST=&lt;existing-cluster-host-<span class="hljs-keyword">to</span>-offload&gt;ceph osd crush unlink $OLDHOST <span class="hljs-keyword">default</span></code></pre><p>其中“默认”是CRUSH地图中的直接祖先。（对于具有未修改配置的较小群集，通常将是“默认”，但也可能是机架名称。）现在，您应该在OSD树输出的顶部看到没有父节点的主机：</p><pre><code class="hljs lsl">$ bin/ceph osd treeID CLASS WEIGHT  TYPE NAME     STATUS REWEIGHT PRI-AFF<span class="hljs-number">-5</span>             <span class="hljs-number">0</span> host oldhost<span class="hljs-number">10</span>   ssd <span class="hljs-number">1.00000</span>     osd<span class="hljs-number">.10</span>        up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><span class="hljs-number">11</span>   ssd <span class="hljs-number">1.00000</span>     osd<span class="hljs-number">.11</span>        up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><span class="hljs-number">12</span>   ssd <span class="hljs-number">1.00000</span>     osd<span class="hljs-number">.12</span>        up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><span class="hljs-number">-1</span>       <span class="hljs-number">3.00000</span> root <span class="hljs-section">default</span><span class="hljs-number">-2</span>       <span class="hljs-number">3.00000</span>     host foo <span class="hljs-number">0</span>   ssd <span class="hljs-number">1.00000</span>         osd<span class="hljs-number">.0</span>     up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span> <span class="hljs-number">1</span>   ssd <span class="hljs-number">1.00000</span>         osd<span class="hljs-number">.1</span>     up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span> <span class="hljs-number">2</span>   ssd <span class="hljs-number">1.00000</span>         osd<span class="hljs-number">.2</span>     up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span>...</code></pre><p>如果一切正常，请直接跳到下面的“等待数据迁移完成”步骤，然后从那里继续进行操作以清理旧的OSD。</p><h4 id="迁移过程"><a href="#迁移过程" class="headerlink" title="迁移过程"></a>迁移过程</h4><p>如果您使用的是新主机，请从步骤1开始。对于现有主机，请跳至下面的步骤5。</p><ol><li><p>为所有设备配置新的BlueStore OSD：</p><pre><code class="hljs awk">ceph-volume lvm create --bluestore --data <span class="hljs-regexp">/dev/</span><span class="hljs-variable">$DEVICE</span></code></pre></li><li><p>验证OSD通过以下方式加入集群：</p><pre><code class="hljs dos">ceph osd <span class="hljs-built_in">tree</span></code></pre><p>您应该看到新主机<code>$NEWHOST</code>与它下面的所有的OSD的，但主机应该<em>不</em>被嵌套任何其他节点下的层次结构（像）。例如，如果是空主机，则可能会看到以下内容：<code>root default``newhost</code></p><pre><code class="hljs lsl">$ bin/ceph osd treeID CLASS WEIGHT  TYPE NAME     STATUS REWEIGHT PRI-AFF<span class="hljs-number">-5</span>             <span class="hljs-number">0</span> host newhost<span class="hljs-number">10</span>   ssd <span class="hljs-number">1.00000</span>     osd<span class="hljs-number">.10</span>        up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><span class="hljs-number">11</span>   ssd <span class="hljs-number">1.00000</span>     osd<span class="hljs-number">.11</span>        up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><span class="hljs-number">12</span>   ssd <span class="hljs-number">1.00000</span>     osd<span class="hljs-number">.12</span>        up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span><span class="hljs-number">-1</span>       <span class="hljs-number">3.00000</span> root <span class="hljs-section">default</span><span class="hljs-number">-2</span>       <span class="hljs-number">3.00000</span>     host oldhost1 <span class="hljs-number">0</span>   ssd <span class="hljs-number">1.00000</span>         osd<span class="hljs-number">.0</span>     up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span> <span class="hljs-number">1</span>   ssd <span class="hljs-number">1.00000</span>         osd<span class="hljs-number">.1</span>     up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span> <span class="hljs-number">2</span>   ssd <span class="hljs-number">1.00000</span>         osd<span class="hljs-number">.2</span>     up  <span class="hljs-number">1.00000</span> <span class="hljs-number">1.00000</span>...</code></pre></li><li><p>确定要转换的第一个目标主机</p><pre><code class="hljs ini"><span class="hljs-attr">OLDHOST</span>=&lt;existing-cluster-host-to-convert&gt;</code></pre></li><li><p>将新主机交换到群集中旧主机的位置：</p><pre><code class="hljs nginx"><span class="hljs-attribute">ceph</span> osd crush swap-bucket <span class="hljs-variable">$NEWHOST</span> <span class="hljs-variable">$OLDHOST</span></code></pre><p>此时，所有数据<code>$OLDHOST</code>将开始迁移到上的OSD <code>$NEWHOST</code>。如果新旧主机的总容量不同，您可能还会看到一些数据迁移到集群中的其他节点或从集群的其他节点迁移，但是只要这些主机的大小相同，这将是相对少量的数据。</p></li><li><p>等待数据迁移完成：</p><pre><code class="hljs reasonml"><span class="hljs-keyword">while</span> ! ceph osd safe-<span class="hljs-keyword">to</span>-destroy <span class="hljs-constructor">$(<span class="hljs-params">ceph</span> <span class="hljs-params">osd</span> <span class="hljs-params">ls</span>-<span class="hljs-params">tree</span> $OLDHOST)</span>; <span class="hljs-keyword">do</span> sleep <span class="hljs-number">60</span> ; <span class="hljs-keyword">done</span></code></pre></li><li><p>停止所有空的旧OSD <code>$OLDHOST</code>：</p><pre><code class="hljs crystal">ssh $OLDHOSTsystemctl kill ceph-osd.targetumount /var/<span class="hljs-class"><span class="hljs-keyword">lib</span>/<span class="hljs-title">ceph</span>/<span class="hljs-title">osd</span>/<span class="hljs-title">ceph</span>-*</span></code></pre></li><li><p>销毁并清除旧的OSD：</p><pre><code class="hljs nginx">for osd in `ceph osd ls-tree $OLDHOST`; do    <span class="hljs-attribute">ceph</span> osd purge <span class="hljs-variable">$osd</span> --<span class="hljs-literal">yes</span>-i-really-mean-itdone</code></pre></li><li><p>擦拭旧的OSD设备。这要求您确定要手动擦除哪些设备（请小心！）。对于每个设备：</p><pre><code class="hljs dockerfile">ceph-<span class="hljs-keyword">volume</span><span class="bash"> lvm zap <span class="hljs-variable">$DEVICE</span></span></code></pre></li><li><p>将现在为空的主机用作新主机，然后重复：</p><pre><code class="hljs ini"><span class="hljs-attr">NEWHOST</span>=<span class="hljs-variable">$OLDHOST</span></code></pre></li></ol><p>优点：</p><ul><li>数据只能通过网络复制一次。</li><li>一次转换整个主机的OSD。</li><li>可以并行转换为一次转换多个主机。</li><li>每个主机上都不需要备用设备。</li></ul><p>缺点：</p><ul><li>需要备用主机。</li><li>整个主机的OSD值将同时迁移数据。这很可能会影响整个群集的性能。</li><li>所有迁移的数据仍然在网络上进行了一整跳。</li></ul><h3 id="每OSD设备副本"><a href="#每OSD设备副本" class="headerlink" title="每OSD设备副本"></a>每OSD设备副本</h3><p>可以使用的<code>copy</code>功能转换单个逻辑OSD <code>ceph-objectstore-tool</code>。这要求主机具有一个或多个空闲设备来供应新的空BlueStore OSD。例如，如果群集中的每个主机都有12个OSD，则需要第13个可用设备，以便可以依次转换每个OSD，然后再收回旧设备以转换下一个OSD。</p><p>注意事项：</p><ul><li>此策略要求准备一个空白的BlueStore OSD，而无需分配该<code>ceph-volume</code> 工具不支持的新OSD ID 。更重要的是，<em>dmcrypt</em>的设置与OSD身份紧密相关，这意味着该方法不适用于加密的OSD。</li><li>设备必须手动分区。</li><li>工具未实现！</li><li>没有记录！</li></ul><p>优点：</p><ul><li>在转换期间，很少或没有数据在网络上迁移。</li></ul><p>缺点：</p><ul><li>工具尚未完全实现。</li><li>流程未记录。</li><li>每个主机必须具有备用或空设备。</li><li>OSD在转换过程中处于脱机状态，这意味着新的写入操作将仅写入OSD的一部分。这会增加由于后续故障而导致数据丢失的风险。（但是，如果在转换完成之前出现故障，则可以启动原始FileStore OSD来提供对其原始数据的访问。）</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note note-primary&quot;&gt;
            &lt;p&gt;本blog包括理论和实践两个部分，实践部分需要您事先部署成功Ceph集群！&lt;/p&gt;&lt;p&gt;参考《Ceph设计与实现》谢型果等，第二章。以及&lt;a href=&quot;https://docs.cep</summary>
      
    
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/categories/ceph/"/>
    
    <category term="bluestore" scheme="http://durantthorvalds.top/categories/ceph/bluestore/"/>
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/tags/ceph/"/>
    
    <category term="理论" scheme="http://durantthorvalds.top/tags/%E7%90%86%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>「参考」Ceph配置参数conf</title>
    <link href="http://durantthorvalds.top/2020/12/15/Ceph%20%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/"/>
    <id>http://durantthorvalds.top/2020/12/15/Ceph%20%E9%85%8D%E7%BD%AE%E5%8F%82%E6%95%B0/</id>
    <published>2020-12-15T08:00:00.000Z</published>
    <updated>2020-12-16T08:33:05.680Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ceph-配置参数"><a href="#Ceph-配置参数" class="headerlink" title="Ceph 配置参数"></a>Ceph 配置参数</h1><blockquote><p>涉及pool, PG, CRUSH的配置参数。</p><p>参考<a href="https://docs.ceph.com/en/latest/rados/configuration/pool-pg-config-ref/">官方文档</a></p></blockquote><p>一个典型的Ceph配置文件如下：</p><pre><code class="hljs routeros">[global]# By default, Ceph makes 3 replicas of objects. <span class="hljs-keyword">If</span> you want <span class="hljs-keyword">to</span> make four# copies of an object the<span class="hljs-built_in"> default </span>value--a primary copy <span class="hljs-keyword">and</span> three replica# copies--reset the<span class="hljs-built_in"> default </span>values as shown <span class="hljs-keyword">in</span> <span class="hljs-string">&#x27;osd pool default size&#x27;</span>.# <span class="hljs-keyword">If</span> you want <span class="hljs-keyword">to</span> allow Ceph <span class="hljs-keyword">to</span> write a lesser number of copies <span class="hljs-keyword">in</span> a degraded# state, <span class="hljs-builtin-name">set</span> <span class="hljs-string">&#x27;osd pool default min size&#x27;</span> <span class="hljs-keyword">to</span> a number less than the# <span class="hljs-string">&#x27;osd pool default size&#x27;</span> value.osd<span class="hljs-built_in"> pool default </span>size = 3  # Write an object 3 times.osd<span class="hljs-built_in"> pool default </span>min size = 2 # Allow writing two copies <span class="hljs-keyword">in</span> a degraded state.# Ensure you have a realistic number of placement groups. We recommend# approximately 100 per OSD. E.g., total number of OSDs multiplied by 100# divided by the number of replicas (i.e., osd<span class="hljs-built_in"> pool default </span>size). So <span class="hljs-keyword">for</span># 10 OSDs <span class="hljs-keyword">and</span> osd<span class="hljs-built_in"> pool default </span>size = 4, we<span class="hljs-string">&#x27;d recommend approximately</span><span class="hljs-string"># (100 * 10) / 4 = 250.</span><span class="hljs-string">        # always use the nearest power of 2</span><span class="hljs-string"></span><span class="hljs-string">osd pool default pg num = 256</span><span class="hljs-string">osd pool default pgp num = 256</span></code></pre><div class="note note-primary">            <p>笔者注：</p><p>关于PG和PGP：</p><ul><li><p>PG =放置组( Placement Group)<br>PGP =用于放置的放置组(Placement Group for Placement purpose)</p><p>pg_num = 映射到OSD的PG的数量，它必须是2的幂次。</p><p>当对任何一个池增加pg_num时，该池的每个PG都会分裂成一半，但它们都将始终映射到其父OSD。</p><p>在此之前，Ceph不会开始重新平衡。 现在，当您为同一池增加pgp_num值时，PG开始从父级迁移到其他OSD，并且群集重新平衡开始。 这就是PGP扮演重要角色的方式。</p></li></ul>          </div><hr><blockquote><p>标记为※的是笔者认为比较重要的或者需要重点理解的配置项。供参考。</p></blockquote><h2 id="PG"><a href="#PG" class="headerlink" title="PG"></a>PG</h2><h3 id="※mon-max-pool-pg-num"><a href="#※mon-max-pool-pg-num" class="headerlink" title="※mon max pool pg num"></a>※mon max pool pg num</h3><ul><li><p>描述</p><p>每个池的最大放置组数。</p></li><li><p>类型</p><p>整数</p></li><li><p>默认</p><p><code>65536</code></p></li></ul><h3 id="※mon-pg-create-interval"><a href="#※mon-pg-create-interval" class="headerlink" title="※mon pg create interval"></a>※mon pg create interval</h3><ul><li><p>描述</p><p>在同一Ceph OSD守护进程中创建PG之间的秒数。[interval含义参考PG那篇博文]</p></li><li><p>类型</p><p>浮动</p></li><li><p>默认</p><p><code>30.0</code></p></li></ul><h3 id="mon-pg-stuck-threshold"><a href="#mon-pg-stuck-threshold" class="headerlink" title="mon pg stuck threshold"></a>mon pg stuck threshold</h3><ul><li><p>描述</p><p>PG被认为阻塞的秒数。</p></li><li><p>类型</p><p>32位整数</p></li><li><p>默认</p><p><code>300</code></p></li></ul><h3 id="mon-pg-min-inactive"><a href="#mon-pg-min-inactive" class="headerlink" title="mon pg min inactive"></a>mon pg min inactive</h3><ul><li><p>描述</p><p>如果PG保持不活动状态的时间<code>mon_pg_stuck_threshold</code>超过此设置的时间，将在群集日志中发出一个<code>HEALTH_ERR</code>信号。非正数表示禁用。</p></li><li><p>类型</p><p>整数</p></li><li><p>默认</p><p><code>1</code></p></li></ul><h3 id="mon-pg-warn-min-per-osd"><a href="#mon-pg-warn-min-per-osd" class="headerlink" title="mon pg warn min per osd"></a>mon pg warn min per osd</h3><ul><li><p>描述</p><p>如果每个OSD中的PG的平均数量低于此数量，则在群集日志中发出 <code>HEALTH_WARN</code>。（非正数禁用此功能）</p></li><li><p>类型</p><p>整数</p></li><li><p>默认</p><p><code>30</code></p></li></ul><h3 id="mon-pg-warn-min-objects"><a href="#mon-pg-warn-min-objects" class="headerlink" title="mon pg warn min objects"></a>mon pg warn min objects</h3><ul><li><p>描述</p><p>如果群集中的对象总数低于此数目，则不发出警告</p></li><li><p>类型</p><p>整数</p></li><li><p>默认</p><p><code>1000</code></p></li></ul><h3 id="mon-pg-warn-min-pool-objects"><a href="#mon-pg-warn-min-pool-objects" class="headerlink" title="mon pg warn min pool objects"></a>mon pg warn min pool objects</h3><ul><li><p>描述</p><p>对象号低于此数字的池不发出警告</p></li><li><p>类型</p><p>整数</p></li><li><p>默认</p><p><code>1000</code></p></li></ul><h3 id="mon-pg-check-down-all-threshold"><a href="#mon-pg-check-down-all-threshold" class="headerlink" title="mon pg check down all threshold"></a>mon pg check down all threshold</h3><ul><li><p>描述</p><p>降低OSD百分比的阈值之后，我们将检查所有PG的陈旧状态。</p></li><li><p>类型</p><p>浮动</p></li><li><p>默认</p><p><code>0.5</code></p></li></ul><h3 id="mon-pg-warn-max-object-skew"><a href="#mon-pg-warn-max-object-skew" class="headerlink" title="mon pg warn max object skew"></a>mon pg warn max object skew</h3><ul><li><p>描述</p><p>如果某个特定池的平均对象数大于整个池的平均对象数，在群集日志中发出<code>HEALTH_WARN</code> 。（零或非正数将禁用此功能）。请注意，此选项适用于管理者。<code>mon pg warn max object skew</code></p></li><li><p>类型</p><p>浮动</p></li><li><p>默认</p><p><code>10</code></p></li></ul><h3 id="mon-delta-reset-interval"><a href="#mon-delta-reset-interval" class="headerlink" title="mon delta reset interval"></a>mon delta reset interval</h3><ul><li><p>描述</p><p>在将pg delta重置为0之前，处于非活动状态的秒数。我们跟踪每个池的已用空间的delta，因此，例如，对于我们来说，更容易理解恢复的进度或缓存层的性能。但是，如果没有报告某个池的活动，我们只需重置该池的增量历史记录即可。</p></li><li><p>类型</p><p>整数</p></li><li><p>默认</p><p><code>10</code></p></li></ul><h3 id="mon-osd-max-op-age"><a href="#mon-osd-max-op-age" class="headerlink" title="mon osd max op age"></a>mon osd max op age</h3><ul><li><p>描述</p><p>关注之前的最大操作年龄（使其为2的幂）。如果请求被阻止的时间超过此限制，则将发出<code>HEALTH_WARN</code>。</p></li><li><p>类型</p><p>浮动</p></li><li><p>默认</p><p><code>32.0</code></p></li></ul><h2 id="OSD"><a href="#OSD" class="headerlink" title="OSD"></a>OSD</h2><h3 id="osd-pg-bits"><a href="#osd-pg-bits" class="headerlink" title="osd pg bits"></a>osd pg bits</h3><ul><li><p>描述</p><p>每个Ceph OSD守护程序的放置组位数。</p></li><li><p>类型</p><p>32位整数</p></li><li><p>默认</p><p><code>6</code></p></li></ul><h3 id="osd-pgp-bits"><a href="#osd-pgp-bits" class="headerlink" title="osd pgp bits"></a>osd pgp bits</h3><ul><li><p>描述</p><p>PGP的每个Ceph OSD守护程序的位数。</p></li><li><p>类型</p><p>32位整数</p></li><li><p>默认</p><p><code>6</code></p></li></ul><h3 id="※osd-crush-chooseleaf-type"><a href="#※osd-crush-chooseleaf-type" class="headerlink" title="※osd crush chooseleaf type"></a>※osd crush chooseleaf type</h3><ul><li><p>描述</p><p><code>chooseleaf</code>在CRUSH规则中使用的存储桶类型。使用顺序等级而不是名称。</p></li><li><p>类型</p><p>32位整数</p></li><li><p>默认</p><p><code>1</code>。通常，一台主机包含一个或多个Ceph OSD守护程序。</p></li></ul><h3 id="※osd-crush-initial-weight"><a href="#※osd-crush-initial-weight" class="headerlink" title="※osd crush initial weight"></a>※osd crush initial weight</h3><ul><li><p>描述</p><p>将新添加的osds的初始权重添加到crushmap中。【参考crush那篇文章】</p></li><li><p>类型</p><p>双</p></li><li><p>默认</p><p><code>the size of newly added osd in TB</code>。默认情况下，新添加的osd的初始压缩重量设置为以TB为单位的卷大小。有关详细信息，请参见对<a href="https://docs.ceph.com/en/latest/rados/operations/crush-map#weightingbucketitems">存储桶项目</a>进行<a href="https://docs.ceph.com/en/latest/rados/operations/crush-map#weightingbucketitems">加权</a>。</p></li></ul><h3 id="※osd-pool-default-crush-rule"><a href="#※osd-pool-default-crush-rule" class="headerlink" title="※osd pool default crush rule"></a>※osd pool default crush rule</h3><ul><li><p>描述</p><p>创建复制池时要使用的默认CRUSH规则。</p></li><li><p>类型</p><p>8位整数</p></li><li><p>默认</p><p><code>-1</code>，这意味着“<strong>选择数字ID最低的规则并使用它</strong>”。这是为了在没有规则0的情况下创建池。</p></li></ul><h3 id="※osd-pool-erasure-code-stripe-unit"><a href="#※osd-pool-erasure-code-stripe-unit" class="headerlink" title="※osd pool erasure code stripe unit"></a>※osd pool erasure code stripe unit</h3><ul><li><p>描述</p><p>设置用于纠删码池的对象条带块的默认大小（以字节为单位）。每个大小为S的对象将存储为N条，每个数据块接收字节。每个字节的条带<code>N*strip_unit</code>将分别进行编码/解码。可以通过纠删码配置文件中的设置<code>strip_unit</code>来覆盖此选项 。</p></li><li><p>类型</p><p>无符号32位整数</p></li><li><p>默认</p><p><code>4096</code></p></li></ul><h3 id="※osd-pool-default-size"><a href="#※osd-pool-default-size" class="headerlink" title="※osd pool default size"></a>※osd pool default size</h3><ul><li><p>描述</p><p>设置池中对象的副本数。预设值与相同 。<code>ceph osd pool set &#123;pool-name&#125; size &#123;size&#125;</code></p></li><li><p>类型</p><p>32位整数</p></li><li><p>默认</p><p><code>3</code></p></li></ul><h3 id="※osd-pool-default-min-size"><a href="#※osd-pool-default-min-size" class="headerlink" title="※osd pool default min size"></a>※osd pool default min size</h3><ul><li><p>描述</p><p>设置池中对象的最小写入副本数，以确认对客户端的写入操作。如果未达到最小值，则Ceph将不会确认对客户端的写入，<strong>这可能会导致数据丢失</strong>。在<code>degraded</code>模式下运行时，此设置可确保最少数量的副本。</p></li><li><p>类型</p><p>32位整数</p></li><li><p>默认</p><p><code>0</code>，表示没有特别的下限。如果<code>0</code>，最小值为。<code>size - (size / 2)</code></p></li></ul><h3 id="※osd-pool-default-pg-num"><a href="#※osd-pool-default-pg-num" class="headerlink" title="※osd pool default pg num"></a>※osd pool default pg num</h3><ul><li><p>描述</p><p>池的默认放置组数。默认值是一样<code>pg_num</code>用<code>mkpool</code>。</p></li><li><p>类型</p><p>32位整数</p></li><li><p>默认</p><p><code>32</code></p></li></ul><h3 id="osd-pool-default-pgp-num"><a href="#osd-pool-default-pgp-num" class="headerlink" title="osd pool default pgp num"></a>osd pool default pgp num</h3><ul><li><p>描述</p><p>池放置的默认放置组数。默认值是一样<code>pgp_num</code>用<code>mkpool</code>。PG和PGP应该相等（目前）。</p></li><li><p>类型</p><p>32位整数</p></li><li><p>默认</p><p><code>8</code></p></li></ul><h3 id="osd-pool-default-flags"><a href="#osd-pool-default-flags" class="headerlink" title="osd pool default flags"></a>osd pool default flags</h3><ul><li><p>描述</p><p>新池的默认标志。</p></li><li><p>类型</p><p>32位整数</p></li><li><p>默认</p><p><code>0</code></p></li></ul><h3 id="osd-max-pgls"><a href="#osd-max-pgls" class="headerlink" title="osd max pgls"></a>osd max pgls</h3><ul><li><p>描述</p><p>要列出的展示位置组的最大数量。请求大量请求的客户端可以占用Ceph OSD守护程序。</p></li><li><p>类型</p><p>无符号64位整数</p></li><li><p>默认</p><p><code>1024</code></p></li><li><p>注意</p><p>默认应该没问题。</p></li></ul><h3 id="osd-min-pg-log-entries"><a href="#osd-min-pg-log-entries" class="headerlink" title="osd min pg log entries"></a>osd min pg log entries</h3><ul><li><p>描述</p><p>修剪日志文件时要保留的最小放置组日志数。</p></li><li><p>类型</p><p>32位Int Unsigned</p></li><li><p>默认</p><p><code>250</code></p></li></ul><h3 id="osd-max-pg-log-entries"><a href="#osd-max-pg-log-entries" class="headerlink" title="osd max pg log entries"></a>osd max pg log entries</h3><ul><li><p>描述</p><p>修剪日志文件时要保留的放置组日志的最大数量。</p></li><li><p>类型</p><p>32位Int Unsigned</p></li><li><p>默认</p><p><code>10000</code></p></li></ul><h3 id="osd-default-data-pool-replay-window"><a href="#osd-default-data-pool-replay-window" class="headerlink" title="osd default data pool replay window"></a>osd default data pool replay window</h3><ul><li><p>描述</p><p>OSD等待客户端重播请求的时间（以秒为单位）。</p></li><li><p>类型</p><p>32位整数</p></li><li><p>默认</p><p><code>45</code></p></li></ul><h3 id="osd-max-pg-per-osd-hard-ratio"><a href="#osd-max-pg-per-osd-hard-ratio" class="headerlink" title="osd max pg per osd hard ratio"></a>osd max pg per osd hard ratio</h3><ul><li><p>描述</p><p>在OSD拒绝创建新PG之前，集群允许的每个OSD PG数量的比率。如果OSD服务的PG数量超过<code>osd max pg per osd hard ratio*mon max pg per osd</code>，则OSD停止创建新的PG 。</p></li><li><p>类型</p><p>浮动</p></li><li><p>默认</p><p><code>2</code></p></li></ul><h3 id="※osd-recovery-priority"><a href="#※osd-recovery-priority" class="headerlink" title="※osd recovery priority"></a>※osd recovery priority</h3><ul><li><p>描述</p><p>工作队列中恢复的优先级。</p></li><li><p>类型</p><p>整数</p></li><li><p>默认</p><p><code>5</code></p></li></ul><h3 id="※osd-recovery-op-priority"><a href="#※osd-recovery-op-priority" class="headerlink" title="※osd recovery op priority"></a>※osd recovery op priority</h3><ul><li><p>描述</p><p>如果不覆盖池，则用于恢复操作的默认优先级。</p></li><li><p>类型</p><p>整数</p></li><li><p>默认</p><p><code>3</code></p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Ceph-配置参数&quot;&gt;&lt;a href=&quot;#Ceph-配置参数&quot; class=&quot;headerlink&quot; title=&quot;Ceph 配置参数&quot;&gt;&lt;/a&gt;Ceph 配置参数&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;涉及pool, PG, CRUSH的配置参数。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/categories/ceph/"/>
    
    <category term="PG" scheme="http://durantthorvalds.top/categories/ceph/PG/"/>
    
    
    <category term="Ceph字典" scheme="http://durantthorvalds.top/tags/Ceph%E5%AD%97%E5%85%B8/"/>
    
  </entry>
  
  <entry>
    <title>「核心」Ceph学习三部曲之三:迁移之美——PG读写流程与状态迁移详解</title>
    <link href="http://durantthorvalds.top/2020/12/15/%E8%BF%81%E7%A7%BB%E4%B9%8B%E7%BE%8EPG%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B%E4%B8%8E%E7%8A%B6%E6%80%81%E8%BF%81%E7%A7%BB%E8%AF%A6%E8%A7%A3/"/>
    <id>http://durantthorvalds.top/2020/12/15/%E8%BF%81%E7%A7%BB%E4%B9%8B%E7%BE%8EPG%E8%AF%BB%E5%86%99%E6%B5%81%E7%A8%8B%E4%B8%8E%E7%8A%B6%E6%80%81%E8%BF%81%E7%A7%BB%E8%AF%A6%E8%A7%A3/</id>
    <published>2020-12-14T16:00:00.000Z</published>
    <updated>2020-12-16T08:32:55.534Z</updated>
    
    <content type="html"><![CDATA[<h1 id="迁移之美——PG读写流程与状态迁移详解"><a href="#迁移之美——PG读写流程与状态迁移详解" class="headerlink" title="迁移之美——PG读写流程与状态迁移详解"></a>迁移之美——PG读写流程与状态迁移详解</h1><div class="note note-primary">            <p>本blog包括理论和实践两个部分，实践部分需要您事先部署成功Ceph集群！由于篇幅较大，建议先看看完理论部分的术语再看官方实践部分，最后到理论部分搜索关键字进行理解。</p><p>参考《Ceph设计与实现》谢型果等，第四章。以及<a href="https://docs.ceph.com/en/latest/rados/operations/placement-groups/">官方PG教程</a>。</p>          </div><h1 id="1-基本概念"><a href="#1-基本概念" class="headerlink" title="1 基本概念"></a>1 基本概念</h1><p>PG是Ceph最难理解的部分之一，但是它也是Ceph最精妙有意思的部分。</p><p>Placement Groups。即归置组（又称放置组）。Ceph对所有的存储资源都进行池化管理，对对象进行两级映射存储$Objects\rightarrow PGs \rightarrow OSDs $</p><ul><li><p>第一级映射是静态的，负责将任何前端类型的应用数据按照固定大小进行切割、编号后作为随机哈希函数输入，均匀映射至PG，以实现负载均衡。</p></li><li><p>第二级映射实现PG到OSD的映射。</p></li></ul><p>PG最引人关注的特性是它可以在OSD之间自由的迁移，这是Ceph赖以实现自动数据恢复、自动数据平衡等高级特性的基础。因为PG的数量远小于对象的数量，因此以PG为单位进行操作更具灵活性。</p><p><img src="/img/ceph-arch.png" alt=""></p><p>存储池中的对象到OSD的映射是通过PG来完成。一方面，存储池中PG数目决定了其并发处理多个对象的能力；另一方面，过多的PG会消耗大量CPU，同时容易使得磁盘长期处于过载状态。（经验表明：磁盘利用率保持在70%左右可以使得I/O并发能力和平均相应时延最佳）。</p><p>因此在创建存储池时，需要合理的指定PG的数目，一般将每个OSD中PG限制在100个左右最佳。</p><p>需要注意的是，创建存储池中指定的PG数目其实是指<strong>逻辑PG数目</strong>。为了数据的可靠性，Ceph会将每个逻辑PG转换为多个实例PG，由它们负责将对象的不同备份或者部分写入不同的OSD。</p><p>如果使用多副本，那么每个逻辑PG被转换为与副本数相等的PG实例。处于数据一致性考虑，我们可以选择Paxos作为数据分布一致性算法，但这样过于重量级。其实我们只需要在PG实例中选择一个主要的PG作为通用的入口进行操作分发或者集中（例如peering）。</p><p>如果使用纠删码，每个逻辑PG会被分为k+m个实例。与多副本不同，这些PG只保存每个对象的一个分片（shard），所以需要对其身份进行严格区分。同样，需要在PG实例中选择一个主要的PG。</p><p>按照约定，主要PG由CRUSH返回的第一个OSD充当。PGID由CRUSH计算，使得PG在所有OSD之间均匀分布。</p><h2 id="1-1-术语和约定"><a href="#1-1-术语和约定" class="headerlink" title="1.1 术语和约定"></a>1.1 术语和约定</h2><ul><li><p>PGID</p><p>PG有一个全局唯一的ID——$PGID$，所有的pool由Monitor统一管理，由pool-id+PG在pool内唯一ID+shard（仅适用于纠删码存储池）组成。</p></li><li><p>OS</p><p>指对象存储的种类（Object Store）例如FileStore和BlueStore。</p></li></ul><ul><li><p>Info</p><p>PG内基本元数据信息。</p></li><li><p>Log </p><p>基于Eversion顺序记录所有客户端发起的修改操作的历史信息，为后续提供历史操作回溯和数据同步的依据。</p></li><li><p>Authoritative History</p><p>指权威日志。它是Peering过程中进行数据同步的依据，通过交换Info并基于一定的规则从所有的PG实例中选举产生。通过重放权威日志，可以使得PG内部每个对象的版本号达成一致。</p></li><li><p>PGBackend</p><p>字面意思是PG后端。负责将对原始对象的操作转化为副本之间的分布式操作。对于多副本而言是<code>ReplicatedBackend</code>；对于纠删码而言是<code>ECBackend</code>。</p></li><li><p>Epoch</p><p>一般情况下指OSDMap（OSDMap 是 Ceph 集群中所有 OSD 的信息）的版本号，由Monitor生成，总是单调递增。Epoch变化意味着OSDMap发生变化，需要通过一定的策略扩散至所有客户端和位于服务端的OSD。</p></li><li><p>Version </p><p>version指本次修改生效之后的版本号。</p></li><li><p>Eversion</p><p>由Epoch和Version组成。Version总是当前的Primary产生，连续单调增，和Epoch一起标志一次PG内修改操作。如223’23。</p></li><li><p>Interval</p><p>指OSDMap一个连续的Epoch的持续时间，Interval和具体的PG绑定。</p></li><li><p>Acting Set</p><p>指一个有序的OSD集合。当前或者曾在某个Interval负责承载对应PG的PG实例。通常与Up Set相同，但有时候设置了PG Temp会导致两者不相同。</p></li><li><p>Primary</p><p>指Acting Set的第一个OSD，负责处理来自客户端的读写请求，同时也是peering的发起者和协调者。</p></li><li><p>Peering</p><p>指归属于同一个PG的所有PG实例就本PG所存储的全部对象以及对象相关的元数据操作进行协商并最终一致的过程。</p><p>Peering 基于Log和Info进行。这里的达成一致，并不表示每个PG实例都能获得最新的内容。事实上，为例尽快恢复对外业务，一旦Peering完成，在满足条件下就可以切换为Active状态，后续的数据恢复可以在后台进行。</p></li><li><p>Recovery</p><p>指针对PG某些实例进行数据同步的过程，其最终目标是将PG重新变为Active+Clean状态。它可以在后台进行。</p></li><li><p>Backfill</p><p>Backfill字面意思是回填，是Recovery的一种特殊场景，指Peering完成后，如果基于当前的权威日志无法对Up Set当中的某些PG实例实现增量同步，则通过完全拷贝当前的Primary所有对象的方式进行<strong>全量同步</strong>。</p></li><li><p>PG Temp</p><p>作为PG临时载体的OSD集合。Peering过程中，如果当前的Interval通过CRUSH计算的Up Set不合理（例如Up Set中的一些OSD新加入集群，根本没有PG的任何历史信息），那么可以通知OSDMonitor设置PG Temp的方式来显式的指定一些仍然具有相对完备PG信息的OSD加入Acting Set，使得Acting Set中的OSD再完成Peering之后能够临时处理客户端发起的读写请求，以尽可能减少业务中断的时间。上述过程会导致Up Set和Acting Set临时不一致。UpSet是CRUSH原始计算的映射结果；因为Peering过程中不能处理客户端读写请求，引入PG Temp可以缩短业务中断的时间，当Up Set中的副本在后台通过Recovery 或者Backfill 完成数据同步时，此时可以通知OSDMonitor取消PG Temp.</p><div class="note note-warning">            <ul><li>之所以需要PG Temp来修改OSDMap，是因为需要同步通知到所有客户端，让它们后续将读写请求发送到Acting Set而不是Up Set中的Primary。</li><li>PG Temp生效之后，PG将处于Remapped状态。</li><li>Peering完成之后，Up Set中与Acting Set不一致的OSD将在后台通过Recovery或者Backfill的方式与当前的Primary进行数据同步；数据同步完成后，PG需要重新修改PG Temp为空集合，完成Acting Set至Up Set的切换，此时取消Remapped标记。</li></ul>          </div></li><li><p>Stray</p><p>指PG所在的OSD不是PG当前的Acting Set中。</p></li></ul><p><img src="/img/ceph-d.png" alt="img"></p><blockquote><p>上图1：客户侧，Monitor和 Primary、Replica的关系</p></blockquote><p><img src="/img/ceph_io2.png" alt="img"></p><blockquote><p>上图2：正常的读写流程</p><p>客户侧先产生一个cluster handle（也就是后文所说的op）。之后连接monitor，再从Primary OSD进行读写。</p></blockquote><p><img src="/img/ceph-e.jpg" alt="img"></p><blockquote><p>上图3：Backfill的读写流程. 由于一些OSD离线太久，或者新的OSD加入到集群导致PG实例整体迁移，上图明显属于后者，需要通过Backfill指定临时主进行全增量同步并且选择新的Primary。</p></blockquote><p>客户端读写流程详细分析：</p><ol><li>OSD收到客户端发出的读写请求，将其封装为一个op（客户端发出的读写请求），并基于其携带的PGID发送至对应PG。</li><li>PG收到op之后，完成一系列检查，所有条件均满足后，开始真正执行op。<ul><li>如果op只包含读操作，那么直接执行同步读（对应多副本），或者异步读（对应纠删码），等待操作完成后向客户端应答。</li><li>如果op包含写操作，首先由primary基于op生成一个针对原始对象的事务及相关操作，然后将其提交给PGBackend安装备份策略转化为每个PG实例（包含所有primary和所有Replica）真正需要执行的本地事务并进行分发，当primary收到所有副本的写入完成应答之后，对应的op执行完成，此时由primary向客户端回应写完成。</li></ul></li></ol><h2 id="1-2-PG快速定位对象"><a href="#1-2-PG快速定位对象" class="headerlink" title="1.2 PG快速定位对象"></a>1.2 PG快速定位对象</h2><blockquote><p>对应参考书 2.2.1 PG</p></blockquote><p>首先由特定类型的Client根据其操作的对象名计算出一个32位的哈希值，然后根据其操作的对象名计算出一个32位的哈希值，然后根据归属的pool及此时的哈希值，通过简单的计算，比如取模，即可找到最终承载该对象的PG。</p><p>我们发现如果pool内的PG数目如果能写成$2^n$形式，那么其低n比特都是相同的。我们将$2^n-1$称为PG的<strong>掩码</strong>。否则，若PG不能写成$2^n$的形式，则不能保证针对不同的输入低n比特相同这一“稳定”的性质。（比如有12个PG，那么对于属于同一个pool的PGID只有低两位相同）</p><p>因此一种行之有效的方法是用掩码代替取模。取hash低n-1位，即$hash\&amp;(2^n-1)$ .但这种映射存在问题，如果PG数目不能被2整除，那么采用这种方式会导致空穴，也就是取模结果没有实际PG对应。</p><p>比如一个pool有12个PG，n=4，但是12-15这些值都浪费了：</p><blockquote><div class="table-container"><table><thead><tr><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>x</td><td>x</td><td>x</td><td>x</td></tr></tbody></table></div><p>我们可以想办法压缩空间 ，$hash\&amp;(2^{n-1}-1)$，使得不能被2整除的PGID仍能被合理映射。</p><div class="table-container"><table><thead><tr><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td></tr></tbody></table></div><p>如果$hash\&amp;(2^{n}-1)&lt;pg_num$，那么可以直接返回$hash\&amp;(2^n-1)$.</p><p>否则，我们返回$hash\&amp;(2^{n-1}-1)$.</p><p>在参考书上被称为稳定哈希（stable hash）。</p></blockquote><p>Ceph主要设计理念之一是高扩展性。当集群中PG增加，新的PG会被随机均匀地映射至所有OSD上。作为stable hash的输入的PG数目已经发生变化，导致某些对象从旧PG重新映射至新PG，因此需要转移这部分对象，我们称为<strong>PG分裂</strong>（这也是为什么PG数目必须是2的次幂的原因！）。</p><h1 id="2-详细剖析PG读写流程"><a href="#2-详细剖析PG读写流程" class="headerlink" title="2 详细剖析PG读写流程"></a>2 详细剖析PG读写流程</h1><h2 id="2-1-消息接收与分发"><a href="#2-1-消息接收与分发" class="headerlink" title="2.1 消息接收与分发"></a>2.1 消息接收与分发</h2><p>OSD绑定的Public Messenger 收到客户端发送的读写请求后，通过OSD注册的回调函数——<code>ms_fast_dispatch</code>进行快速派发：</p><ul><li>基于消息(Messenger)创建一个op， 用于对消息进行跟踪，并记录消息携带的Epoch。</li><li>查找OSD关联的客户端会话上下文，，将op加入其内部的<code>waiting_on_map</code>队列，获取OSDMap，，并将其与<code>waiting_on_map</code>队列的所有op进行逐一比较——如果OSD当前的OSDMap的Epoch不小于op所携带的Epoch，则进一步将其派发至OSD的<code>op_shardedwq</code>队列（OSD内部的工作队列）；否则直接终止派发。</li><li>如果会话的上下文的<code>waiting_on_map</code>不为空，说明至少存在一个op，其携带的Epoch比OSDMap更新，此时将其加入OSD全局<code>session_waiting_for_map</code>集合，该集合汇集了当前所有需要等待OSD更新完OSDMap之后才能继续处理的会话上下文；否则将对应的会话从<code>session_waiting_for_map</code>中移除。</li></ul><p>上面有些概念我们先抛砖引玉，下面我们具体讲</p><h2 id="2-2-do-request"><a href="#2-2-do-request" class="headerlink" title="2.2 do_request"></a>2.2 do_request</h2><p><code>do_request</code>作为PG处理op的第一步，主要完成全局（PG级别的）检查：</p><ul><li>Epoch——如果op携带的Epoch更新，那么需要等待PG完成OSDMap同步之后才能进行处理。</li><li><p>op能否被直接丢弃——一些可能的场景有：</p><ul><li>op对应的客户端链接已经断开</li><li>收到op时，PG当前已经切换到一个更新的Interval（OSD生成一个连续Epoch的间隔），后续客户端会重发。</li><li>op在PG分裂之前发送，后续客户端会重发。</li></ul></li><li><p>PG自身的状态如果不为Active，op同样会被阻塞。</p><p>PG内部维护了许多不同类型的重试队列，保证请求按顺序被处理。当对应限制解除之后，op会重新进入<code>op_shardedwq</code>，等待被PG执行。</p></li></ul><h2 id="2-3-do-op"><a href="#2-3-do-op" class="headerlink" title="2.3 do_op"></a>2.3 do_op</h2><p>do_op进行对象级别的检查：</p><p>1）按照op携带的操作类型，初始化op中各种标志位。</p><p>2）完成对op的合法性校验，不合法的情况包括：1.PG包含op所携带的对象；2.op之间携带可以并发执行的标志 ；3. 客户端权限不足；4. op携带对象名称、key或者命名空间长度超过最大限制（只有在FileStore下存在此限制）5.op对应客户端被纳入黑名单 6. op在集群被标记为Full之前发送 7. PG所在的OSD存储空间不足 8. op包含写操作并且企图访问快照对象 9. op包含写操作并且一次写入量太大（超过<code>osd_max_write_size</code>）。</p><p>3）检查op携带的对象是否不可读或者处于降级状态或者正在被scrub（读取数据对象并重新计算校验和），加入相应队列。</p><p>4）检查op是否为重发（基于op的repid在当前的Log中查找，如果找到说明为重发）。</p><p>5）获取对象上下文，创建OpContext对op进行跟踪，并通过<code>execute_ctx</code>真正开始执行op。</p><blockquote><p>💬关于可用存储空间控制</p><p>Ceph使用四个配置项，<code>mon_osd_full_ratio</code>、 <code>mon_osd_nearfull_ratio</code>、<code>osd_backfill_full_ratio</code>（OSD空间利用率大于此值，PG被拒绝以backfill方式迁入）、<code>osd_failsafe_full_ratio</code>（防止OSD磁盘被100%写满的最后一道屏障）。 </p><p>每个OSD通过<strong>心跳</strong>机制周期性的检测自身空间利用率，并上报至Monitor。<code>osd_backfill_full_ratio</code>的存在意义是有些数据迁移是自动触发的，我们无法预料到自动数据平衡后数据会落到哪个磁盘，因此必须设置此项进行控制。</p><p>💬关于对象上下文 (原书134页图4-3)</p><p>对象上下文主要保存了对象OI(Object Info)和SS(Snap Set)属性。同时表明对象是否仍然存在。查找head对象上下文相对简单，如果没有在缓存中命中，直接在磁盘中读取即可。然而如果op直接操作快照或者对象克隆，这个过程将变得很复杂。其难点在于一个克隆对象可以对应多个快照，因此需要根据快照序列号定位到某个特定的克隆对象，然后通过分析其位于OI中的snap属性才能进一步判断快照序列号是否位于克隆对象之中。</p></blockquote><h2 id="2-4-execute-ctx"><a href="#2-4-execute-ctx" class="headerlink" title="2.4 execute_ctx"></a>2.4 execute_ctx</h2><p><code>execute</code>是真正执行op的步骤。它首先基于当前的快照模式，更新OpContext中的快照上下文(SnapContext)——如果是自定义快照模式，直接基于op携带的快照信息更新；否则基于PGPool更新。 </p><p>为了保证数据的一致性，所以包含修改操作的PG会预先由Primary通过<code>prepare_transcation</code>封装为一个PG事务，然后由不同类型的PGBackend负责转化为OS(objectStore,笔者注)能够识别的本地事务，最后在副本间分发和同步。</p><h2 id="2-5-事务准备"><a href="#2-5-事务准备" class="headerlink" title="2.5 事务准备"></a>2.5 事务准备</h2><p>针对多副本，因为每个副本保存的对象完全相同，所以由Primary生成的PG事务也可以直接作为每个副本的本地事务直接执行。引入纠删码之后，每个副本保存的都是独一无二的分片，所以需要对原始对象的整体操作（对应PG操作）和每个分片操作（对应OS事务）加以区分。</p><p>本节介绍如何基于op生成PG级别的事务，这个过程通过<code>prepare_transaction</code>完成。</p><ol><li>通过<code>do_osd_ops</code>生成原始op对应的PG事务。</li><li>如果op针对<code>head</code>对象操作，通过<code>make_writable</code>检查是否需要预先执行克隆操作。</li><li>通过<code>finish_ctx</code>检查是否需要创建或者删除<code>snapdir</code>对象，生成日志，并更新对象的OI及SS属性。</li></ol><p>下面我们具体介绍相关流程：</p><h3 id="1-do-osd-ops"><a href="#1-do-osd-ops" class="headerlink" title="1 do_osd_ops"></a>1 do_osd_ops</h3><ol><li>检查write操作携带的<code>trancate_seq</code>，并和对象上下文保存的<code>truncate_seq</code>比较从而判定客户端执行write操作和trimtrunc/truncate操作的真实顺序，并对write操作涉及的逻辑地址范围进行修正。</li><li>检查本地写入逻辑地址范围是否合法——例如我们当前限制对象大小不超过100GB。(对应<code>osd_max_object_size</code>)。</li><li>将write对象转化为PGTransaction中的事务。</li><li>如果是满对象写（包括新写或者覆盖写），或者为追加写并且之前存在数据校验和，则重新计算并更新OI中数据校验和，作为后续执行Deep Scrub的依据；否则清除校验和。在OpContext中积累本次write修改的逻辑地址范围以及其它统计（例如写操作次数、写入字节数），同时更新对象大小。</li></ol><h3 id="2-make-writable"><a href="#2-make-writable" class="headerlink" title="2 make_writable"></a>2 make_writable</h3><p>如果op针对head对象进行修改</p><ol><li>判断head对象是否需要执行克隆：取对象当前的SnapSet，和OpContext中SnapContext 中内容进行比较——如果SnapSet中最新的快照序列号比SnapContext中最新的快照序列号小，说明自上次快照之后，又产生新的快照。此时不能直接对head对象进行修改，而是需要先执行克隆（默认为全对象克隆）。如果SnapContext携带了多个新的快照序列号，那么所有比SnapSet中更新的快照序列号都将关联至同一个克隆对象。</li></ol><blockquote><p>这里有一个特殊情况——如果当前操作为删除head对象，并且该对象自创建之后没有经历任何修改（此时SnapSet为空），也需要该head对象正常执行克隆后再删除，后续将创建一个snapdir对象来转移这些快照及相关的克隆信息。</p></blockquote><ol><li>创建克隆对象，需要同步更新SS属性中相关信息：<ul><li>在<code>clones</code>集合中记录当前克隆对象中最新快照序列号。</li><li>在<code>clone_size</code>集合中更新当前克隆对象的大小——因为默认使用全对象克隆，所以克隆对象大小为执行克隆时head对象head对象的实时大小。</li><li>在<code>clone_overlap</code>集合中记录当前克隆对象与前一个克隆对象之间的重合部分。</li></ul></li><li>为克隆对象生成一条新的、独立的日志，更新op中日志版本号。</li><li>最后，基于SnapContext更新对象SS属性中快照信息。</li></ol><h3 id="3-finish-ctx"><a href="#3-finish-ctx" class="headerlink" title="3 finish_ctx"></a>3 finish_ctx</h3><p>顾名思义，<code>finish_ctx</code>完成事务准备阶段最后的清理工作。</p><p>1）如果创建head对象并且snapdir对象存在，则删除snapdir对象，同时生成一条删除snapdir对象的日志；如果删除head对象并且对象仍然被快照引用，则创建snapdir对象，同时生成一条创建snapdir对象的日志，并将head对象的OI和SS属性用snapdir’对象转存</p><p>2）如果对象存在，则更新对象OI属性——例如version、last_reqid、mtime等；进一步，如果是head对象，同步更新其SS属性。</p><p>3）生成一条op操作原始对象的日志，并追加至现有的OpContext中的日志集合中。</p><p>4）在OpContext关联的对象上下文中应用最新的对象状态和SS上下文。</p><h2 id="2-6-注册回调函数"><a href="#2-6-注册回调函数" class="headerlink" title="2.6  注册回调函数"></a>2.6  注册回调函数</h2><p>PG事务准备后，如果是纯粹的读操作，如果是同步读（对于多副本），op已经执行完毕，此时可以直接向客户端应答；如果是异步读（针对纠删码），则将op挂入PG内部的异步读队列，等待异步读完成之后再向客户端应答。</p><p>如果是写操作，则注册如下几类回调函数：</p><ul><li><code>on_commit</code>——执行时，向客户端发送写入完成应答；</li><li><code>on_success</code>——执行时，进行与Watch\Notify相关的处理；</li><li><code>on_finish</code>——执行时，删除OpContext。</li></ul><h2 id="2-7-事务分发与同步"><a href="#2-7-事务分发与同步" class="headerlink" title="2.7 事务分发与同步"></a>2.7 事务分发与同步</h2><p>事务的分发与同步由Primary完成，具体而言是通过RepGather实现的。RepGather被提交到PGBackend，后者负责将PG事务转化为每个副本之间的本地事务之后再进行分发。</p><p>对于纠删码而言，当涉及覆盖写时，如果改写的部分不足一个完整条带（指写入的起始地址或者数据长度没有进行条带对齐），则需要执行RMW，这期间需要多次执行补齐读、重新生成完整条带并重新计算校验块、单独生成每个副本的事务并构造消息进行分发（Write）、同时在必要时执行范围克隆和对PG日志进行修正，以支持Peering期间的回滚操作。</p><h1 id="3-PG-状态迁移详解"><a href="#3-PG-状态迁移详解" class="headerlink" title="3 PG 状态迁移详解"></a>3 PG 状态迁移详解</h1><p>PG状态分为外部状态和内部状态，其中外部状态是可以直接被用户感知的。</p><blockquote><p>​                                                                    PG外部状态表</p></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">PG状态</th><th style="text-align:left">含义</th></tr></thead><tbody><tr><td style="text-align:center">Activating</td><td style="text-align:left">Peering已经完成，PG正在等待所有PG实例同步并固化Peering结果（Info、Log）</td></tr><tr><td style="text-align:center">Active</td><td style="text-align:left">PG可以正常处理来自客户端的读写请求</td></tr><tr><td style="text-align:center">Backfilling</td><td style="text-align:left">见前面术语——Backfill部分</td></tr><tr><td style="text-align:center">Clean</td><td style="text-align:left">PG当前不存在待修复的对象，Acting Set与Up Set一致，并且大小等于存储池副本数</td></tr><tr><td style="text-align:center">Creating</td><td style="text-align:left">PG正在被创建</td></tr><tr><td style="text-align:center">Deep</td><td style="text-align:left">PG正在进行对象一致性扫描（总是与Scrubbing同时出现）</td></tr><tr><td style="text-align:center">Scrubbing</td><td style="text-align:left">PG正在进行对象一致性扫描，但Scrubbing仅扫描元数据</td></tr><tr><td style="text-align:center">Degraded</td><td style="text-align:left">Peering完成后，PG检测到任意一个PG实例存在不一致的对象；或者当前ActingSet小于存储池副本数。</td></tr><tr><td style="text-align:center">Down</td><td style="text-align:left">Peering过程中，PG检测到某个Interval中，当前剩余的OSD不足以完成数据修复</td></tr><tr><td style="text-align:center">Incomplete</td><td style="text-align:left">Peering过程中，由于：1）无法获得权威日志 2）通过<code>choose_acting</code>选出的Acting Set后续不足以完成数据修复（例如针对纠删码，存活的副本数小于k）</td></tr><tr><td style="text-align:center">Inconsistent</td><td style="text-align:left">PG通过Scrub检测到某些对象在PG实例间出现不一致（主要是因为静默错误）</td></tr><tr><td style="text-align:center">Peered</td><td style="text-align:left">指Peering完成，但是PG当前的ActingSet小于存储池规定的最小副本数。</td></tr><tr><td style="text-align:center">Recovering</td><td style="text-align:left">PG正在对不一致对象进行同步/修复。</td></tr><tr><td style="text-align:center">Remapped</td><td style="text-align:left">Peering完成，PG当前的Acting Set和Up Set出现不一致。</td></tr><tr><td style="text-align:center">Repair</td><td style="text-align:left">PG在下一次执行Scrub的过程中，如果发现存在不一致的对象，并且能够进行修复，则自动进行修复。</td></tr><tr><td style="text-align:center">Stale</td><td style="text-align:left">Monitor检测到当前Primary所在的OSD宕机；Primary超时未向Monitor上报心跳信息。</td></tr><tr><td style="text-align:center">Undersized</td><td style="text-align:left">PG当前的Acting Set小于存储池副本数</td></tr></tbody></table></div><div class="note note-primary">            <p>注意上述外部状态是可以叠加的。比如Active+clean表示一切正常。</p>          </div><h2 id="3-1-状态机描述"><a href="#3-1-状态机描述" class="headerlink" title="3.1 状态机描述"></a>3.1 状态机描述</h2><p><img src="\img\PG_DFA.png" style="zoom: 80%;" /></p><h2 id="3-2-具体流程分析"><a href="#3-2-具体流程分析" class="headerlink" title="3.2 具体流程分析"></a>3.2 具体流程分析</h2><h2 id="1-创建PG"><a href="#1-创建PG" class="headerlink" title="1 创建PG"></a>1 创建PG</h2><p>OSDMonitor收到存储池创建命令之后，最终通过PGMonitor异步向每个OSD下发批量创建PG命令。创建PG是在Primary主导下进行的。Replica会在随后由Primary发起的Peering过程中自动被创建。</p><h2 id="2-Peering"><a href="#2-Peering" class="headerlink" title="2 Peering"></a>2 Peering</h2><p>所有需要执行Peering 的PG也会专门安排一个peering_wq工作队列，当PG从peering_wq出列时：</p><ol><li>创建一个RecoveryCtx，用于批量处理所有PG与Peering相关的消息，例如Query(Log, Info等)，Notify等。</li><li>逐个PG处理：取OSD最新的OSDMap，通过advance_pg检查PG是否需要执行OSDMap更新操作。如果为否，说明直接由Peering事件触发，将该事件从PG内部的peering_queue出列，投递到PG内部的状态机进行处理；如果为是，则在advance_pg内部执行OSDMap更新操作，完成之后再将PG再次加入peering_wq队列。</li><li>检查是否需要通知Monitor设置本OSD的<code>up_thru</code>（我们规定PG在切换至新的Interval之后，成功完成Peering并重新开始接受客户端读写请求之前，必须先通知OSDMonitor设置其归属的up_thru参数）.</li><li>批量派发RecoveryCtx中积累的Query\Notify消息。</li></ol><p>下面是几个必须的操作，包括GetInfo, GetLog, GetMissing和Activate</p><p>GetInfo：获取PG元数据信息。</p><p>GetLog：开始着手进行日志同步。按照以下原则：</p><ul><li>优先选取具有最新内容的日志（即Info中的<code>last_update</code>最大）；</li><li>如果有多份满足1）的日志，优先选择保存更多日志条目的日志，即Info中<code>log_tail</code>最小；</li><li>如果有多份满足2）的日志，优先选择当前的Primary。</li></ul><p>GetMissing</p><p>Missing列表记录了自身所有需要通过Recovery进行修复的对象信息。只保留两个：</p><ul><li><code>need</code>：对象被同步的目标版本号。</li><li><code>have</code>：对象当前归属PG实例的本地版本号。</li></ul><p>当Primary收到每个Peer的本地日志之后，可以通过日志合并的方式得到每个Peer的missing列表，这一过程是通过解决日志分歧得到的。</p><p>为解决日志分歧，我们先将所有日志按照对象进行分类——即所有针对同一个对象操作的分歧日志都使用同一个队列进行管理，然后逐个队列进行管理。我们假定最老的那条分歧日志生效之前对应的版本号为prior_version，则针对每个队列的处理 都可以归结为以下五种情形：</p><ul><li>本地存在比分歧日志更新的日志。</li><li>对象此前不存在。此时可以直接删除对象。</li><li>对象当前位于missing列表之中（例如上一次peering完成之后，Primary刚更新了自己的missing列表，但是其中的对象还没来得及修复，系统发生断电）。</li><li>对象不在missing列表之中同时所有分歧日志都可以回滚。此时将所有分歧日志按照从新到老的顺序依次进行回滚。</li><li>对象不在missing列表之中并且至少存在一条分歧日志不可回滚。此时将本地对象直接删除，将其加入missing列表，同时设置其need为prior_version，have为0.</li></ul><p>Activate</p><p>在PG正式变为Active状态接受客户端请求之前，还必须先固化本次Peering的结果（也就是写入磁盘，开机bootstrap），遇到系统掉电时不会前功尽弃；同时需要初始化后续在后台执行的Recovery或者Backfill所依赖的元数据信息。以上过程便是Activate。</p><p>下面我们重点对两个元数据进行分析：</p><ul><li><code>last_epoch_started</code></li></ul><p>它本来用于指示上一次peering成功时完成的epoch，但是因为peering涉及在多个osd之间进行数据和状态同步，所以存在进度不一致的可能。 为此我们设计两个<code>last_epoch_started</code>，一个用于标识每个参与本次Peering的PG实例本地Activate已经完成，直接作为本身Info的子属性存盘；另一个保存在Info的History属性下，由Primary在检测到所有副本的Activate过程都完成后统一更新和存盘。</p><ul><li><code>MissingLoc</code></li></ul><p>在进行Recovery之前我们需要先引入一种同时包含所有missing条目和它们（目标版本）所在位置信息的全局数据结构，称为<code>MissingLoc</code>，它包含两个子表，分别是<code>needs_recovery_map</code>和<code>missing_loc</code>.它们分别保存当前PG的所有待修复对象，以及这些对象的目标版本可能同时存在于多个PG实例之上。因为目标版本可能位于多个PG实例之上，注意<code>missing_loc</code>不是一个PG而是一些PG的集合。后者由Primary统一生成。</p><p>生成<code>missing_loc</code>需要两步：首先，将所有的Peer missing列表之中的条目依次加入到needs_recovery_map之中；其次，以每个Peeri的Info和missing列表作为输入，针对<code>needs_recovery_map</code>中的每个对象逐一进行检查，以进一步确认其目标版本的位置信息并填充<code>missing_loc</code>.</p><p>成功生成<code>MissingLoc</code>之后，如果<code>needs_recovery_map</code>不为空，即存在任何需要被Recovery的对象，则Primary设置自身状态为<strong>Degraded+Activating</strong>；进一步，如果Primary检测到当前的Acting Set小于存储池副本数，则同时设置为<strong>Undersized</strong>状态。之后，Primary通过本地OS接口开始固化Peering结构；当Primary检测自身以及所有Peer的Activate操作都完成时，通过向状态机投递一个<code>AllReplicasActivated</code>事件来清除自身的Activating状态和Creating状态。同时检测PG此时Acting Set是否小于存储池最小副本数，如果小于，则设置PG状态为<strong>Peered</strong>并终止后续处理，否则将PG设置为Active，同时将之前来自客户端被阻塞的op重新入列。</p><p>随后PG进入<strong>Active</strong>状态，可以正常执行客户端的读写请求。</p><h2 id="3-Recovery"><a href="#3-Recovery" class="headerlink" title="3 Recovery"></a>3 Recovery</h2><p>Recovery是在Primary检测到自身或者任意一个peer存在待修复的对象进行的操作。为了防止集群中大量PG同时执行Recovery造成客户端响应速度过慢，需要限制Recovery。我们有几种配置项可供修改：</p><ul><li><code>osd_max_bakfills</code>: 单个OSD运行同时执行Recovery或者Backfill的PG实例个数。 注意虽然单个PG的Recovery或者Backfill不能并发，但是不同PG的Recovery和Backfill可以并发。</li><li><code>osd_max_push_cost/osd_max_push_objects</code>:指示通过Push操作执行Recovery时，以OSD为单位，单个op所能携带的字节数，对象数。</li><li><code>osd_recovery_max_active</code>: 单个OSD允许同时执行Recovery的对象数。</li><li><code>osd_recovery_op_priority</code>: 指示Recovery op的默认优先级，它将与客户端op进行竞争，优先级设置越低，竞争劣势更大。</li><li><code>osd_recovery_sleep</code>: Recovery op每次在<code>op_shardedwq</code>中被处理前，设置此参数将导致对应的服务线程先休眠对应的时间。</li></ul><p>不难看出，考虑到集群总IOPS和带宽有限，可以通过降低Recovery权重，或者通过QoS对Recovery总的IOPS和带宽加以限制，可以有效抑制Recovery对资源的消耗。</p><p>Recovery有以下两种方式：</p><ol><li><code>pull</code>: 指Primary自身存在待修复对象，由Primary按照<code>missing_loc</code>选择合适的副本去拉取待修复对象目标版本到本地，完成修复。</li><li><code>push</code>: 指Primary感知到一个或者多个Replica当前存在待修复对象，主动推送每个待修复对象目标版本至相应的Replica，然后在本地完成修复。</li></ol><p>Primary必须先完成自我修复才能修复别的Replica。它是基于日志进行的：</p><ul><li>日志中的<code>last_requested</code>用于指示Recovery的起始版本号，在Activate中生成。因此我们首先将所有待修复对象按照日志版本号进行顺序排列，找到版本号不小于<code>last_requested</code>的第一个对象，记为v；</li><li>如果不为head对象，那么检查是否需要优先修复head对象后者snapdir对象；</li><li>根据具体的PGBackend生成一个Pull类型的op；</li><li>更新last_requested，使其指向v；</li><li>如果尚未达到单次最大修复数码，则从顺序队列中处理下一个待修复对象；否则返回。</li></ul><p>以多副本为例子，因为PG日志中并未记录任何关于修改的详细信息，目前都是通过简单的全对象拷贝，因而效率低下，这也是Ceph为人所诟病的地方。</p><h2 id="4-Backfill"><a href="#4-Backfill" class="headerlink" title="4 Backfill"></a>4 Backfill</h2><p>Backfill的理论依据是“PG中所有对象可以基于全精度哈希排序”，所以是按照从小到大对当前对象进行遍历，并依次将它们按照全对象拷贝的方式写入待Backfill的PG实例。</p><p>当空的PG Temp在新的OSDMap生效之后，PG关联的Acting Set和Up Set重新变得一致，再次经过Peering之后，PG最终进入<strong>Active+Clean</strong>状态，此时PG一切恢复正常，可以删除不必要的副本（Stray）。</p><h1 id="4-总结"><a href="#4-总结" class="headerlink" title="4 总结"></a>4 总结</h1><p>PG的主要定位如下：</p><ul><li>作为存储池的基本组成单位，负责执行存储池所绑定的副本策略。</li><li>以OSD作为单位，进行副本分布，将前端应用任何针对PG中原始对象的操作，转化为OSD所能理解的事务操作，并保证副本之间的强一致性。</li></ul><p>不足之处在于：因为PG日志中并未记录任何关于修改的详细信息，目前都是通过简单的全对象拷贝，因而效率低下，这也是Ceph为人所诟病的地方。</p><hr><h1 id="——"><a href="#——" class="headerlink" title="——"></a>——</h1><h1 id="实践部分"><a href="#实践部分" class="headerlink" title="实践部分"></a>实践部分</h1><h2 id="0-官方的指导和讲解"><a href="#0-官方的指导和讲解" class="headerlink" title="0 官方的指导和讲解"></a>0 官方的指导和讲解</h2><p>数据的持久性以及所有OSD之间的均匀分配都需要更多的放置组，但应将其数量减少到最少，以节省CPU和内存。</p><h3 id="0-1-数据持久性"><a href="#0-1-数据持久性" class="headerlink" title="0.1 数据持久性"></a>0.1 数据持久性</h3><p>OSD发生故障后，数据丢失的风险会增加，直到完全恢复其中包含的数据为止。让我们想象一下在单个放置组中导致永久性数据丢失的情况：</p><ul><li>OSD失败，并且它包含的对象的所有副本均丢失。对于放置组中的所有对象，副本的数量突然从三个减少到两个。</li><li>Ceph通过选择一个新的OSD来重新创建所有对象的第三个副本，从而开始对该放置组的恢复。</li><li>在同一放置组内的另一个OSD在新OSD完全填充第三份副本之前发生故障。某些对象将只有一个幸存副本。</li><li>Ceph选择了另一个OSD并保持复制对象以恢复所需的副本数。</li><li>在同一放置组内的第三个OSD在恢复完成之前发生故障。如果此OSD包含对象的唯一剩余副本，则它将永久丢失。</li></ul><p>在三个副本池中包含10个OSD和512个放置组的群集中，CRUSH将为每个放置组提供三个OSD。最后，每个OSD将托管（512 * 3）/ 10 =〜150个放置组。当第一个OSD发生故障时，以上情形将因此同时开始恢复所有150个放置组的操作。</p><p>恢复的150个放置组可能均匀分布在剩余的9个OSD上。因此，每个剩余的OSD都有可能将对象的副本发送给所有其他对象，并且还可能接收一些要存储的新对象，因为它们已成为新放置组的一部分。</p><p>完成恢复所需的时间完全取决于Ceph集群的架构。假设每个OSD由一台机器上的1TB SSD托管，并且所有OSD都连接到10Gb / s交换机，并且单个OSD的恢复将在M分钟内完成。如果每台计算机使用不带SSD日志的微调器和1Gb / s开关的两个OSD，则速度至少要慢一个数量级。</p><p>在这种大小的群集中，放置组的数量几乎对数据持久性没有影响。可能是128或8192，恢复速度不会变慢或变快。</p><p><strong>但是，将相同的Ceph群集增加到20个OSD而不是10个OSD可能会加快恢复速度，从而显着提高数据的持久性</strong>。现在，每个OSD只能参与约75个放置组，而不是只有10个OSD时的约150个放置组，并且仍然需要全部19个剩余OSD执行相同数量的对象副本才能恢复。但是，如果10个OSD必须每个复制大约100GB，则现在它们必须每个复制50GB。如果网络是瓶颈，恢复将以两倍的速度进行。换句话说，当OSD数量增加时，恢复速度会更快。</p><p>如果该群集增长到40个OSD，则每个OSD将仅托管约35个放置组。如果OSD死亡，则恢复将保持更快的速度，除非它被另一个瓶颈阻止。但是，如果该群集增长到200个OSD，则每个OSD将仅托管约7个放置组。如果OSD死亡，则在这些放置组中最多将有约21（7 * 3）个OSD之间发生恢复：恢复将比有40个OSD时花费更长的时间，这意味着应该增加放置组的数量。</p><p>无论恢复时间有多短，第二个OSD在进行过程中都有可能发生故障。在上述10个OSD集群中，如果其中任何一个失败，则〜17个放置组（即，已恢复的〜150/9个放置组）将只有一个幸存副本。并且，如果剩余的8个OSD中的任何一个失败，则两个放置组的最后一个对象很可能会丢失（即，〜17/8个放置组，仅恢复了一个剩余副本）。</p><p>当群集的大小增加到20个OSD时，丢失三个OSD会损坏的放置组的数量会减少。第二个OSD丢失将降低〜4个（即，恢复到约75个/ 19个放置组），而不是〜17个，而第三个OSD丢失则仅在它是包含尚存副本的四个OSD之一时才丢失数据。换句话说，如果在恢复时间范围内丢失一个OSD的概率为0.0001％，则它从具有10个OSD的群集中的17 <em> 10 </em> 0.0001％变为具有20个OSD的群集中的4 <em> 20 </em> 0.0001％。</p><p><strong><u>简而言之，更多OSD意味着更快的恢复速度和更低的导致安置组的永久损失的级联故障风险。就数据持久性而言，在少于50个OSD的群集中，具有512或4096个放置组大致等效。</u></strong></p><p>注意：添加到群集中的新OSD可能需要很长时间才能分配有分配给它的放置组。但是，不会降低任何对象的质量，也不会影响群集中包含的数据的持久性。</p><h3 id="0-2-池中的对象分布"><a href="#0-2-池中的对象分布" class="headerlink" title="0.2 池中的对象分布"></a>0.2 池中的对象分布</h3><p>理想情况下，对象在每个放置组中均匀分布。由于CRUSH计算每个对象的放置组，但实际上不知道该放置组内每个OSD中存储了多少数据，因此放置组数与OSD数之比可能会显着影响数据的分布。</p><p>例如，如果在三个副本池中有一个用于十个OSD的放置组，则仅使用三个OSD，因为CRUSH别无选择。当有更多的放置组可用时，对象更有可能在其中均匀分布。CRUSH还尽一切努力在所有现有的放置组中平均分配OSD。</p><p>只要放置组比OSD多一个或两个数量级，则分布应该均匀。例如，用于3个OSD的256个放置组，用于10个OSD的512或1024个放置组等。</p><p>数据分布不均可能是由OSD与放置组之间的比率以外的因素引起的。由于CRUSH没有考虑对象的大小，因此一些非常大的对象可能会造成不平衡。假设有100万个4K对象（共4GB）均匀分布在10个OSD的1024个放置组中。他们将在每个OSD上使用4GB / 10 = 400MB。如果将一个400MB对象添加到池中，则支持放置对象的放置组的三个OSD将填充400MB + 400MB = 800MB，而其余七个将仅占据400MB。</p><h3 id="0-3-内存，CPU和网络使用率"><a href="#0-3-内存，CPU和网络使用率" class="headerlink" title="0.3 内存，CPU和网络使用率"></a>0.3 内存，CPU和网络使用率</h3><p>对于每个放置组，OSD和MON始终需要内存，网络和CPU，并且在恢复期间甚至更多。通过对放置组内的对象进行聚类来共享此开销是它们存在的主要原因之一。</p><p><strong><u>最小化放置组的数量可以节省大量资源。</u></strong></p><h3 id="0-4-选择放置组的数量"><a href="#0-4-选择放置组的数量" class="headerlink" title="0.4 选择放置组的数量"></a>0.4 选择放置组的数量</h3><p><strong><u>如果您有超过50个OSD，我们建议每个OSD大约有50-100个放置组</u></strong>，以平衡资源使用，数据持久性和分发。如果OSD少于50个，则最好在上述<a href="https://docs.ceph.com/en/latest/rados/operations/placement-groups/?#preselection">预选</a>中进行<a href="https://docs.ceph.com/en/latest/rados/operations/placement-groups/?#preselection">选择</a>。对于单个对象池，您可以使用以下公式获取基准</p><script type="math/tex; mode=display">Total \ PGs = \frac{OSDs*100}{pool\_size}</script><p>$pool_size$在副本池表示副本数，而在纠删码池表示$K+M$</p><p>然后，您应该检查结果是否与您设计Ceph集群的方式有意义，以最大程度地提高<a href="https://docs.ceph.com/en/latest/rados/operations/placement-groups/?#data-durability">数据持久性</a>， <a href="https://docs.ceph.com/en/latest/rados/operations/placement-groups/?#object-distribution">对象分配</a>并最小化<a href="https://docs.ceph.com/en/latest/rados/operations/placement-groups/?#resource-usage">资源使用</a>。</p><p>结果应始终<strong>四舍五入到最接近的2的幂</strong>。</p><p>只有2的幂可以平衡放置组中的对象数量。其他值将导致OSD上的数据分布不均。它们的使用应仅限于从两个方的一种逐步增加到另一种。</p><p>例如，对于具有200个OSD和3个副本的池大小的群集，您可以如下估算PG的数量</p><script type="math/tex; mode=display">\frac{200 \times 100}{3} = 6667</script><p>最近的2的次幂是8192.</p><p>当使用多个数据池存储对象时，您需要确保在每个池的放置组数量与每个OSD的放置组数量之间取得平衡，以便获得合理的放置组总数，从而使每个OSD的方差很小而不会增加系统资源的负担或使对等进程太慢。</p><p>例如，一个由10个池组成的群集，每个池在10个OSD上具有512个放置组，则总共有5120个放置组分布在10个OSD上，即每个OSD 512个放置组。那不会使用太多资源。但是，如果创建了1,000个池，每个池有512个放置组，则OSD将分别处理约50,000个放置组，并且将需要更多的资源和时间来进行对等。</p><p>您可能会发现<a href="http://ceph.com/pgcalc/">PGCalc</a>工具很有帮助。这是一个很有意思的工具。</p><blockquote><p><strong>建议的PG计数背后的逻辑</strong></p><p>( Target PGs per OSD ) x ( OSD # ) x ( %Data )/ ( Size )</p><ol><li>如果以上计算的值小于<strong>（OSD＃）/（Size）</strong>的值，则该值将更新为<strong>（OSD＃）/（Size）的值</strong>。这是通过为每个池向每个OSD分配至少一个主PG或辅助PG来确保均匀的负载/数据分配。</li><li>然后将输出值舍入到<strong>最接近的2的幂</strong>。<br><strong>提示：</strong>最接近的2的幂提供了<a href="http://ceph.com/docs/master/rados/operations/crush-map/">CRUSH</a>算法效率的少量提高。</li><li>如果最接近的2的幂比原始值低<strong>25％</strong>以上，则使用下一个更高的2的幂。</li></ol><p><strong>目的</strong></p><ul><li>此计算的目的和上面“关键”部分所述的目标范围是为了确保有足够的放置组，以便在整个群集中进行均匀的数据分布，同时每个OSD PG的PG值不够高，从而在恢复期间引起问题和/或回填操作。</li></ul><p><strong>无效或无效池的影响：</strong></p><ul><li>空池或其他非活动池不应被认为有助于整个群集中的数据均匀分布。</li><li>但是，与这些空/非活动池关联的PG仍会消耗内存和CPU开销。</li></ul></blockquote><hr><h2 id="1-设置放置组数"><a href="#1-设置放置组数" class="headerlink" title="1 设置放置组数"></a>1 设置放置组数</h2><p>要设置池中的放置组数量，必须在创建池时指定放置组的数量。有关详细信息，请参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools#createpool">创建池</a>。即使在创建池之后，您也可以使用以下方法更改放置组的数量：</p><pre><code class="hljs pgsql">ceph osd pool <span class="hljs-keyword">set</span> &#123;pool-<span class="hljs-type">name</span>&#125; pg_num &#123;pg_num&#125;</code></pre><p>增加放置组的数量之后，还必须增加放置（<code>pgp_num</code>）的放置组的数量，群集才能重新平衡。该<code>pgp_num</code>会是将由CRUSH算法可考虑放置位置的组数。增加会<code>pg_num</code>拆分放置组，但数据将不会迁移到较新的放置组，直到放置的放置组，即<code>pgp_num</code>增加的值<code>pgp_num</code> 应等于<code>pg_num</code>。要增加用于放置的放置组的数量，请执行以下操作：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">set</span> &#123;pool-name&#125; pgp_num &#123;pgp_num&#125;</code></pre><p>减少PG数量时，<code>pgp_num</code>将自动为您调整。</p><div class="note note-primary">            <p>笔者注：</p><p>关于PG和PGP：</p><ul><li><p>PG =放置组( Placement Group)<br>PGP =用于放置的放置组(Placement Group for Placement purpose)</p><p>pg_num = 映射到OSD的PG的数量，它必须是2的幂次。</p><p>当对任何一个池增加pg_num时，该池的每个PG都会<strong>分裂</strong>成一半，但它们都将始终映射到其父OSD。</p><p>在此之前，Ceph不会开始重新平衡。 现在，当您为同一池增加pgp_num值时，PG开始从父级迁移到其他OSD，并且群集重新平衡开始。 这就是PGP扮演重要角色的方式。</p></li></ul>          </div><h2 id="2-获取放置组的数量"><a href="#2-获取放置组的数量" class="headerlink" title="2 获取放置组的数量"></a>2 获取放置组的数量</h2><p>要获取池中的放置组数，请执行以下操作：</p><pre><code class="hljs pgsql">ceph osd pool <span class="hljs-keyword">get</span> &#123;pool-<span class="hljs-type">name</span>&#125; pg_num</code></pre><h2 id="3-Auto-scaling"><a href="#3-Auto-scaling" class="headerlink" title="3 Auto_scaling"></a>3 Auto_scaling</h2><h3 id="自动调整"><a href="#自动调整" class="headerlink" title="自动调整"></a>自动调整</h3><p>这是一种自动调整PG的方式。有三个参数<code>off</code>, <code>on</code>,<code>warn</code>. 当设置为off就需要人为控制PG数目。</p><p>要为现有池设置自动缩放模式，请执行以下操作：</p><pre><code class="hljs pgsql">ceph osd pool <span class="hljs-keyword">set</span> &lt;pool-<span class="hljs-type">name</span>&gt; pg_autoscale_mode &lt;mode&gt;</code></pre><p>例如，要在pool上启用自动缩放<code>foo</code>，请执行以下操作：</p><pre><code class="hljs pgsql">ceph osd pool <span class="hljs-keyword">set</span> foo pg_autoscale_mode <span class="hljs-keyword">on</span></code></pre><p>您还可以使用以下命令配置<code>pg_autoscale_mode</code>应用于以后创建的任何池的默认值：</p><pre><code class="hljs routeros">ceph<span class="hljs-built_in"> config </span><span class="hljs-builtin-name">set</span> global osd_pool_default_pg_autoscale_mode &lt;mode&gt;</code></pre><h2 id="4-Autoscale-status"><a href="#4-Autoscale-status" class="headerlink" title="4 Autoscale_status"></a>4 Autoscale_status</h2><h3 id="查看PG缩放建议"><a href="#查看PG缩放建议" class="headerlink" title="查看PG缩放建议"></a>查看PG缩放建议</h3><p>您可以使用以下命令查看每个池，池的相对利用率以及对PG计数的任何建议更改：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>autoscale-status</code></pre><p>输出将类似于：</p><pre><code class="hljs apache"><span class="hljs-attribute">POOL</span>    SIZE  TARGET SIZE  RATE  RAW CAPACITY   RATIO  TARGET RATIO  EFFECTIVE RATIO PG_NUM  NEW PG_NUM  AUTOSCALE<span class="hljs-attribute">a</span>     <span class="hljs-number">12900</span>M                <span class="hljs-number">3</span>.<span class="hljs-number">0</span>        <span class="hljs-number">82431</span>M  <span class="hljs-number">0</span>.<span class="hljs-number">4695</span>                                     <span class="hljs-number">8</span>         <span class="hljs-number">128</span>  warn<span class="hljs-attribute">c</span>         <span class="hljs-number">0</span>                 <span class="hljs-number">3</span>.<span class="hljs-number">0</span>        <span class="hljs-number">82431</span>M  <span class="hljs-number">0</span>.<span class="hljs-number">0000</span>        <span class="hljs-number">0</span>.<span class="hljs-number">2000</span>           <span class="hljs-number">0</span>.<span class="hljs-number">9884</span>      <span class="hljs-number">1</span>          <span class="hljs-number">64</span>  warn<span class="hljs-attribute">b</span>         <span class="hljs-number">0</span>        <span class="hljs-number">953</span>.<span class="hljs-number">6</span>M   <span class="hljs-number">3</span>.<span class="hljs-number">0</span>        <span class="hljs-number">82431</span>M  <span class="hljs-number">0</span>.<span class="hljs-number">0347</span>                                     <span class="hljs-number">8</span>              warn</code></pre><p><strong>SIZE</strong>是存储在池中的数据量。<strong>TARGET SIZE</strong>（如果存在）是管理员指定的数据量，管理员希望最终将其存储在此池中。系统使用两个值中的较大者进行计算。</p><p><strong>RATE</strong>是池的乘数，它确定要消耗多少原始存储容量。例如，3个副本池的比率为3.0，而k = 4，m = 2纠删码池的比率为1.5。</p><p><strong>RAW CAPACITY</strong>是OSD上负责存储此池（可能还有其他池）数据的原始存储容量的总量。 <strong>比率</strong>是该池消耗的总容量的比率（即比率=大小*比率/原始容量）。</p><p><strong>TARGET RATIO</strong>（如果存在）是管理员已指定他们希望该池相对于设置了目标比率的其他池消耗的存储比率。如果同时指定了目标大小字节和比率，则比率优先。</p><p><strong>EFFECTIVE RATIO</strong>是通过两种方式进行调整后的目标比率：</p><ol><li>减去设置了目标大小的池预期使用的任何容量</li><li>设定目标比率后，对池中的目标比率进行标准化，以便它们共同针对其余空间。例如，target_ratio 1.0的4个池的有效比率为0.25。</li></ol><p>系统使用实际比率和有效比率中的较大者进行计算。</p><p><strong>PG_NUM</strong>是该池的当前PG数量（如果<code>pg_num</code> 正在进行更改，则为该池正在使用的PG的当前数量）。 系统认为应该将<code>pg_num</code>更改为<strong>NEW PG_NUM</strong>。它始终是2的幂，并且仅在“理想”值与当前值的差异大于3时才存在。</p><p>最后一列，<strong>AUTOSCALE</strong>，是池<code>pg_autoscale_mode</code>，并将于要么<code>on</code>，<code>off</code>或<code>warn</code>。</p><h2 id="5-Automated-scaling"><a href="#5-Automated-scaling" class="headerlink" title="5 Automated_scaling"></a>5 Automated_scaling</h2><h3 id="自动缩放"><a href="#自动缩放" class="headerlink" title="自动缩放"></a>自动缩放</h3><p>最简单的方法是允许群集根据使用情况自动扩展PG。Ceph将查看整个系统的PG的总可用存储量和目标数量，查看每个池中存储了多少数据，并尝试相应地分配PG。该系统的方法相对保守，仅当当前PG（<code>pg_num</code>）数量比其认为的数量多3倍时才对池进行更改。</p><p>每个OSD的PG的目标数量基于可 <code>mon_target_pg_per_osd</code>配置（默认值：100），可以通过以下方式进行调整：</p><pre><code class="hljs routeros">ceph<span class="hljs-built_in"> config </span><span class="hljs-builtin-name">set</span> global mon_target_pg_per_osd 100</code></pre><p>自动缩放器将分析池并在每个子树的基础上进行调整。因为每个池可能映射到不同的CRUSH规则，并且每个规则可能在不同的设备之间分配数据，所以Ceph将考虑独立使用层次结构的每个子树。例如，映射到ssd类的OSD的池和映射到hdd类的OSD的池将分别具有最佳PG计数，这取决于这些相应设备类型的数量。</p><h2 id="6-指定期望池大小"><a href="#6-指定期望池大小" class="headerlink" title="6 指定期望池大小"></a>6 指定期望池大小</h2><p>首次创建集群或池时，它将消耗集群总容量的一小部分，并且在系统中似乎只需要少量的放置组。但是，在大多数情况下，群集管理员会很好地知道哪些池会随着时间消耗掉大部分系统容量。通过将此信息提供给Ceph，可以从一开始就使用更合适数量的PG，从而避免进行后续调整 <code>pg_num</code>以及在进行这些调整时与移动数据相关的开销。</p><p>池的<em>目标大小</em>可以通过两种方式指定：要么以池的绝对大小（即字节）为单位，要么以相对于具有一<code>target_size_ratio</code>组其他池的权重为单位。</p><p>例如，：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">set</span> mypool target_size_bytes 100T</code></pre><p>会告诉系统mypool预计会占用100 TiB的空间。或者，：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">set</span> mypool target_size_ratio 1.0</code></pre><p>会告诉系统mypool与<code>target_size_ratio</code>set的其他池相比预期消耗1.0 。如果mypool是群集中唯一的池，则意味着预期使用了总容量的100％。如果第二个池的<code>target_size_ratio</code> 1.0，则两个池都将使用50％的群集容量。</p><p>您还可以在创建时使用命令的可选参数<code>--target-size-bytes &lt;bytes&gt;</code>或参数<code>--target-size-ratio &lt;ratio&gt;</code>设置池的目标大小。</p><p>请注意，如果指定了不可能的目标大小值（例如，容量大于整个群集的容量），则会发出健康警告（<code>POOL_TARGET_SIZE_BYTES_OVERCOMMITTED</code>）。</p><p>如果为池指定了<code>target_size_ratio</code>和<code>target_size_bytes</code>，则仅考虑比率，并发出运行状况警告（<code>POOL_HAS_TARGET_SIZE_BYTES_AND_RATIO</code>）。</p><h2 id="7-设置PG的下界"><a href="#7-设置PG的下界" class="headerlink" title="7 设置PG的下界"></a>7 设置PG的下界</h2><p>也可以为一个池指定最小数量的PG。这对于确定执行IO时客户端将看到的并行度的数量的下限很有用，即使池中大多数都是空的。设置下限可以防止Ceph将PG编号减少（或建议减少）到配置的编号以下。</p><p>您可以使用以下方法设置池的最小PG数量：</p><pre><code class="hljs pgsql">ceph osd pool <span class="hljs-keyword">set</span> &lt;pool-<span class="hljs-type">name</span>&gt; pg_num_min &lt;num&gt;</code></pre><p>您还可以使用命令的可选参数在创建池时指定最小PG计数。<code>--pg-num-min &lt;num&gt;``ceph osd pool create</code></p><h2 id="8-获取集群的PG统计信息"><a href="#8-获取集群的PG统计信息" class="headerlink" title="8 获取集群的PG统计信息"></a>8 获取集群的PG统计信息</h2><p>要获取集群中放置组的统计信息，请执行以下操作：</p><pre><code class="hljs dos">ceph pg dump [--<span class="hljs-built_in">format</span> &#123;<span class="hljs-built_in">format</span>&#125;]</code></pre><p>有效格式为<code>plain</code>（默认）和<code>json</code>。</p><h2 id="9-获取卡住的PG的统计信息"><a href="#9-获取卡住的PG的统计信息" class="headerlink" title="9 获取卡住的PG的统计信息"></a>9 获取卡住的PG的统计信息</h2><p>要获取处于指定状态的所有放置组的统计信息，请执行以下操作：</p><pre><code class="hljs coq">ceph pg dump_stuck inactive|<span class="hljs-type">unclean</span>|<span class="hljs-type">stale</span>|<span class="hljs-type">undersized</span>|<span class="hljs-type">degraded</span> [--format &lt;format&gt;] [-t|<span class="hljs-type">--threshold</span> &lt;seconds&gt;]</code></pre><p><strong>inactive</strong>放置组无法处理读写，因为它们正在等待OSD包含最新数据。</p><p><strong>unclean</strong>放置组包含未复制所需次数的对象。他们应该正在恢复。</p><p><strong>stale</strong>放置组处于未知状态-承载它们的OSD暂时未向监视集群报告（由配置<code>mon_osd_report_timeout</code>）。</p><p>有效格式为<code>plain</code>（默认）和<code>json</code>。阈值定义了放置组停留在返回的统计信息中之前所停留的最小秒数（默认为300秒）。</p><h2 id="10-获取PG-Map"><a href="#10-获取PG-Map" class="headerlink" title="10 获取PG Map"></a>10 获取PG Map</h2><p>要获取特定放置组的放置组映射，请执行以下操作：</p><pre><code class="hljs applescript">ceph pg map &#123;pg-<span class="hljs-built_in">id</span>&#125;</code></pre><p>例如：</p><pre><code class="hljs apache"><span class="hljs-attribute">ceph</span> pg map <span class="hljs-number">1</span>.<span class="hljs-number">6</span>c</code></pre><p>Ceph将返回放置组图，放置组和OSD状态：</p><pre><code class="hljs angelscript">osdmap e13 pg <span class="hljs-number">1.6</span>c (<span class="hljs-number">1.6</span>c) -&gt; up [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>] acting [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]</code></pre><p>解释一下，这里表示 pg 1.6c被映射到 编号为 [1,0]的两个OSD上。 Acting 表示Acting Set。</p><h2 id="11-获取PG统计信息"><a href="#11-获取PG统计信息" class="headerlink" title="11 获取PG统计信息"></a>11 获取PG统计信息</h2><p>要检索特定放置组的统计信息，请执行以下操作：</p><pre><code class="hljs puppet">ceph <span class="hljs-keyword">pg</span> &#123;pg-<span class="hljs-built_in">id</span>&#125; <span class="hljs-keyword">query</span></code></pre><p> 这里的query其实是一种元数据信息，部分形式如下：</p><pre><code class="hljs clojure">&#123;<span class="hljs-string">&quot;snap_trimq&quot;</span>: <span class="hljs-string">&quot;[]&quot;</span>,    <span class="hljs-string">&quot;snap_trimq_len&quot;</span>: <span class="hljs-number">0</span>,    <span class="hljs-string">&quot;state&quot;</span>: <span class="hljs-string">&quot;active+clean&quot;</span>,    <span class="hljs-string">&quot;epoch&quot;</span>: <span class="hljs-number">236</span>,    <span class="hljs-string">&quot;up&quot;</span>: [        <span class="hljs-number">1</span>,        <span class="hljs-number">2</span>,        <span class="hljs-number">0</span>    ],    <span class="hljs-string">&quot;acting&quot;</span>: [        <span class="hljs-number">1</span>,        <span class="hljs-number">2</span>,        <span class="hljs-number">0</span>    ],    <span class="hljs-string">&quot;acting_recovery_backfill&quot;</span>: [        <span class="hljs-string">&quot;0&quot;</span>,        <span class="hljs-string">&quot;1&quot;</span>,        <span class="hljs-string">&quot;2&quot;</span>    ],    <span class="hljs-string">&quot;info&quot;</span>: &#123;        <span class="hljs-string">&quot;pgid&quot;</span>: <span class="hljs-string">&quot;1.0&quot;</span>,        <span class="hljs-string">&quot;last_update&quot;</span>: <span class="hljs-string">&quot;223&#x27;23&quot;</span>,        <span class="hljs-string">&quot;last_complete&quot;</span>: <span class="hljs-string">&quot;223&#x27;23&quot;</span>,        <span class="hljs-string">&quot;log_tail&quot;</span>: <span class="hljs-string">&quot;0&#x27;0&quot;</span>,        <span class="hljs-string">&quot;last_user_version&quot;</span>: <span class="hljs-number">23</span>,        <span class="hljs-string">&quot;last_backfill&quot;</span>: <span class="hljs-string">&quot;MAX&quot;</span>,        <span class="hljs-string">&quot;purged_snaps&quot;</span>: [],        <span class="hljs-string">&quot;history&quot;</span>: &#123;            <span class="hljs-string">&quot;epoch_created&quot;</span>: <span class="hljs-number">2</span>,            <span class="hljs-string">&quot;epoch_pool_created&quot;</span>: <span class="hljs-number">2</span>,            <span class="hljs-string">&quot;last_epoch_started&quot;</span>: <span class="hljs-number">221</span>,            <span class="hljs-string">&quot;last_interval_started&quot;</span>: <span class="hljs-number">220</span>,            <span class="hljs-string">&quot;last_epoch_clean&quot;</span>: <span class="hljs-number">221</span>,            <span class="hljs-string">&quot;last_interval_clean&quot;</span>: <span class="hljs-number">220</span>,            <span class="hljs-string">&quot;last_epoch_split&quot;</span>: <span class="hljs-number">0</span>,            <span class="hljs-string">&quot;last_epoch_marked_full&quot;</span>: <span class="hljs-number">0</span>,            <span class="hljs-string">&quot;same_up_since&quot;</span>: <span class="hljs-number">220</span>,            <span class="hljs-string">&quot;same_interval_since&quot;</span>: <span class="hljs-number">220</span>,            <span class="hljs-string">&quot;same_primary_since&quot;</span>: <span class="hljs-number">212</span>,            <span class="hljs-string">&quot;last_scrub&quot;</span>: <span class="hljs-string">&quot;189&#x27;21&quot;</span>,            <span class="hljs-string">&quot;last_scrub_stamp&quot;</span>: <span class="hljs-string">&quot;2020-12-14T06:56:57.181447+0800&quot;</span>,            <span class="hljs-string">&quot;last_deep_scrub&quot;</span>: <span class="hljs-string">&quot;189&#x27;20&quot;</span>,            <span class="hljs-string">&quot;last_deep_scrub_stamp&quot;</span>: <span class="hljs-string">&quot;2020-12-13T04:09:17.431508+0800&quot;</span>,            <span class="hljs-string">&quot;last_clean_scrub_stamp&quot;</span>: <span class="hljs-string">&quot;2020-12-14T06:56:57.181447+0800&quot;</span>,            <span class="hljs-string">&quot;prior_readable_until_ub&quot;</span>: <span class="hljs-number">0</span>        &#125;,...&#125;</code></pre><p>我们可以看到很多理论部分讲过的元数据，比如 up 、acting、info、epoch、peer、interval等</p><p>当前的版本号为236.</p><h2 id="12-Scrub一个放置组"><a href="#12-Scrub一个放置组" class="headerlink" title="12 Scrub一个放置组"></a>12 Scrub一个放置组</h2><p>关于Scrub的含义，我们在《Ceph纠删码部署》已经介绍了，Scrub指数据扫描，通过读取对象数据并重新计算校验和，再与之前存储在对象属性的校验和进行比对，以判断有无静默错误（磁盘自身无法感知的错误）。要Scrub，请执行以下操作：</p><pre><code class="hljs pf">ceph pg <span class="hljs-keyword">scrub</span> &#123;pg-id&#125;</code></pre><p>Ceph检查主节点和任何副本节点，生成放置组中所有对象的目录并进行比较，以确保没有丢失或不匹配的对象，并且它们的内容一致。假设所有副本都匹配，则最终的语义扫描可确保所有与快照相关的对象元数据都是一致的。通过日志报告错误。</p><p>要从特定池中清理所有放置组，请执行以下操作：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>scrub &#123;pool-name&#125;</code></pre><h2 id="12-设置PG-Backfill-Recovery的优先级"><a href="#12-设置PG-Backfill-Recovery的优先级" class="headerlink" title="12 设置PG Backfill/Recovery的优先级"></a>12 设置PG Backfill/Recovery的优先级</h2><p>请注意，这些命令可能会破坏Ceph内部优先级计算的顺序，因此请谨慎使用！特别是，如果您有多个当前共享相同底层OSD的池，并且某些特定的池比其他池更重要，则建议您使用以下命令以更好的顺序重新排列所有池的恢复/回填优先级：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">set</span> &#123;pool-name&#125; recovery_priority &#123;value&#125;</code></pre><p>例如，如果您有10个池，则可以将最重要的一个优先级设置为10，下一个9，等等。或者您可以不理会大多数池，而说3个重要的池分别设置为优先级1或优先级3、2、1。</p><p>在恢复或者回填比用户op的优先级更高的时候。我们可以执行：</p><pre><code class="hljs applescript">ceph pg force-recovery &#123;pg-<span class="hljs-built_in">id</span>&#125; [&#123;pg-<span class="hljs-built_in">id</span> <span class="hljs-comment">#2&#125;] [&#123;pg-id #3&#125; ...]</span>ceph pg force-backfill &#123;pg-<span class="hljs-built_in">id</span>&#125; [&#123;pg-<span class="hljs-built_in">id</span> <span class="hljs-comment">#2&#125;] [&#123;pg-id #3&#125; ...]</span></code></pre><p>如果您认为这是一个不好的决定，请使用：</p><pre><code class="hljs applescript">ceph pg cancel-force-recovery &#123;pg-<span class="hljs-built_in">id</span>&#125; [&#123;pg-<span class="hljs-built_in">id</span> <span class="hljs-comment">#2&#125;] [&#123;pg-id #3&#125; ...]</span>ceph pg cancel-force-backfill &#123;pg-<span class="hljs-built_in">id</span>&#125; [&#123;pg-<span class="hljs-built_in">id</span> <span class="hljs-comment">#2&#125;] [&#123;pg-id #3&#125; ...]</span></code></pre><p>这将从这些PG中删除“ force”标志，并将以默认顺序对其进行处理。同样，这不会影响当前正在处理的放置组，只会影响仍在排队的放置组。</p><p>恢复或回填组后，将自动清除“ force”标志。</p><p>同样，您可以使用以下命令强制Ceph首先对指定池中的所有放置组执行恢复或回填：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>force-recovery &#123;pool-name&#125;ceph osd<span class="hljs-built_in"> pool </span>force-backfill &#123;pool-name&#125;</code></pre><p>要么：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>cancel-force-recovery &#123;pool-name&#125;ceph osd<span class="hljs-built_in"> pool </span>cancel-force-backfill &#123;pool-name&#125;</code></pre><p>如果您改变主意，则可以恢复到默认的恢复或回填优先级。</p><h2 id="13-还原丢失"><a href="#13-还原丢失" class="headerlink" title="13 还原丢失"></a>13 还原丢失</h2><p>如果群集丢失了一个或多个对象，并且您决定放弃对丢失数据的搜索，则必须将未找到的对象标记为<code>lost</code>。</p><p>如果已查询所有可能的位置并且仍然丢失了对象，则可能必须放弃丢失的对象。鉴于异常的异常组合使集群能够了解恢复写本身之前执行的写，这是可能的。</p><p>当前唯一受支持的选项是“还原”，它可以回滚到该对象的先前版本，或者（如果是新对象）则完全忘记它。要将“未找到”的对象标记为“丢失”，请执行以下操作：</p><pre><code class="hljs puppet">ceph <span class="hljs-keyword">pg</span> &#123;pg-<span class="hljs-built_in">id</span>&#125; <span class="hljs-keyword">mark_unfound_lost</span> <span class="hljs-keyword">revert</span>|delete</code></pre><div class="note note-danger">            <p>重要：</p><p>请谨慎使用此功能，因为它可能会使期望对象存在的应用程序感到困惑(confused)。</p>          </div><hr><p>EOF</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;迁移之美——PG读写流程与状态迁移详解&quot;&gt;&lt;a href=&quot;#迁移之美——PG读写流程与状态迁移详解&quot; class=&quot;headerlink&quot; title=&quot;迁移之美——PG读写流程与状态迁移详解&quot;&gt;&lt;/a&gt;迁移之美——PG读写流程与状态迁移详解&lt;/h1&gt;&lt;div </summary>
      
    
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/categories/ceph/"/>
    
    <category term="PG" scheme="http://durantthorvalds.top/categories/ceph/PG/"/>
    
    
    <category term="Ceph理论" scheme="http://durantthorvalds.top/tags/Ceph%E7%90%86%E8%AE%BA/"/>
    
  </entry>
  
  <entry>
    <title>距离向量路由选择算法——DV</title>
    <link href="http://durantthorvalds.top/2020/12/15/%E8%B7%9D%E7%A6%BB%E5%90%91%E9%87%8F%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95DV/"/>
    <id>http://durantthorvalds.top/2020/12/15/%E8%B7%9D%E7%A6%BB%E5%90%91%E9%87%8F%E8%B7%AF%E7%94%B1%E9%80%89%E6%8B%A9%E7%AE%97%E6%B3%95DV/</id>
    <published>2020-12-14T16:00:00.000Z</published>
    <updated>2020-12-15T10:49:51.490Z</updated>
    
    <content type="html"><![CDATA[<h1 id="距离向量路由选择算法——DV"><a href="#距离向量路由选择算法——DV" class="headerlink" title="距离向量路由选择算法——DV"></a>距离向量路由选择算法——DV</h1><p>获取全局的路由信息是代价很高的，我们需要一种分布式的、异步的、迭代的、自我终止的算法，这便是DV（$Distance  vector$），它是路由器中真正运行的算法，直到现在！</p><p>这儿的自我终止指：即没有计算应该停止的信号，它就停止了。</p><p>我们首先讨论最低路径开销之间的一种重要关系。令$d_x(y)$是从节点x到y的最低开销，由著名的Bellman-Ford方程：</p><script type="math/tex; mode=display">d_x(y)=min_v\{c(x,v)+d_v(y)\}</script><p>$c(x,y)$表示x与y之间的边的开销。这正是Dijkstra算法的核心思路。</p><p>我们令$D_x(y)$为节点x到邻近的每一个节点y的<strong>距离向量</strong>。</p><p>每个节点不时的向每个邻居发送它的距离向量副本。当节点x从它任何一个邻居v收到一个新的距离向量，它就保存，然后根据Bellford-man方程更新自己的距离向量，如果自己的距离向量发生改变，那么它向所有邻居广播更新后的距离向量。令人惊奇的是，只要所有节点都异步地交换它们的距离向量，每个开销$D_x(y)$都会收敛到$d_x(y)$!!!</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;距离向量路由选择算法——DV&quot;&gt;&lt;a href=&quot;#距离向量路由选择算法——DV&quot; class=&quot;headerlink&quot; title=&quot;距离向量路由选择算法——DV&quot;&gt;&lt;/a&gt;距离向量路由选择算法——DV&lt;/h1&gt;&lt;p&gt;获取全局的路由信息是代价很高的，我们需要一种</summary>
      
    
    
    
    <category term="算法" scheme="http://durantthorvalds.top/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="图算法" scheme="http://durantthorvalds.top/tags/%E5%9B%BE%E7%AE%97%E6%B3%95/"/>
    
    <category term="分布式" scheme="http://durantthorvalds.top/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"/>
    
  </entry>
  
  <entry>
    <title>小白投资入门（煎炸卤炖）</title>
    <link href="http://durantthorvalds.top/2020/12/14/%E5%B0%8F%E7%99%BD%E6%8A%95%E8%B5%84%E5%85%A5%E9%97%A8/"/>
    <id>http://durantthorvalds.top/2020/12/14/%E5%B0%8F%E7%99%BD%E6%8A%95%E8%B5%84%E5%85%A5%E9%97%A8/</id>
    <published>2020-12-13T16:00:00.000Z</published>
    <updated>2020-12-15T11:03:47.752Z</updated>
    
    <content type="html"><![CDATA[<h1 id="小白投资入门（煎炸卤炖）"><a href="#小白投资入门（煎炸卤炖）" class="headerlink" title="小白投资入门（煎炸卤炖）"></a>小白投资入门（煎炸卤炖）</h1><p>写这个博客表明笔者准备开始炒股了，当然任何事情都是万事开头难，希望与君共勉，踩坑。</p><p>假如小Q有1W元，如何投资才能获得最大收益：</p><ol><li>存银行</li><li>炒股</li><li>购买保险</li><li>购买基金</li><li>购买黄金</li><li>购买房地产</li><li>购买期货</li><li>全部换成美元</li><li>全部换成日元</li><li>研究“如何让钱无性生殖”</li></ol><p>上面问题便是笔者写博客的初衷，弄清楚这些问题不是简单是事，除了问题10以外。</p><h1 id="1基本概念"><a href="#1基本概念" class="headerlink" title="1基本概念"></a>1基本概念</h1><p>所谓股票，就是股份制公司发行的所有权凭证。那么公司为什么要发行股票呢？一般是为了凑集资金，非上市公司和上市公司都可以发行股票，只是非上市公司的股票不能在证券交易所交易而已。</p><h2 id="证券"><a href="#证券" class="headerlink" title="证券"></a>证券</h2><p>证券是多种经济权益凭证的统称，有很多分类，比如股票和证券。</p><h2 id="证券交易所"><a href="#证券交易所" class="headerlink" title="证券交易所"></a>证券交易所</h2><p>专门进行证券交易的场所。我国目前有四大证券交易所，分别是1990年11月26日成立的上海证券交易所，简称上交所或者沪市；1990年12月1日成立的深圳证券交易所，简称深交所；此外还有香港证券交易所和成都证券交易所。</p><p>证券交易所本身是一家公司，也可以上市，比如香港证券交易所的股票代码是00388。</p><h2 id="股市"><a href="#股市" class="headerlink" title="股市"></a>股市</h2><p>股市就是股票市场，是已经发行的股票转让、买卖和流通的场所，在我国就是指证券交易所，又称二级市场。</p><h2 id="IPO"><a href="#IPO" class="headerlink" title="IPO"></a>IPO</h2><p>指首次公开募股。通常是新上市的公司第一次发售股票。</p><h2 id="如何炒股？"><a href="#如何炒股？" class="headerlink" title="如何炒股？"></a>如何炒股？</h2><p>炒股时盈亏是兵家常事，但是如果想长期盈利，我们需要掌握正确的投资理念和搭建适合自己的交易体系，并严格指定好交易策略才能实现长期盈利。</p><h2 id="证券公司"><a href="#证券公司" class="headerlink" title="证券公司"></a>证券公司</h2><p>就是专门经营证券交易所的交易商，俗称券商。投资者通过在券商处开设账户从而去交易放在证券交易所的股票。</p><h2 id="证券账户"><a href="#证券账户" class="headerlink" title="证券账户"></a>证券账户</h2><p>我国规定每个投资者最多拥有三个账户。目前有线上和线下两种方式，最常用线上的券商包括【同花顺APP】和【东方财富】。它们的区别是，同花顺本身是一家上市公司，股票代码300033，而不是一家券商。而东方财富本身是一家券商，股票代码300059.</p><h2 id="三方管存"><a href="#三方管存" class="headerlink" title="三方管存"></a>三方管存</h2><p>全称是<strong><em>客户交易结算资金第三方管存</em></strong>，在券商开户时必须指定一张银行卡，买卖股票的资金都通过这个银行账户。</p><h1 id="2-如何看数据"><a href="#2-如何看数据" class="headerlink" title="2 如何看数据"></a>2 如何看数据</h1><h2 id="指数与点数"><a href="#指数与点数" class="headerlink" title="指数与点数"></a>指数与点数</h2><p>指数指金融机构事先制定好规则，选取一部分股票作为样本，按照某种计算方法编制乘的一组数字，目的是为了反映市场情况的变动。</p><ul><li><p>上证指数</p><p>全称【上海证券综合指数】，俗称<strong>大盘</strong>。它是把在上海证券交易所上市的所有股票按照特定的规则编制而成的一个指数，自1991年7月15日开始实时发布，一开始就是100点。其中中石油、中石化称为【两桶油】。银行、证券、保险俗称为【金三胖】。</p></li><li><p>深圳成指</p><p>全称【深圳成分股指数】，代码为399001. 它是取市场上最有代表性的500家公司编制的股票，基点为1000。</p></li><li><p>中小板指</p><p>从深交所中小板上市的所有股票中选取100只编制的股票。代码399005.</p></li><li><p>创业板指</p><p>从深交所创业板上市的所有股票中选取100只编制的股票。代码399006.</p></li><li><p>沪深300</p><p>000300</p></li><li><p>上证50</p><p>000016</p></li><li><p>中证500</p><p>主要挑选沪深两地的中小盘股票，在上海为000905，在深圳为399905.</p></li></ul><p><img src="/img/1607942239006.jpeg" alt="1607942239006"></p><h2 id="板块"><a href="#板块" class="headerlink" title="板块"></a>板块</h2><p>指证券交易所不同的交易市场，目的是支持不同类型的公司。</p><p>上交所包含主板和科创板两个。上交所主板股票代码一般以「600」、「601」或「603」开头。科创板一般以「688」开头，比如「金山办公」为688111.</p><p>深交所包括主板、中小板、创业板三个板块，中小板是专为中小型公司所开设的，创业板与其它板块区别较大，主要是因为公司在创业板上市要求更加宽松，所以上市后股票风险性更大，因而开通创业板必须去线下营业点而且要签一堆风险声明并且录视频。 深市主板代码以「000」开头，中小板以「002」开头，创业板以「300」开头。</p><h2 id="全球"><a href="#全球" class="headerlink" title="全球"></a>全球</h2><p>可以查看全球市场的大概情况，最上面是我国的沪深指数，往下依次是股指期货、汇率指数、全球商品。</p><p>「恒生指数」是香港的，「日经指数」是日本的，「富时A50」是富时指数公司选取中国市值最大的50家公司创建的指数，</p><p>「道琼斯」「纳斯达克」「标普500」是美国的，美股和「富时A50」可以影响A股走势。</p><h2 id="A股"><a href="#A股" class="headerlink" title="A股"></a>A股</h2><p>我国股市的大概情况，有三个板块，「沪深」「板块」「科创板」。</p><p>「沪深」页面最上面的上证指数、深证成指和创业板是我国A股最主要的三个指数，下面是市场概况，全部股票的涨停比例和跌停涨停比，再往下是股票排行，比如涨幅榜和跌幅榜等。</p><p>「板块」主要显示行业板块的情况，最上面是涨幅前三名的板块和跌幅前三名的板块。其中第三个页面是「创业板」，这个板块是2019年刚刚创立的，主要是支持我国科技创新的发展，对投资者而言具有较高的<strong>门槛</strong>和较大的<strong>风险</strong>。</p><h2 id="交易界面"><a href="#交易界面" class="headerlink" title="交易界面"></a>交易界面</h2><p>我们可以看到账户情况，比如总资产、浮动盈亏和当日盈亏等情况，也可以买入、卖出、撤单、持仓和查询，申购新股、国债逆回购、可转债、银证转账等功能</p><p>那么我们如何进行交易呢？</p><ul><li>通过搜索或自选解码进入股票的详情页面</li><li>点击最下面的「下单」按钮，有「分时下单」和「交易下单」两种。默认为「分时下单」。</li><li>点击「买」按钮，再次跳出新的买卖页面。</li><li>设定好合适价格，输入想要买入的数量，然后点击最下面的红色「买入」按钮。</li><li>最后会跳出询问页面，确认之前提交的信息是否有误等。点击「确认买入」</li></ul><h2 id="股市开市时间及股票交易费用"><a href="#股市开市时间及股票交易费用" class="headerlink" title="股市开市时间及股票交易费用"></a>股市开市时间及股票交易费用</h2><p>我国A股交易时间为周一至周五上午9：30-11：30，下午13：00-15：00， 其中9：15-9：25，下午14：57-15：00是集合竞价的时间，具体概念我们后面再讲。</p><p>股票交易一般包含以下几种费用：</p><ul><li>佣金：券商收取，买卖都要收，每笔最低5元，如果超过后则按万分之3或万分之2.5.</li><li>印花税：国税局收取，卖出股票时收取，比例为成交金额的0.1%</li><li>过户费：上交所收取，交易沪市股票时收取，为成交金额的0.002%。</li><li>规费：视券商而定。</li></ul><h2 id="K线"><a href="#K线" class="headerlink" title="K线"></a>K线</h2><p>k线图又称为蜡烛图、日本线、阴阳线。它源于日本德川幕府时代。它是一个竖着的长方体，如下图所示。</p><p><img src="/img/1607943017765.jpeg" alt="1607943017765" style="zoom:67%;" /></p><p>如果上影线较长，上方抛压较大，股价上涨后又被砸了回来，有长下影线则表示下方买盘较强，股价跌了下去又被买了回来。红色表示阳K线，绿色表示阴K线。红表示涨，即开盘价小于收盘价，绿表示跌。</p><p><img src="/img/1607943072426.jpeg" alt="1607943072426"></p><p><strong>注意不要把技术指标当作买卖的标准。</strong></p><p>我们有【假阴线】和【假阳线】两种说法，假阳线指收盘价比前一根K线的收盘价要低。假阳线表示收盘价全部比各自前一天的收盘价要高</p><p><img src="/img/v2-e6d2b7984a2228522f4012c2af96436e.jpg" alt="v2-e6d2b7984a2228522f4012c2af96436e"></p><h2 id="均线"><a href="#均线" class="headerlink" title="均线"></a>均线</h2><h2 id="成交量"><a href="#成交量" class="headerlink" title="成交量"></a>成交量</h2><h2 id="MACD"><a href="#MACD" class="headerlink" title="MACD"></a>MACD</h2>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;小白投资入门（煎炸卤炖）&quot;&gt;&lt;a href=&quot;#小白投资入门（煎炸卤炖）&quot; class=&quot;headerlink&quot; title=&quot;小白投资入门（煎炸卤炖）&quot;&gt;&lt;/a&gt;小白投资入门（煎炸卤炖）&lt;/h1&gt;&lt;p&gt;写这个博客表明笔者准备开始炒股了，当然任何事情都是万事开头难</summary>
      
    
    
    
    <category term="投资" scheme="http://durantthorvalds.top/categories/%E6%8A%95%E8%B5%84/"/>
    
    
    <category term="股票" scheme="http://durantthorvalds.top/tags/%E8%82%A1%E7%A5%A8/"/>
    
  </entry>
  
  <entry>
    <title>「参考」Ceph Pool</title>
    <link href="http://durantthorvalds.top/2020/12/14/ceph%20pool/"/>
    <id>http://durantthorvalds.top/2020/12/14/ceph%20pool/</id>
    <published>2020-12-13T16:00:00.000Z</published>
    <updated>2020-12-16T08:33:23.524Z</updated>
    
    <content type="html"><![CDATA[<div class="note note-primary">            <p>本期主要介绍Ceph pool的操作，需要您事先部署成功Ceph集群！</p><p>主要参考<a href="https://docs.ceph.com/en/latest/rados/operations/pools/">官方pool教程</a>。</p>          </div><h1 id="Ceph-pool"><a href="#Ceph-pool" class="headerlink" title="Ceph pool"></a>Ceph pool</h1><p>池是用于存储对象的逻辑分区。</p><p>当首次部署群集而不创建池时，Ceph使用默认池来存储数据。pool具有以下特性：</p><ul><li><strong>弹性</strong>：可以设置允许多少OSD发生故障而不丢失数据。对于复制池，它是对象的所需副本数/副本数。典型的配置存储一个对象和一个附加副本（即<code>size=2</code>），但是您可以确定副本/副本的数量。对于<a href="https://docs.ceph.com/en/latest/rados/operations/erasure-code">纠删码池</a>，它是编码块的数量<code>m=2</code></li><li><strong>放置组</strong>(PG)：可以设置池的放置组数。一个典型的配置每个OSD使用大约100个放置组，以提供最佳的平衡，而不会消耗太多的计算资源。设置多个池时，请确保为池和整个群集设置合理数量的放置组。</li><li><strong>CRUSH规则</strong>：将数据存储在池中时，对象及其副本（或用于纠删码池的块）在群集中的位置由CRUSH规则控制。如果默认规则不适用于您的用例，则可以为池创建自定义的CRUSH规则。</li><li><strong>快照</strong>：使用创建快照时，可以有效地为特定池拍摄快照。<code>ceph osd pool mksnap</code></li></ul><p>要列出群集的池，请执行：</p><pre><code class="hljs ebnf"><span class="hljs-attribute">ceph osd lspools</span></code></pre><h2 id="1-创建一个池"><a href="#1-创建一个池" class="headerlink" title="1 创建一个池"></a>1 创建一个池</h2><p>在创建池之前，我们有必要修改Ceph配置文件，它位于<code>\etc\ceph.conf</code>，典型的ceph配置文件如下：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>create &#123;pool-name&#125; [&#123;pg-num&#125; [&#123;pgp-num&#125;]] [replicated] \     [crush-rule-name] [expected-num-objects]ceph osd<span class="hljs-built_in"> pool </span>create &#123;pool-name&#125; [&#123;pg-num&#125; [&#123;pgp-num&#125;]]   erasure \     [erasure-code-profile] [crush-rule-name] [expected_num_objects] [<span class="hljs-attribute">--autoscale-mode</span>=&lt;on,off,warn&gt;]</code></pre><p>我们对几个比较重要的参数进行讲解：</p><ul><li><code>replicated|erasure</code></li></ul><p>官方有这样一句话。副本池需要更多的空间但是实现了Ceph所有操作，而纠删码池只实现了一部分的功能。主要是因为纠删码不支持omap，所以只能采用FileStore。</p><p>实例：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>create ecpool erasure</code></pre><h2 id=""><a href="#" class="headerlink" title=" "></a> </h2><h2 id="2-将池关联到应用程序"><a href="#2-将池关联到应用程序" class="headerlink" title="2 将池关联到应用程序"></a>2 将池关联到应用程序</h2><p>池在使用前需要与应用程序关联。将与CephFS一起使用的池或RGW自动创建的池自动关联。打算与RBD一起使用的池应使用该<code>rbd</code>工具进行初始化（有关更多信息，请参见<a href="https://docs.ceph.com/en/latest/rbd/rados-rbd-cmds/#create-a-block-device-pool">块设备命令</a>）。</p><p>对于其他情况，您可以手动将自由格式的应用程序名称关联到池。</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>application <span class="hljs-builtin-name">enable</span> &#123;pool-name&#125; &#123;application-name&#125;</code></pre><p>提示：</p><p>CephFS使用应用程序名称<code>cephfs</code>，RBD使用应用程序名称<code>rbd</code>，而RGW使用应用程序名称<code>rgw</code>。</p><h2 id="3-设置池配额"><a href="#3-设置池配额" class="headerlink" title="3 设置池配额"></a>3 设置池配额</h2><p>您可以将池配额设置为每个池的最大字节数和/或最大对象数。</p><pre><code class="hljs dsconfig"><span class="hljs-string">ceph </span><span class="hljs-string">osd </span><span class="hljs-string">pool </span><span class="hljs-built_in">set-quota</span> &#123;<span class="hljs-string">pool-name&#125;</span> [<span class="hljs-string">max_objects </span>&#123;<span class="hljs-string">obj-count&#125;</span>] [<span class="hljs-string">max_bytes </span>&#123;<span class="hljs-string">bytes&#125;</span>]</code></pre><p>例如：</p><pre><code class="hljs dsconfig"><span class="hljs-string">ceph </span><span class="hljs-string">osd </span><span class="hljs-string">pool </span><span class="hljs-built_in">set-quota</span> <span class="hljs-string">data </span><span class="hljs-string">max_objects </span><span class="hljs-string">10000</span></code></pre><p>要删除配额，请将其值设置为<code>0</code>。</p><h2 id="4-删除池"><a href="#4-删除池" class="headerlink" title="4 删除池"></a>4 删除池</h2><p>要删除池，请执行：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>delete &#123;pool-name&#125; [&#123;pool-name&#125; --yes-i-really-really-mean-it]</code></pre><p>要删除池，必须在Monitor的配置中将mon_allow_pool_delete标志设置为true。否则，他们将拒绝删除池。</p><p>有关更多信息，请参见<a href="https://docs.ceph.com/en/latest/rados/configuration/mon-config-ref">Monitor Configuration</a>。</p><p>如果您为自己创建的池创建了自己的规则，则在不再需要池时应考虑删除它们：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">get</span> &#123;pool-name&#125; crush_rule</code></pre><p>例如，如果规则是“ 123”，则可以像这样检查其他池：</p><pre><code class="hljs gradle">ceph osd <span class="hljs-keyword">dump</span> | <span class="hljs-keyword">grep</span> <span class="hljs-string">&quot;^pool&quot;</span> | <span class="hljs-keyword">grep</span> <span class="hljs-string">&quot;crush_rule 123&quot;</span></code></pre><p>通过ceph osd dump可以查看monitor的映射信息，包括epoch，fsid和crush rule等。返回结果如下</p><pre><code class="hljs pgsql">pool <span class="hljs-number">1</span> <span class="hljs-string">&#x27;device_health_metrics&#x27;</span> replicated size <span class="hljs-number">3</span> min_size <span class="hljs-number">2</span> crush_rule <span class="hljs-number">0</span> object_hash rjenkins pg_num <span class="hljs-number">1</span> pgp_num <span class="hljs-number">1</span> autoscale_mode <span class="hljs-keyword">on</span> last_change <span class="hljs-number">13</span> flags hashpspool stripe_width <span class="hljs-number">0</span> pg_num_min <span class="hljs-number">1</span> application mgr_devicehealthpool <span class="hljs-number">2</span> <span class="hljs-string">&#x27;cephfs_data&#x27;</span> replicated size <span class="hljs-number">3</span> min_size <span class="hljs-number">2</span> crush_rule <span class="hljs-number">0</span> object_hash rjenkins pg_num <span class="hljs-number">32</span> pgp_num <span class="hljs-number">32</span> autoscale_mode <span class="hljs-keyword">on</span> last_change <span class="hljs-number">17</span> flags hashpspool stripe_width <span class="hljs-number">0</span> application cephfspool <span class="hljs-number">3</span> <span class="hljs-string">&#x27;cephfs_metadata&#x27;</span> replicated size <span class="hljs-number">3</span> min_size <span class="hljs-number">2</span> crush_rule <span class="hljs-number">0</span> object_hash rjenkins pg_num <span class="hljs-number">32</span> pgp_num <span class="hljs-number">32</span> autoscale_mode <span class="hljs-keyword">on</span> last_change <span class="hljs-number">18</span> flags hashpspool stripe_width <span class="hljs-number">0</span> pg_autoscale_bias <span class="hljs-number">4</span> pg_num_min <span class="hljs-number">16</span> recovery_priority <span class="hljs-number">5</span> application cephfspool <span class="hljs-number">4</span> <span class="hljs-string">&#x27;ecpool&#x27;</span> erasure profile toy_ec size <span class="hljs-number">3</span> min_size <span class="hljs-number">2</span> crush_rule <span class="hljs-number">1</span> object_hash rjenkins pg_num <span class="hljs-number">16</span> pgp_num <span class="hljs-number">16</span> autoscale_mode <span class="hljs-keyword">on</span> last_change <span class="hljs-number">65</span> flags hashpspool,ec_overwrites stripe_width <span class="hljs-number">8192</span> application rgw</code></pre><p>如果没有其他池使用该自定义规则，则可以从群集中删除该规则。</p><p>如果您创建的用户严格地具有不再存在的池的权限，则也应该考虑删除这些用户：</p><pre><code class="hljs dust"><span class="xml">ceph auth ls | grep -C 5 </span><span class="hljs-template-variable">&#123;pool-name&#125;</span><span class="xml">ceph auth del </span><span class="hljs-template-variable">&#123;user&#125;</span></code></pre><h2 id="5-重命名池"><a href="#5-重命名池" class="headerlink" title="5 重命名池"></a>5 重命名池</h2><p>要重命名池，请执行：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>rename &#123;current-pool-name&#125; &#123;new-pool-name&#125;</code></pre><p>如果重命名池，并且您具有针对经过身份验证的用户的每个池功能，则必须使用新的池名称更新用户的功能（即上限）。</p><h2 id="6-显示池统计信息"><a href="#6-显示池统计信息" class="headerlink" title="6 显示池统计信息"></a>6 显示池统计信息</h2><p>要显示池的利用率统计信息，请执行：</p><pre><code class="hljs ebnf"><span class="hljs-attribute">rados df</span></code></pre><p>返回如下</p><pre><code class="hljs apache"><span class="hljs-attribute">POOL_NAME</span>                 USED  OBJECTS  CLONES  COPIES  MISSING_ON_PRIMARY  UNFOUND  DEGRADED  RD_OPS       RD  WR_OPS      WR  USED COMPR  UNDER COMPR<span class="hljs-attribute">cephfs_data</span>                <span class="hljs-number">0</span> B        <span class="hljs-number">0</span>       <span class="hljs-number">0</span>       <span class="hljs-number">0</span>                   <span class="hljs-number">0</span>        <span class="hljs-number">0</span>         <span class="hljs-number">0</span>       <span class="hljs-number">0</span>      <span class="hljs-number">0</span> B       <span class="hljs-number">0</span>     <span class="hljs-number">0</span> B         <span class="hljs-number">0</span> B          <span class="hljs-number">0</span> B<span class="hljs-attribute">cephfs_metadata</span>        <span class="hljs-number">156</span> KiB       <span class="hljs-number">22</span>       <span class="hljs-number">0</span>      <span class="hljs-number">66</span>                   <span class="hljs-number">0</span>        <span class="hljs-number">0</span>         <span class="hljs-number">0</span>     <span class="hljs-number">362</span>  <span class="hljs-number">382</span> KiB      <span class="hljs-number">70</span>  <span class="hljs-number">24</span> KiB         <span class="hljs-number">0</span> B          <span class="hljs-number">0</span> B<span class="hljs-attribute">device_health_metrics</span>   <span class="hljs-number">15</span> KiB        <span class="hljs-number">1</span>       <span class="hljs-number">0</span>       <span class="hljs-number">3</span>                   <span class="hljs-number">0</span>        <span class="hljs-number">0</span>         <span class="hljs-number">0</span>      <span class="hljs-number">17</span>   <span class="hljs-number">17</span> KiB      <span class="hljs-number">19</span>  <span class="hljs-number">19</span> KiB         <span class="hljs-number">0</span> B          <span class="hljs-number">0</span> B<span class="hljs-attribute">ecpool</span>                  <span class="hljs-number">12</span> KiB        <span class="hljs-number">1</span>       <span class="hljs-number">0</span>       <span class="hljs-number">3</span>                   <span class="hljs-number">0</span>        <span class="hljs-number">0</span>         <span class="hljs-number">0</span>       <span class="hljs-number">0</span>      <span class="hljs-number">0</span> B       <span class="hljs-number">3</span>   <span class="hljs-number">3</span> KiB         <span class="hljs-number">0</span> B          <span class="hljs-number">0</span> B<span class="hljs-attribute">total_objects</span>    <span class="hljs-number">24</span><span class="hljs-attribute">total_used</span>       <span class="hljs-number">3</span>.<span class="hljs-number">0</span> GiB<span class="hljs-attribute">total_avail</span>      <span class="hljs-number">57</span> GiB<span class="hljs-attribute">total_space</span>      <span class="hljs-number">60</span> GiB</code></pre><p>此外，要获取特定池或全部池的I / O信息，请执行以下操作：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>stats [&#123;pool-name&#125;]</code></pre><h2 id="7-制作池快照"><a href="#7-制作池快照" class="headerlink" title="7 制作池快照"></a>7 制作池快照</h2><p>要制作池的快照，请执行：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>mksnap &#123;pool-name&#125; &#123;snap-name&#125;</code></pre><h2 id="8-删除池快照"><a href="#8-删除池快照" class="headerlink" title="8 删除池快照"></a>8 删除池快照</h2><p>要删除池的快照，请执行：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span>rmsnap &#123;pool-name&#125; &#123;snap-name&#125;</code></pre><h2 id="9-设置对象副本数"><a href="#9-设置对象副本数" class="headerlink" title="9 设置对象副本数"></a>9 设置对象副本数</h2><p>要设置复制池上对象副本的数量，请执行以下操作：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">set</span> &#123;poolname&#125; size &#123;num-replicas&#125;</code></pre><div class="note note-danger">            <p>重要</p><p><code>{num-replicas}</code>包括所述对象本身。如果您需要该对象和该对象的两个副本，以总共三个对象的实例，请指定<code>3</code>。</p>          </div><p>例如：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">set</span> data size 3</code></pre><p>您可以为每个池执行此命令。<strong>注意：</strong>对象在降级模式下接受的I / O可能少于副本。要设置I / O所需的最小副本数，应使用该设置。例如：<code>pool size``min_size</code></p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">set</span> data min_size 2</code></pre><p>这样可以确保数据池中的任何对象都不会收到少于<code>min_size</code>副本的I / O。</p><h2 id="10-获取对象副本数"><a href="#10-获取对象副本数" class="headerlink" title="10 获取对象副本数"></a>10 获取对象副本数</h2><p>要获取对象副本的数量，请执行以下操作：</p><pre><code class="hljs gradle">ceph osd <span class="hljs-keyword">dump</span> | <span class="hljs-keyword">grep</span> <span class="hljs-string">&#x27;replicated size&#x27;</span></code></pre><p>Ceph将列出池，并突出显示该属性。默认情况下，ceph创建一个对象的两个副本（共三个副本，或3个大小）。<code>replicated size</code></p><h2 id="11-池值"><a href="#11-池值" class="headerlink" title="11 池值"></a>11 池值</h2><p>要将值设置为池，请执行以下操作：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">set</span> &#123;pool-name&#125; &#123;key&#125; &#123;value&#125;</code></pre><p>您可以为以下键设置值：</p><pre><code class="hljs ebnf"><span class="hljs-attribute">compression_algorithm</span></code></pre><ul><li><p>描述</p><p>设置用于基础BlueStore的内联压缩算法。此设置将覆盖<a href="https://docs.ceph.com/en/latest/rados/configuration/bluestore-config-ref/#inline-compression">全局设置</a>的。<code>bluestore compression algorithm</code></p></li><li><p>类型</p><p>串</p></li><li><p>有效设定</p><p><code>lz4</code>，<code>snappy</code>，<code>zlib</code>，<code>zstd</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">compression_mode</span></code></pre><ul><li><p>描述</p><p>为基础BlueStore设置嵌入式压缩算法的策略。此设置将覆盖<a href="http://docs.ceph.com/en/latest/rados/configuration/bluestore-config-ref/#inline-compression">全局设置</a>的。<code>bluestore compression mode</code></p></li><li><p>类型</p><p>串</p></li><li><p>有效设定</p><p><code>none</code>，<code>passive</code>，<code>aggressive</code>，<code>force</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">compression_min_blob_size</span></code></pre><ul><li><p>描述</p><p>小于此大小的块永远不会被压缩。此设置将覆盖<a href="http://docs.ceph.com/en/latest/rados/configuration/bluestore-config-ref/#inline-compression">全局设置</a>的。<code>bluestore compression min blob *</code></p></li><li><p>类型</p><p>无符号整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">compression_max_blob_size</span></code></pre><ul><li><p>描述</p><p>大于此的块<code>compression_max_blob_size</code>在压缩之前会分解为较小的斑点大小 。</p></li><li><p>类型</p><p>无符号整数</p></li></ul><pre><code class="hljs arduino"><span class="hljs-built_in">size</span></code></pre><ul><li><p>描述</p><p>设置池中对象的副本数。有关更多详细信息，请参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#set-the-number-of-object-replicas">设置对象副本数</a>。仅复制池。</p></li><li><p>类型</p><p>整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">min_size</span></code></pre><ul><li><p>描述</p><p>设置I / O所需的最小副本数。有关更多详细信息，请参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#set-the-number-of-object-replicas">设置对象副本数</a>。对于擦除编码池，应将其设置为大于“ k”的值，因为如果我们将IO的值设置为“ k”，则不会出现冗余，并且如果OSD永久性故障，数据将会丢失。有关更多信息，请参见<a href="https://docs.ceph.com/en/latest/rados/operations/erasure-code">擦除代码</a></p></li><li><p>类型</p><p>整数</p></li><li><p>版</p><p><code>0.54</code> 以上</p></li></ul><pre><code class="hljs pgsql">pg_num</code></pre><ul><li><p>描述</p><p>计算数据放置时要使用的放置组的有效数量。</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>优于<code>pg_num</code>当前值。</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">pgp_num</span></code></pre><ul><li><p>描述</p><p>计算数据放置时要使用的放置的有效放置组数。</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>等于或小于<code>pg_num</code>。</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">crush_rule</span></code></pre><ul><li><p>描述</p><p>用于在集群中映射对象放置的规则。</p></li><li><p>类型</p><p>串</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">allow_ec_overwrites</span></code></pre><ul><li><p>描述</p><p>是否写入擦除代码池可以更新对象的一部分，因此cephfs和rbd可以使用它。有关更多详细信息，请参见 <a href="https://docs.ceph.com/en/latest/rados/operations/erasure-code#erasure-coding-with-overwrites">带覆盖的擦除编码</a>。</p></li><li><p>类型</p><p>布尔型</p></li><li><p>版</p><p><code>12.2.0</code> 以上</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hashpspool</span></code></pre><ul><li><p>描述</p><p>在给定的池上设置/取消设置HASHPSPOOL标志。</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>1个设置标志，0个未设置标志</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">nodelete</span></code></pre><ul><li><p>描述</p><p>在给定的池上设置/取消设置NODELETE标志。</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>1个设置标志，0个未设置标志</p></li><li><p>版</p><p>版 <code>FIXME</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">nopgchange</span></code></pre><ul><li><p>描述</p><p>在给定的池上设置/取消设置NOPGCHANGE标志。</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>1个设置标志，0个未设置标志</p></li><li><p>版</p><p>版 <code>FIXME</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">nosizechange</span></code></pre><ul><li><p>描述</p><p>在给定的池上设置/取消设置NOSIZECHANGE标志。</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>1个设置标志，0个未设置标志</p></li><li><p>版</p><p>版 <code>FIXME</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">write_fadvise_dontneed</span></code></pre><ul><li><p>描述</p><p>在给定的池上设置/取消设置WRITE_FADVISE_DONTNEED标志。</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>1个设置标志，0个未设置标志</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">noscrub</span></code></pre><ul><li><p>描述</p><p>在给定的池上设置/取消设置NOSCRUB标志。</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>1个设置标志，0个未设置标志</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">nodeep-scrub</span></code></pre><ul><li><p>描述</p><p>在给定的池上设置/取消设置NODEEP_SCRUB标志。</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>1个设置标志，0个未设置标志</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hit_set_type</span></code></pre><ul><li><p>描述</p><p>对高速缓存池启用命中集跟踪。有关其他信息，请参见<a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom Filter</a>。</p></li><li><p>类型</p><p>串</p></li><li><p>有效设定</p><p><code>bloom</code>，<code>explicit_hash</code>，<code>explicit_object</code></p></li><li><p>默认</p><p><code>bloom</code>。其他值用于测试。</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hit_set_count</span></code></pre><ul><li><p>描述</p><p>要为高速缓存池存储的命中集的数量。该数字越高，<code>ceph-osd</code>守护程序消耗的RAM就越多。</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p><code>1</code>。代理尚未处理&gt; 1。</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hit_set_period</span></code></pre><ul><li><p>描述</p><p>高速缓存池的命中设置周期的持续时间（以秒为单位）。该数字越高，<code>ceph-osd</code>守护程序消耗的RAM就越多 。</p></li><li><p>类型</p><p>整数</p></li><li><p>例</p><p><code>3600</code> 1小时</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hit_set_fpp</span></code></pre><ul><li><p>描述</p><p><code>bloom</code>匹配集类型的误报概率。有关其他信息，请参见<a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom Filter</a>。</p></li><li><p>类型</p><p>双</p></li><li><p>有效范围</p><p>0.0-1.0</p></li><li><p>默认</p><p><code>0.05</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">cache_target_dirty_ratio</span></code></pre><ul><li><p>描述</p><p>在缓存分层代理将其刷新到后备存储池之前，包含修改后的（脏）对象的缓存池的百分比。</p></li><li><p>类型</p><p>双</p></li><li><p>默认</p><p><code>.4</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">cache_target_dirty_high_ratio</span></code></pre><ul><li><p>描述</p><p>在缓存分层代理将其以较高速度刷新到后备存储池之前，包含修改后的（脏）对象的缓存池的百分比。</p></li><li><p>类型</p><p>双</p></li><li><p>默认</p><p><code>.6</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">cache_target_full_ratio</span></code></pre><ul><li><p>描述</p><p>在缓存分层代理将其从缓存池中驱逐之前，包含未修改（干净）对象的缓存池的百分比。</p></li><li><p>类型</p><p>双</p></li><li><p>默认</p><p><code>.8</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">target_max_bytes</span></code></pre><ul><li><p>描述</p><p><code>max_bytes</code>触发阈值时，Ceph将开始刷新或逐出对象 。</p></li><li><p>类型</p><p>整数</p></li><li><p>例</p><p><code>1000000000000</code> ＃1-TB</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">target_max_objects</span></code></pre><ul><li><p>描述</p><p><code>max_objects</code>触发阈值时，Ceph将开始刷新或逐出对象 。</p></li><li><p>类型</p><p>整数</p></li><li><p>例</p><p><code>1000000</code> ＃1M个对象</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hit_set_grade_decay_rate</span></code></pre><ul><li><p>描述</p><p>两个连续命中点之间的温度衰减率</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>0-100</p></li><li><p>默认</p><p><code>20</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hit_set_search_last_n</span></code></pre><ul><li><p>描述</p><p>计算hit_sets中最多N个出现以进行温度计算</p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>0-hit_set_count</p></li><li><p>默认</p><p><code>1</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">cache_min_flush_age</span></code></pre><ul><li><p>描述</p><p>缓存分层代理将对象从缓存池刷新到存储池之前的时间（以秒为单位）。</p></li><li><p>类型</p><p>整数</p></li><li><p>例</p><p><code>600</code> 10分钟</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">cache_min_evict_age</span></code></pre><ul><li><p>描述</p><p>缓存分层代理将对象从缓存池中逐出之前的时间（以秒为单位）。</p></li><li><p>类型</p><p>整数</p></li><li><p>例</p><p><code>1800</code> 30分钟</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">fast_read</span></code></pre><ul><li><p>描述</p><p>在擦除编码池上，如果打开此标志，则读取请求将对所有分片发出子读取，并等待直到接收到足够的分片以解码以服务于客户端。对于jerasure和isaerasure插件，一旦返回第一个K答复，就会使用从这些答复中解码的数据立即满足客户的请求。这有助于权衡一些资源以获得更好的性能。当前，仅擦除编码池支持此标志。</p></li><li><p>类型</p><p>布尔型</p></li><li><p>默认值</p><p><code>0</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">scrub_min_interval</span></code></pre><ul><li><p>描述</p><p>负载低时最小时间间隔（以秒为单位）。如果为0，则使用config中的osd_scrub_min_interval值。</p></li><li><p>类型</p><p>双</p></li><li><p>默认</p><p><code>0</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">scrub_max_interval</span></code></pre><ul><li><p>描述</p><p>池清理的最大时间间隔（以秒为单位），与群集负载无关。如果为0，则使用config中的osd_scrub_max_interval值。</p></li><li><p>类型</p><p>双</p></li><li><p>默认</p><p><code>0</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">deep_scrub_interval</span></code></pre><ul><li><p>描述</p><p>池“深度”清理的时间间隔（以秒为单位）。如果为0，则使用config中的osd_deep_scrub_interval值。</p></li><li><p>类型</p><p>双</p></li><li><p>默认</p><p><code>0</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">recovery_priority</span></code></pre><ul><li><p>描述</p><p>设置值后，它将增加或减少计算出的预留优先级。此值的范围必须在-10到10之间。对于不太重要的池，请使用负优先级，以使它们的优先级低于任何新池。</p></li><li><p>类型</p><p>整数</p></li><li><p>默认</p><p><code>0</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">recovery_op_priority</span></code></pre><ul><li><p>描述</p><p>指定该池的恢复操作优先级，而不要指定<code>osd_recovery_op_priority</code>。</p></li><li><p>类型</p><p>整数</p></li><li><p>默认</p><p><code>0</code></p></li></ul><h2 id="12-获取池值"><a href="#12-获取池值" class="headerlink" title="12 获取池值"></a>12 获取池值</h2><p>要从池中获取值，请执行以下操作：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">get</span> &#123;pool-name&#125; &#123;key&#125;</code></pre><p>您可能会获得以下键的值：</p><pre><code class="hljs arduino"><span class="hljs-built_in">size</span></code></pre><ul><li><p>描述</p><p>看<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#size">大小</a></p></li><li><p>类型</p><p>整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">min_size</span></code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#min-size">min_size</a></p></li><li><p>类型</p><p>整数</p></li><li><p>版</p><p><code>0.54</code> 以上</p></li></ul><pre><code class="hljs pgsql">pg_num</code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#pg-num">pg_num</a></p></li><li><p>类型</p><p>整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">pgp_num</span></code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#pgp-num">pgp_num</a></p></li><li><p>类型</p><p>整数</p></li><li><p>有效范围</p><p>等于或小于<code>pg_num</code>。</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">crush_rule</span></code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#crush-rule">rush_rule</a></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hit_set_type</span></code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#hit-set-type">hit_set_type</a></p></li><li><p>类型</p><p>串</p></li><li><p>有效设定</p><p><code>bloom</code>，<code>explicit_hash</code>，<code>explicit_object</code></p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hit_set_count</span></code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#hit-set-count">hit_set_count</a></p></li><li><p>类型</p><p>整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hit_set_period</span></code></pre><ul><li><p>描述</p><p>参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#hit-set-period">hit_set_period</a></p></li><li><p>类型</p><p>整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">hit_set_fpp</span></code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#hit-set-fpp">hit_set_fpp</a></p></li><li><p>类型</p><p>双</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">cache_target_dirty_ratio</span></code></pre><ul><li><p>描述</p><p>参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#cache-target-dirty-ratio">cache_target_dirty_ratio</a></p></li><li><p>类型</p><p>双</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">cache_target_dirty_high_ratio</span></code></pre><ul><li><p>描述</p><p>参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#cache-target-dirty-high-ratio">cache_target_dirty_high_ratio</a></p></li><li><p>类型</p><p>双</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">cache_target_full_ratio</span></code></pre><ul><li><p>描述</p><p>请参阅<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#cache-target-full-ratio">cache_target_full_ratio</a></p></li><li><p>类型</p><p>双</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">target_max_bytes</span></code></pre><ul><li><p>描述</p><p>参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#target-max-bytes">target_max_bytes</a></p></li><li><p>类型</p><p>整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">target_max_objects</span></code></pre><ul><li><p>描述</p><p>参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#target-max-objects">target_max_objects</a></p></li><li><p>类型</p><p>整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">cache_min_flush_age</span></code></pre><ul><li><p>描述</p><p>参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#cache-min-flush-age">cache_min_flush_age</a></p></li><li><p>类型</p><p>整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">cache_min_evict_age</span></code></pre><ul><li><p>描述</p><p>参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#cache-min-evict-age">cache_min_evict_age</a></p></li><li><p>类型</p><p>整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">fast_read</span></code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#fast-read">fast_read</a></p></li><li><p>类型</p><p>布尔型</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">scrub_min_interval</span></code></pre><ul><li><p>描述</p><p>参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#scrub-min-interval">scrub_min_interval</a></p></li><li><p>类型</p><p>双</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">scrub_max_interval</span></code></pre><ul><li><p>描述</p><p>参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#scrub-max-interval">scrub_max_interval</a></p></li><li><p>类型</p><p>双</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">deep_scrub_interval</span></code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#deep-scrub-interval">deep_scrub_interval</a></p></li><li><p>类型</p><p>双</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">allow_ec_overwrites</span></code></pre><ul><li><p>描述</p><p>参见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#allow-ec-overwrites">allow_ec_overwrites</a></p></li><li><p>类型</p><p>布尔型</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">recovery_priority</span></code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#recovery-priority">recovery_priority</a></p></li><li><p>类型</p><p>整数</p></li></ul><pre><code class="hljs ebnf"><span class="hljs-attribute">recovery_op_priority</span></code></pre><ul><li><p>描述</p><p>见<a href="https://docs.ceph.com/en/latest/rados/operations/pools/#recovery-op-priority">recovery_op_priority</a></p></li><li><p>类型</p><p>整数</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note note-primary&quot;&gt;
            &lt;p&gt;本期主要介绍Ceph pool的操作，需要您事先部署成功Ceph集群！&lt;/p&gt;&lt;p&gt;主要参考&lt;a href=&quot;https://docs.ceph.com/en/latest/rados/</summary>
      
    
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/categories/ceph/"/>
    
    
    <category term="Ceph实践" scheme="http://durantthorvalds.top/tags/Ceph%E5%AE%9E%E8%B7%B5/"/>
    
  </entry>
  
  <entry>
    <title>kNN算法实现人脸识别</title>
    <link href="http://durantthorvalds.top/2020/12/12/kNN%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/"/>
    <id>http://durantthorvalds.top/2020/12/12/kNN%E7%AE%97%E6%B3%95%E5%AE%9E%E7%8E%B0%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB/</id>
    <published>2020-12-11T16:00:00.000Z</published>
    <updated>2020-12-16T08:31:01.582Z</updated>
    
    <content type="html"><![CDATA[<h1 id="kNN算法实现人脸识别"><a href="#kNN算法实现人脸识别" class="headerlink" title="kNN算法实现人脸识别"></a>kNN算法实现人脸识别</h1><blockquote><p>代表论文：</p><p><a href="http://www.stanford.edu/~hastie/Papers/dann_IEEE.pdf">http://www.stanford.edu/~hastie/Papers/dann_IEEE.pdf</a></p></blockquote><p>kNN算法属于监督学习，而且是一种典型的“懒惰学习算法”，kNN算法流程如下：</p><p>  1）算距离：给定测试对象，计算它与训练集中的每个对象的距离<br>  2）找邻居：圈定距离最近的k个训练对象，作为测试对象的近邻<br>  3）做分类：根据这k个近邻归属的主要类别，来对测试对象分类</p><script type="math/tex; mode=display">d(x,y) = \sqrt{\sum\limits_{i=1}^{n}(x_i-y_i)^2}</script><p>k太小，分类结果易受噪声点影响；k太大，近邻中又可能包含太多的其它类别的点。（对距离加权，可以降低k值设定的影响）<br>k值通常是采用交叉检验来确定（以k=1为基准）<br>经验规则：k一般低于训练样本数的平方根</p><p>1、优点<br>简单，易于理解，易于实现，无需估计参数，无需训练<br>适合对稀有事件进行分类（例如当流失率很低时，比如低于0.5%，构造流失预测模型）<br>特别适合于多分类问题(multi-modal,对象具有多个类别标签)，例如根据基因特征来判断其功能分类，kNN比SVM的表现要好</p><p>2、缺点<br>懒惰算法，对测试样本分类时的计算量大，内存开销大，评分慢<br>可解释性较差，无法给出决策树那样的规则</p><h2 id="人脸识别指标"><a href="#人脸识别指标" class="headerlink" title="人脸识别指标"></a>人脸识别指标</h2><p>虽然跑库的时候我们一般还是看Accuracy或者Recall，不过其实实际应用的时候更多的是会用TAR(True Accept Rate)和FAR(False Accept Rate)。</p><p><img src="https://www.zhihu.com/equation?tex=FAR+%3D+%5Cfrac%7B%E9%9D%9E%E5%90%8C%E4%BA%BA%E5%88%86%E6%95%B0%3ET%7D%7B%E9%9D%9E%E5%90%8C%E4%BA%BA%E6%AF%94%E8%BE%83%E7%9A%84%E6%AC%A1%E6%95%B0%7D++%5C%5C" alt="[公式]"></p><p>这个指标的意思是我们拿一对不同的人的照片去测试的时候，如果两个人的特征向量之差超过了设定的阈值（也就是把这两个人认成了同一个人）的次数比上所有不同的人的pairs的对比次数。也就是把不同的人识别成同一个人的概率啦。当然是越小越好</p><p>那么TAR则是表示正确接受的比例。就是同一个人的照片被判别为同一个人的概率。</p><p><img src="https://www.zhihu.com/equation?tex=TAR+%3D+%5Cfrac%7B%E5%90%8C%E4%BA%BA%E5%88%86%E6%95%B0%3ET%7D%7B%E5%90%8C%E4%BA%BA%E6%AF%94%E8%BE%83%E7%9A%84%E6%AC%A1%E6%95%B0%7D+%5C%5C" alt="[公式]"></p><p>一般我们会计算的是在FAR为多少（比如 <img src="https://www.zhihu.com/equation?tex=10%5E%7B-3%7D" alt="[公式]"> ）的情况下TAR为多少</p><p><img src="https://img2018.cnblogs.com/blog/1011838/201901/1011838-20190123203347054-1083715070.png" alt="sklearn算法选择"></p><h2 id="数据预处理"><a href="#数据预处理" class="headerlink" title="数据预处理"></a>数据预处理</h2><p><strong>1.最小-最大规范化</strong><br>最小-最大规范化对原始数据进行线性变换，变换到[0,1]区间（也可以是其他固定最小最大值的区间）</p><p><em>x[n] = (x[n] - min) / (max - min)</em></p><p><strong>2. 标准化（Standardization or Mean Removal and Variance Scaling)</strong><br>变换后各维特征有0均值，单位方差。也叫z-score规范化（零均值规范化）。计算方式是将特征值减去均值，除以标准差。</p><p><em>x[n] = (x[n] - mean) / stdev</em></p><p><strong>3. L2-Normalization ( 人脸识别中会用到 )</strong><br>Normalization主要思想是对每个样本计算其p-范数，然后对该样本中每个元素除以该范数，这样处理的结果是使得每个处理后样本的p-范数（l1-norm,l2-norm）等于1。<br>p-范数的计算公式：<em>||X||p = ( |x1|^p + |x2|^p +…+ |xn|^p ）^1/p</em><br>该方法主要应用于文本分类和聚类中。例如，对于两个TF-IDF向量的l2-norm进行点积，就可以得到这两个向量的余弦相似性。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;kNN算法实现人脸识别&quot;&gt;&lt;a href=&quot;#kNN算法实现人脸识别&quot; class=&quot;headerlink&quot; title=&quot;kNN算法实现人脸识别&quot;&gt;&lt;/a&gt;kNN算法实现人脸识别&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;代表论文：&lt;/p&gt;
&lt;p&gt;&lt;a href=</summary>
      
    
    
    
    <category term="机器学习" scheme="http://durantthorvalds.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="算法" scheme="http://durantthorvalds.top/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="机器学习" scheme="http://durantthorvalds.top/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>【研究向】Redis中跳表实现原理</title>
    <link href="http://durantthorvalds.top/2020/12/01/%E3%80%90%E7%A0%94%E7%A9%B6%E5%90%91%E3%80%91Redis%E4%B8%AD%E8%B7%B3%E8%A1%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/"/>
    <id>http://durantthorvalds.top/2020/12/01/%E3%80%90%E7%A0%94%E7%A9%B6%E5%90%91%E3%80%91Redis%E4%B8%AD%E8%B7%B3%E8%A1%A8%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86/</id>
    <published>2020-11-30T16:00:00.000Z</published>
    <updated>2020-12-01T11:24:27.142Z</updated>
    
    <content type="html"><![CDATA[<h1 id="跳表-SkipList的实现原理"><a href="#跳表-SkipList的实现原理" class="headerlink" title="跳表 SkipList的实现原理"></a>跳表 SkipList的实现原理</h1><h2 id="XII-跳跃表（Skip-list）实现排序"><a href="#XII-跳跃表（Skip-list）实现排序" class="headerlink" title="XII 跳跃表（Skip list）实现排序"></a>XII 跳跃表（Skip list）实现排序</h2><blockquote><h4 id="1206-设计跳表-这一题可以帮助我们快速理解跳表原理。"><a href="#1206-设计跳表-这一题可以帮助我们快速理解跳表原理。" class="headerlink" title="1206. 设计跳表  这一题可以帮助我们快速理解跳表原理。"></a><a href="https://leetcode-cn.com/problems/design-skiplist/">1206. 设计跳表  </a>这一题可以帮助我们快速理解跳表原理。</h4><p>这种数据结构是由<a href="https://en.wikipedia.org/wiki/William_Pugh">William Pugh</a>发明的，最早出现于他在1990年发表的论文《<a href="ftp://ftp.cs.umd.edu/pub/skipLists/skiplists.pdf">Skip Lists: A Probabilistic Alternative to Balanced Trees</a>》</p></blockquote><p>跳跃表是一种<strong>随机化</strong>的数据结构，基于<strong>并联</strong>的链表，其效率相当于二叉查找树，查找和删除均为$O(logn)$。有序的链表加上附加的前进链接。</p><p><img src="/img/1506_skiplist.gif" alt="img"></p><p>为避免插入节点时保持上下节点的节点数之比为2：1的麻烦，跳表不要求上下相邻两层的节点数有严格的对应关系，而是为每个节点随机选择一个层数（level），比如一个节点随机出层数为3，那么就把它链入第1层到第3层这三层链表中。</p><p><img src="http://zhangtielei.com/assets/photos_redis/skiplist/skiplist_insertions.png" alt="skiplist插入形成过程"></p><p>我们可以看到，每一个节点的层数是随机的，而且插入一个节点不会影响其它节点的层数。因此插入操作只需要修改插入节点前后的指针，而不需要对很多节点进行调整。这就降低了插入操作的时间复杂度。并且在性能上优于平衡树。</p><p>下面我们介绍插入操作计算随机层数的过程：</p><ul><li>首先，每一个节点肯定有第1层的指针</li><li>如果一个节点有第i层指针(i≥1)指针，即节点已在1层到第i层链表中，那么它有第（i+1）层指针的概率为p。</li><li>节点的最大层数不允许超过一个最大值，记为<code>MAX_LEVEL</code></li></ul><p>这个计算随机层数的伪码如下所示：</p><pre><code class="hljs pgsql">randomLevel()    <span class="hljs-keyword">level</span> := <span class="hljs-number">1</span>    // random()返回一个[<span class="hljs-number">0.</span>.<span class="hljs-number">.1</span>)的随机数    <span class="hljs-keyword">while</span> random() &lt; p <span class="hljs-keyword">and</span> <span class="hljs-keyword">level</span> &lt; MaxLevel <span class="hljs-keyword">do</span>        <span class="hljs-keyword">level</span> := <span class="hljs-keyword">level</span> + <span class="hljs-number">1</span>    <span class="hljs-keyword">return</span> <span class="hljs-keyword">level</span></code></pre><p>randomLevel()的伪码中包含两个参数，一个是p，一个是MaxLevel。在Redis的skiplist实现中，这两个参数的取值为：</p><pre><code class="hljs ini"><span class="hljs-attr">p</span> = <span class="hljs-number">1</span>/<span class="hljs-number">4</span><span class="hljs-attr">MaxLevel</span> = <span class="hljs-number">32</span></code></pre><p>根据前面randomLevel()的伪码，我们很容易看出，产生越高的节点层数，概率越低。定量的分析如下：</p><ul><li>节点层数至少为1。而大于1的节点层数，满足一个概率分布。</li><li>节点层数恰好等于1的概率为1-p。</li><li>节点层数大于等于2的概率为p，而节点层数恰好等于2的概率为p(1-p)。</li><li>节点层数大于等于3的概率为p2，而节点层数恰好等于3的概率为p2(1-p)。</li><li>节点层数大于等于4的概率为p3，而节点层数恰好等于4的概率为p3(1-p)。</li><li>……</li></ul><p>因此，一个节点的平均层数（也即包含的平均指针数目），计算如下：</p><script type="math/tex; mode=display">(1-p)+2p(1-p)+3p^2(1-p)+.... = (1-p)\sum\limits_{k=1}^{+\infin}=(1-p)\frac{1}{(1-p)^2}=\frac1{1-p}</script><p>现在很容易计算出：</p><ul><li>当p=1/2时，每个节点所包含的平均指针数目为2；</li><li>当p=1/4时，每个节点所包含的平均指针数目为1.33。这也是Redis里的skiplist实现在空间上的开销。</li><li></li></ul><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;跳表-SkipList的实现原理&quot;&gt;&lt;a href=&quot;#跳表-SkipList的实现原理&quot; class=&quot;headerlink&quot; title=&quot;跳表 SkipList的实现原理&quot;&gt;&lt;/a&gt;跳表 SkipList的实现原理&lt;/h1&gt;&lt;h2 id=&quot;XII-跳跃表（S</summary>
      
    
    
    
    <category term="算法" scheme="http://durantthorvalds.top/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="数据结构" scheme="http://durantthorvalds.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>「核心」Ceph学习三部曲之二:CEPH 纠删码操作&amp;API</title>
    <link href="http://durantthorvalds.top/2020/11/26/ceph%E7%BA%A0%E5%88%A0%E7%A0%81%E9%83%A8%E7%BD%B2/"/>
    <id>http://durantthorvalds.top/2020/11/26/ceph%E7%BA%A0%E5%88%A0%E7%A0%81%E9%83%A8%E7%BD%B2/</id>
    <published>2020-11-25T16:00:00.000Z</published>
    <updated>2020-12-16T08:34:48.117Z</updated>
    
    <content type="html"><![CDATA[<div class="note note-primary">            <p>本blog包括理论和实践两个部分，力求深入浅出，实践部分需要您事先部署成功Ceph集群！</p><p>参考《Ceph设计与实现》谢型果等，第三章。以及<a href="https://docs.ceph.com/en/latest/rados/operations/erasure-code/">官方纠删码教程</a>。</p>          </div><h1 id="Part-I"><a href="#Part-I" class="headerlink" title="Part I"></a>Part I</h1><h2 id="Ceph-纠删码操作"><a href="#Ceph-纠删码操作" class="headerlink" title="Ceph 纠删码操作"></a>Ceph 纠删码操作</h2><hr><h2 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h2><p>K ——数据块数。</p><p>M——编码块数。</p><p>N——条带中块的个数，$N=K+M$。</p><p>块（chunk）——将对象基于纠删码进行编码时，每次编码将产生若干大小的块（要求是有序的），Ceph通过数量相等的PG将这些块分别存储至不同的OSD之中。每次编码时，序号相同的块总是由同一个PG负责存储。</p><p>条带（stripe）——如果待编码的对象太大，无法一次性完成，那么可以分成多次进行，每次完成编码的部分称为一个条带。其大小为k*块大小。</p><p>分片（shard）——同一个对象所有序号相同的块位于同一个PG之上，它们组成的对象的一个分片。</p><p>rate——空间利用率，即$K/N$</p><h2 id="1-Ceph纠删码库"><a href="#1-Ceph纠删码库" class="headerlink" title="1 Ceph纠删码库"></a>1 Ceph纠删码库</h2><p>Ceph的默认纠删码库是Jerasure，即Jerasure库；除此之外还有 Clay, ISA-L, LRC, Shec(Octopus版本15.2.5).<br>当管理员创建一个erasure-coded后端时，可以指定数据块和代码块参数。Jerasure库是第三方提供的中间件。Ceph环境安装时，已经默认安装了Jerasure库。</p><h2 id="1-1-一个简单的纠删码池样例"><a href="#1-1-一个简单的纠删码池样例" class="headerlink" title="1.1 一个简单的纠删码池样例"></a>1.1 一个简单的纠删码池样例</h2><p>最简单的erasure pool等效于RAID5，至少需要3个主机：【更多关于池的操作可以参考《Ceph pool》博文】</p><pre><code class="hljs routeros">$ ceph osd<span class="hljs-built_in"> pool </span>create ecpool erasurepool <span class="hljs-string">&#x27;ecpool&#x27;</span> created$ echo ABCDEFGHI | rados --pool ecpool put NYAN -$ rados --pool ecpool <span class="hljs-builtin-name">get</span> NYAN -ABCDEFGHI</code></pre><h2 id="1-2-获取纠删码配置文件"><a href="#1-2-获取纠删码配置文件" class="headerlink" title="1.2 获取纠删码配置文件"></a>1.2 获取纠删码配置文件</h2><p>最简单的 k = 2, m = 2, 允许两个节点同时失效。相当于三副本，但是空间节省了。</p><pre><code class="hljs routeros">$ ceph osd erasure-code-profile <span class="hljs-builtin-name">get</span> default<span class="hljs-attribute">k</span>=2<span class="hljs-attribute">m</span>=2<span class="hljs-attribute">plugin</span>=jerasure<span class="hljs-attribute">crush-failure-domain</span>=host<span class="hljs-attribute">technique</span>=reed_sol_van</code></pre><p>选择正确的配置文件很重要，因为在创建池之后无法对其进行修改：需要创建具有不同配置文件的新池，并且将先前池中的所有对象都移到新的池中。</p><p>概要文件的最重要参数是<em>K</em>，<em>M</em>和 <em>rush-failure域，</em>因为它们定义了存储开销和数据持久性。例如，如果所需的架构必须承受两个机架的损失，而存储开销(m/k*100%)为开销的67％，则可以定义以下配置文件：</p><pre><code class="hljs routeros">$ ceph osd erasure-code-profile <span class="hljs-builtin-name">set</span> myprofile \   <span class="hljs-attribute">k</span>=3 \   <span class="hljs-attribute">m</span>=2 \   <span class="hljs-attribute">crush-failure-domain</span>=rack$ ceph osd<span class="hljs-built_in"> pool </span>create ecpool 128 erasure myprofile #128在这类是PG的数量$ echo ABCDEFGHI | rados --pool ecpool put NYAN -$ rados --pool ecpool <span class="hljs-builtin-name">get</span> NYAN -ABCDEFGHI</code></pre><p>该<em>NYAN</em>对象将在三个（被划分<em>K = 3</em>）和两个附加 <em>的块</em>将被创建（<em>M = 2</em>）。<em>M</em>的值定义了在不丢失任何数据的情况下可以同时丢失多少个OSD。所述<code>crush-failure-domain=rack</code>将创建一个CRUSH规则，以确保没有两个<code>chunks</code>被存储在同一个机架。</p><pre><code class="hljs vim">ceph osd erasure-code-<span class="hljs-keyword">profile</span> <span class="hljs-keyword">ls</span> #显示所有<span class="hljs-keyword">profile</span>ceph osd erasure-code-<span class="hljs-keyword">profile</span> rm &#123;profilr&#125; #删除特定<span class="hljs-keyword">profile</span></code></pre><p>读写文件test.txt</p><pre><code class="hljs cmake">rados -p ecpool put <span class="hljs-keyword">test</span> <span class="hljs-keyword">test</span>.txtrados -p ecpool get <span class="hljs-keyword">test</span> <span class="hljs-keyword">file</span>.txt</code></pre><p>更多信息在 <a href="https://docs.ceph.com/en/latest/rados/operations/erasure-code-profile">erasure code profiles</a></p><p><img src="/img/nyan.png" alt="img"></p><p>上图展示的是一种最简单的情况，我们称之为“满条带写”，向k=3，m=2的纠删码存储池写入NYAN对象。针对同一个逻辑PG，将对象分片并写入不同的PG实例。每个PG实例都认为字节保存的是一个完整而独立的对象。因此其保存的内容在逻辑上是连续的，以块大小为单位。5个OSD最终都向名为“NYAN”的对象写入三个字节，它们在对象内的逻辑地址都为[0,2]。</p><h2 id="1-3-写覆盖"><a href="#1-3-写覆盖" class="headerlink" title="1.3 写覆盖"></a>1.3 写覆盖</h2><p>默认情况下，纠删码池仅适用于执行完整对象写入和追加的RGW之类的用途。</p><p>自从luminous版本，每个池设置启用对纠删码池的<strong>部分写</strong>入。这使RBD和CephFS将其数据存储在纠删码池中：</p><pre><code class="hljs routeros">ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">set</span> ec_pool allow_ec_overwrites <span class="hljs-literal">true</span></code></pre><p>这是针对bluestore的osd，这是因为bluestore的校验和用于检测deep-scrub 期间的bitrot和其它损坏。除了不安全之外，overwrite还将降低性能。</p><p>纠删码不支持<code>omap</code>,因此需要和RBD和CephFS一起使用，必须指示它们将数据存储在ec池中，并将元数据存储在复制池中。对于RBD，这意味着<code>--data-pool</code>在图像创建过程中使用纠删码池：</p><pre><code class="hljs brainfuck"><span class="hljs-comment">rbd</span> <span class="hljs-comment">create</span> --<span class="hljs-comment">size</span> <span class="hljs-comment">1G</span> --<span class="hljs-comment">data</span><span class="hljs-literal">-</span><span class="hljs-comment">pool</span> <span class="hljs-comment">ec_pool</span> <span class="hljs-comment">replicated_pool/image_name</span><span class="hljs-comment"></span></code></pre><p>对于CephFS，可以在文件系统创建过程中或通过<a href="https://docs.ceph.com/en/latest/cephfs/file-layouts">文件布局</a>将纠删码池设置为默认数据池。</p><h2 id="1-4-缓存层"><a href="#1-4-缓存层" class="headerlink" title="1.4 缓存层"></a>1.4 缓存层</h2><p>纠删码比副本需要更多资源，并且缺失<code>omap</code>这样的功能。为了克服这些限制，需要设置一个<a href="https://docs.ceph.com/en/latest/rados/operations/cache-tiering">缓存层</a></p><pre><code class="hljs dsconfig">$ <span class="hljs-string">ceph </span><span class="hljs-string">osd </span><span class="hljs-string">tier </span><span class="hljs-string">add </span><span class="hljs-string">ecpool </span><span class="hljs-string">hot-storage</span><span class="hljs-string">$</span> <span class="hljs-string">ceph </span><span class="hljs-string">osd </span><span class="hljs-string">tier </span><span class="hljs-string">cache-mode </span><span class="hljs-string">hot-storage </span><span class="hljs-string">writeback</span><span class="hljs-string">$</span> <span class="hljs-string">ceph </span><span class="hljs-string">osd </span><span class="hljs-string">tier </span><span class="hljs-built_in">set-overlay</span> <span class="hljs-string">ecpool </span><span class="hljs-string">hot-storage</span></code></pre><p>将放置热存储池的ecpool 在<em>写回</em> 模式。提供灵活性和速度。</p><h2 id="1-5-恢复"><a href="#1-5-恢复" class="headerlink" title="1.5 恢复"></a>1.5 恢复</h2><p>如果纠删码池丢失了一些碎片，则必须从其他碎片中恢复它们。通常，这涉及读取其余分片，重建数据并将其写入新对等方。在Octopus中，只要至少有<em>K个</em>碎片可用，擦除编码池就可以恢复。（使用少于<em>K个分</em>片，您实际上已经丢失了数据！）</p><p>在使用Octopus之前，即使<em>min_size</em>大于<em>K</em>，擦除编码池也至少需要<em>min_size分</em>片可用。（我们通常建议min_size为<em>K + 2</em>或更大，以防止写入和数据丢失。）这种保守的决定是在设计新的池模式时出于谨慎考虑而做出的，但是这也意味着丢失OSD但没有数据丢失的池无法进行操作恢复并开始活动，而无需手动干预来更改<em>min_size</em>。</p><h2 id="2-OSD-erasure-code-profile-参数"><a href="#2-OSD-erasure-code-profile-参数" class="headerlink" title="2 OSD erasure-code-profile 参数"></a>2 OSD erasure-code-profile 参数</h2><p>通用</p><pre><code class="hljs routeros">ceph osd erasure-code-profile <span class="hljs-builtin-name">set</span> &#123;name&#125; \     [&#123;<span class="hljs-attribute">directory</span>=directory&#125;] \     [&#123;<span class="hljs-attribute">plugin</span>=plugin&#125;] \     [&#123;<span class="hljs-attribute">stripe_unit</span>=stripe_unit&#125;] \     [&#123;<span class="hljs-attribute">key</span>=value&#125; <span class="hljs-built_in">..</span>.] \     [--force]</code></pre><ul><li><p><code>&#123;directory&#125;:string</code></p><p>设置从中加载擦除代码插件的<strong>目录</strong>名称. 默认<code>/ usr / lib / ceph / erasure-code</code></p></li><li><p><code>crush-failure-domain=&#123;bucket-type&#125;</code></p><p>确保一个桶两个数据块没有相同的容灾域. 它被用于创建 CRUSH 规则 <strong>step chooseleaf host</strong>. 默认host。</p></li><li><p><code>crush-device-class=&#123;device-class&#125;</code></p><p>使用CRUSH映射中的Crush设备类名称，将布局限制为特定类（例如 <code>ssd</code>或<code>hdd</code>）的设备。</p></li><li><p><code>&#123;plugin&#125;:string</code></p><p>默认: <code>jerasure</code> ,  可选<code>isa\ lrc \shec\clay</code></p></li></ul><h2 id="2-1-jerasure"><a href="#2-1-jerasure" class="headerlink" title="2.1 jerasure"></a>2.1 jerasure</h2><pre><code class="hljs sql">ceph osd erasure-code-profile <span class="hljs-keyword">set</span> &#123;<span class="hljs-keyword">name</span>&#125; \     <span class="hljs-keyword">plugin</span>=jerasure \     k=&#123;<span class="hljs-keyword">data</span>-chunks&#125; \     m=&#123;coding-chunks&#125; \     technique=&#123;reed_sol_van|reed_sol_r6_op|cauchy_orig|cauchy_good|liberation|blaum_roth|liber8tion&#125; \     [crush-root=&#123;root&#125;] \     [crush-<span class="hljs-keyword">failure</span>-<span class="hljs-keyword">domain</span>=&#123;<span class="hljs-keyword">bucket</span>-<span class="hljs-keyword">type</span>&#125;] \     [crush-device-<span class="hljs-keyword">class</span>=&#123;device-<span class="hljs-keyword">class</span>&#125;] \     [<span class="hljs-keyword">directory</span>=&#123;<span class="hljs-keyword">directory</span>&#125;] \     [<span class="hljs-comment">--force]</span></code></pre><p>我们可以选择具体技术<code>technique</code>。更灵活的技术是<em>reed_sol_van</em>：足以设置<em>k</em>和<em>m</em>。该<em>cauchy_good</em>技术可以更快，但你需要选择的<em>PACKETSIZE</em> 小心。从只能使用<em>m = 2</em>进行配置的意义上来说，所有<em>reed_sol_r6_op</em>，<em>liberation</em>， <em>blaum_roth</em>，<em>liber8tion</em>都是<em>RAID6</em>等效项。</p><h2 id="2-2-ISA"><a href="#2-2-ISA" class="headerlink" title="2.2 ISA"></a>2.2 ISA</h2><pre><code class="hljs sql">ceph osd erasure-code-profile <span class="hljs-keyword">set</span> &#123;<span class="hljs-keyword">name</span>&#125; \     <span class="hljs-keyword">plugin</span>=isa \     technique=&#123;reed_sol_van|cauchy&#125; \     [k=&#123;<span class="hljs-keyword">data</span>-chunks&#125;] \     [m=&#123;coding-chunks&#125;] \     [crush-root=&#123;root&#125;] \     [crush-<span class="hljs-keyword">failure</span>-<span class="hljs-keyword">domain</span>=&#123;<span class="hljs-keyword">bucket</span>-<span class="hljs-keyword">type</span>&#125;] \     [crush-device-<span class="hljs-keyword">class</span>=&#123;device-<span class="hljs-keyword">class</span>&#125;] \     [<span class="hljs-keyword">directory</span>=&#123;<span class="hljs-keyword">directory</span>&#125;] \     [<span class="hljs-comment">--force]</span></code></pre><h2 id="2-3-LRC"><a href="#2-3-LRC" class="headerlink" title="2.3 LRC"></a>2.3 LRC</h2><pre><code class="hljs sql">ceph osd erasure-code-profile <span class="hljs-keyword">set</span> &#123;<span class="hljs-keyword">name</span>&#125; \     <span class="hljs-keyword">plugin</span>=lrc \     k=&#123;<span class="hljs-keyword">data</span>-chunks&#125; \     m=&#123;coding-chunks&#125; \     l=&#123;locality&#125; \     [crush-root=&#123;root&#125;] \     [crush-locality=&#123;<span class="hljs-keyword">bucket</span>-<span class="hljs-keyword">type</span>&#125;] \     [crush-<span class="hljs-keyword">failure</span>-<span class="hljs-keyword">domain</span>=&#123;<span class="hljs-keyword">bucket</span>-<span class="hljs-keyword">type</span>&#125;] \     [crush-device-<span class="hljs-keyword">class</span>=&#123;device-<span class="hljs-keyword">class</span>&#125;] \     [<span class="hljs-keyword">directory</span>=&#123;<span class="hljs-keyword">directory</span>&#125;] \     [<span class="hljs-comment">--force]</span></code></pre><p><em>LRC</em>创建本地校验块，使用更少的存活OSD。例如，如果<em>lrc</em>配置为 <em>k = 8</em>，<em>m = 4</em>和<em>l = 4</em>，它将为每4个OSD创建一个额外的奇偶校验块。当1个OSD丢失时，只能使用4个OSD（而不是8个）来恢复它。</p><h2 id="2-4-SHEC"><a href="#2-4-SHEC" class="headerlink" title="2.4 SHEC"></a>2.4 SHEC</h2><pre><code class="hljs sql">ceph osd erasure-code-profile <span class="hljs-keyword">set</span> &#123;<span class="hljs-keyword">name</span>&#125; \     <span class="hljs-keyword">plugin</span>=shec \     [k=&#123;<span class="hljs-keyword">data</span>-chunks&#125;] \     [m=&#123;coding-chunks&#125;] \     [c=&#123;durability-estimator&#125;] \     [crush-root=&#123;root&#125;] \     [crush-<span class="hljs-keyword">failure</span>-<span class="hljs-keyword">domain</span>=&#123;<span class="hljs-keyword">bucket</span>-<span class="hljs-keyword">type</span>&#125;] \     [crush-device-<span class="hljs-keyword">class</span>=&#123;device-<span class="hljs-keyword">class</span>&#125;] \     [<span class="hljs-keyword">directory</span>=&#123;<span class="hljs-keyword">directory</span>&#125;] \     [<span class="hljs-comment">--force]</span></code></pre><ul><li><p><code>c=&#123;durability-estimator&#125;:int</code></p><p>奇偶校验块的数量，每个奇偶校验块包括其计算范围内的每个数据块。该数字用作<strong>耐久性估算器</strong>。例如，如果c = 2，则2个OSD可以关闭而不会丢失数据。默认为2.</p></li></ul><h2 id="2-5-CLAY"><a href="#2-5-CLAY" class="headerlink" title="2.5 CLAY"></a>2.5 CLAY</h2><p>全称是coupled-layer.  此编码目标是在修复时减少网络带宽和磁盘IO。</p><p>令d为修复时沟通的OSD数量。比如Jerasure中k=8，m=4，修复1GiB数据</p><p>需要下载8GiB数据。</p><p>在clay中允许设置d， $k+1\le d\le k+m-1$。默认情况下$d=k+m-1$，这将最大化节省网络带宽和磁盘IO。比如 k = 8, m = 4, d = 11. <em>则</em>当单个OSD发生故障时，将沟通d = 11 osds并从每个插件中下载250MiB，导致总下载量为11 X 250MiB = 2.75GiB。下面提供了更多常规参数。当对存储量达到TB级的信息的机架进行维修时，好处是巨大的。</p><div class="table-container"><table><thead><tr><th style="text-align:left">Plugin</th><th style="text-align:left">磁盘IO总量</th></tr></thead><tbody><tr><td style="text-align:left">Jeraure</td><td style="text-align:left">$kS$</td></tr><tr><td style="text-align:left">Clay</td><td style="text-align:left">$dS/(d−k+1)=(k+m−1)S/m$</td></tr></tbody></table></div><p>其中<em>S</em>是正在修复的单个OSD上存储的数据量。在上表中，我们使用了<em>d</em>的最大可能值，因为这将导致从OSD故障恢复所需的最小数据下载量。</p><pre><code class="hljs sql">ceph osd erasure-code-profile <span class="hljs-keyword">set</span> &#123;<span class="hljs-keyword">name</span>&#125; \     <span class="hljs-keyword">plugin</span>=clay \     k=&#123;<span class="hljs-keyword">data</span>-chunks&#125; \     m=&#123;coding-chunks&#125; \     [d=&#123;helper-chunks&#125;] \     [scalar_mds=&#123;<span class="hljs-keyword">plugin</span>-<span class="hljs-keyword">name</span>&#125;] \     [technique=&#123;technique-<span class="hljs-keyword">name</span>&#125;] \     [crush-<span class="hljs-keyword">failure</span>-<span class="hljs-keyword">domain</span>=&#123;<span class="hljs-keyword">bucket</span>-<span class="hljs-keyword">type</span>&#125;] \     [<span class="hljs-keyword">directory</span>=&#123;<span class="hljs-keyword">directory</span>&#125;] \     [<span class="hljs-comment">--force]</span></code></pre><ul><li><p><code>d=&#123;helper-chunks&#125;</code></p><p>恢复单个块期间请求发送数据的OSD数量。需要选择<em>d</em>，以使k + 1 &lt;= d &lt;= k + m-1。在较大的<em>d</em>，节省越多。默认 k + m -1.</p></li><li><p><code>scalar_mds=&#123;jerasure|isa|shec&#125;</code></p><p><strong>scalar_mds</strong>指定在分层构造中用作构建块的插件。可以是<em>jerasure</em>，<em>isa</em>，<em>shec之一</em></p></li><li><p><code>technique=&#123;technique&#125;</code></p><p><strong>technique</strong>指定将在指定的“ scalar_mds”插件中采用的技术。支持的技术是’reed_sol_van’，’reed_sol_r6_op’，’cauchy_orig’，’cauchy_good’，’liber8tion’用于jerasure，’reed_sol_van’，’cauchy’用于isa和’single’，’multiple’用于shec。</p><p>默认reed_sol_van (for jerasure, isa), single (for shec)</p></li></ul><blockquote><h2 id="MORE"><a href="#MORE" class="headerlink" title="MORE"></a>MORE</h2><p>Clay代码是矢量代码，因此能够节省磁盘IO和网络带宽，并且能够以称为子块的更精细的粒度查看和操作块中的数据。Clay代码的块中子块的数量由下式给出：</p><blockquote><p>子块计数= $q^{(k+m)/q}$， $q=d−k+1$</p></blockquote><p>在OSD修复期间，从可用OSD请求的帮助者信息只是块的一小部分。实际上，修复期间访问的块内子块的数量由下式给出：</p><blockquote><p>修复子块计数= $\frac{sub—-chunk \: count}{q}$</p></blockquote><h3 id="例子"><a href="#例子" class="headerlink" title="例子"></a>例子</h3><ol><li>对于<em>k = 4</em>，<em>m = 2</em>，<em>d = 5的配置</em>，子块计数为8，修复子块计数为4。因此，在修复期间仅读取一半的块。</li><li>当<em>k = 8</em>，<em>m = 4</em>，<em>d = 11时</em>，子块计数为64，修复子块计数为16。从可用OSD中读取四分之一的块以修复故障块。</li></ol><h2 id="如何在给定工作量的情况下选择配置"><a href="#如何在给定工作量的情况下选择配置" class="headerlink" title="如何在给定工作量的情况下选择配置"></a>如何在给定工作量的情况下选择配置</h2><p>块中所有子块中只有几个子块被读取。这些子块不必连续存储在块中。为了获得最佳的磁盘IO性能，读取连续的数据很有帮助。因此，建议您选择条带大小，以使子块大小足够大。</p><p>对于给定的条带大小（这是基于固定的工作负载），选择<code>k</code>，<code>m</code>，<code>d</code>使得：</p><blockquote><p>子块大小= $\frac{stripe-size}{k sub-chunk count}$ = 4KB，8KB，12KB…</p></blockquote><ol><li>对于条带大小较大的大型工作负载，很容易选择k，m，d。例如，考虑大小为64MB的条带大小，选择<em>k = 16</em>，<em>m = 4</em>和<em>d = 19</em>将导致子块计数为1024，子块大小为4KB。</li><li>对于较小的工作负载，<em>k = 4</em>，<em>m = 2</em>是一个很好的配置，可同时带来网络和磁盘IO的好处。</li></ol><h2 id="与LRC的比较"><a href="#与LRC的比较" class="headerlink" title="与LRC的比较"></a>与LRC的比较</h2><p>还设计了本地可恢复代码（LRC），以便在网络带宽方面节省单个OSD恢复期间的磁盘IO。但是，LRC的重点是使修复（d）期间接触的OSD数量保持最少，但这是以存储开销为代价的。clay代码有一个存储开销 m/k。在<em>lrc</em>的情况下，除奇偶校验外，它还存储（k + m）/ d个奇偶<code>m</code>校验，从而导致存储开销（m +（k + m）/ d）/ k。两个<em>粘土</em>和<em>LRC</em> 可以从任何的故障中恢复<code>m</code>的OSD。</p><blockquote><div class="table-container"><table><thead><tr><th style="text-align:left">参量</th><th style="text-align:left">磁盘IO，存储开销（LRC）</th><th style="text-align:left">磁盘IO，存储开销（CLAY）</th></tr></thead><tbody><tr><td style="text-align:left">（k = 10，m = 4）</td><td style="text-align:left">7 * S，0.6（d = 7）</td><td style="text-align:left">3.25 * S，0.4（d = 13）</td></tr><tr><td style="text-align:left">（k = 16，m = 4）</td><td style="text-align:left">4 * S，0.5625（d = 4）</td><td style="text-align:left">4.75 * S，0.25（d = 19）</td></tr></tbody></table></div></blockquote><p><code>S</code>是恢复单个OSD的存储数据量。</p></blockquote><h2 id="覆盖写思考"><a href="#覆盖写思考" class="headerlink" title="覆盖写思考"></a>覆盖写思考</h2><p>因为数据更新必须以条带为单位进行，如果覆盖写的起始或者结束位置没有进行条带对齐，那么不足一个完整条带的部分，其写入只能通过“读取完整条带→修改数据→基于条带重新计算校验数据→写入（被修改部分和校验和）”。这个过程被称为RMW。</p><p>整个RMW过程补齐读阶段最耗时，由两种解决思路：1. 减少RMW次数，2.如果RMW不可避免，那么尽量减少补齐读的数据量。一种常见的做法是引入写缓存。将驻留于缓存的写操作进行合并。 另外是尽可能减少读的次数，基于被修改写的数据范围预先计算出需要执行补齐读的块，而不是每次都执行满条带写。</p><h2 id="Scrub的问题"><a href="#Scrub的问题" class="headerlink" title="Scrub的问题"></a>Scrub的问题</h2><p>Scrub指数据扫描，通过读取对象数据并重新计算校验和，再与之前存储在对象属性的校验和进行比对，以判断有无静默错误（磁盘自身无法感知的错误）。目前Ceph纠删码没有自动修复功能。</p><p>例如对象大小为4MB，那么每4KB原始数据采用CRC32生成固定四个字节的校验和，则整个对象的校验和最大只能是4KB，这显然无法直接使用对象扩展属性存储，而只能使用对象的omap存储(kv pairs)，但是纠删码目前不支持omap! </p><p>Ceph中纠删码一直未达到商业水平，无外乎以下几个原因：</p><ul><li>相较于多副本，纠删码实现更复杂</li><li>相较于多副本，纠删码性能较差，尤其是读性能。其最适合的场景一般是追加写或者删除。</li></ul><p>这也是笔者的研究方向，路漫漫其修远兮，吾将上下而求索。</p><hr><h1 id="Part-II"><a href="#Part-II" class="headerlink" title="Part II"></a>Part II</h1><h2 id="纠删码库介绍"><a href="#纠删码库介绍" class="headerlink" title="纠删码库介绍"></a>纠删码库介绍</h2><h2 id="1-Jerasure"><a href="#1-Jerasure" class="headerlink" title="1 Jerasure"></a>1 Jerasure</h2><p>2007 James给出了RS-RAID一个开源实现。<a href="http://jerasure.org/jerasure/jerasure">official</a> ，<a href="https://github.com/tsuraan/Jerasure">github</a></p><p>Jerasure库包括以下5个模块：</p><ul><li><code>galois.h/.c</code>提供伽罗华域的算术运算。</li><li><code>jerasure.h/.c</code>提供了绝大部分的核心函数。包括矩阵的编解码，位矩阵变换，矩阵转置和位矩阵转置。</li><li><code>reedsol.h/.c</code>支持RS编解码和优化和的RS码。</li><li><code>caucy.h/.c</code> 支持Caucy RS编解码和最优Caucy编码。</li><li><code>caucy_best_r6.h/.c</code> 基于Caucy矩阵的RAID-6优化。</li><li><code>liberation.h/.c</code> 支持Liberartion RAID-6编码, Blaum-Roth 编码，和Liber8tion RAID-6编码。 Liberation是一种低密度MDS。这三种编码采用位矩阵来实现，其性能远优于现有的RS和EVENNODD，在某种情况下也优于RDP编码。</li></ul><p>下标汇总了Jerasure-2.0库常见的参数和其含义：</p><div class="table-container"><table><thead><tr><th style="text-align:center">参数名</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">k</td><td style="text-align:center">数据盘个数</td></tr><tr><td style="text-align:center">m</td><td style="text-align:center">校验盘个数</td></tr><tr><td style="text-align:center">w</td><td style="text-align:center">字长</td></tr><tr><td style="text-align:center">packetsize</td><td style="text-align:center">包大小</td></tr><tr><td style="text-align:center">size</td><td style="text-align:center">每个盘待编码或者解码的字节数</td></tr><tr><td style="text-align:center">matrix</td><td style="text-align:center">编码矩阵</td></tr><tr><td style="text-align:center">bitmatrix</td><td style="text-align:center">位矩阵</td></tr><tr><td style="text-align:center">dataptrs</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">erasures</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">erased</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">schdule</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">row k ones</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">dm ids</td></tr></tbody></table></div><p>针对RAID-6，Jerasure作了两类优化：</p><ul><li><p>对乘2运算进行优化</p></li><li><p>直接对编码矩阵进行改造，得到最小密度RAID6. 这类矩阵很稀疏，计算量较少。目前有三种</p><ul><li>Liberation: 要求W必须是素数</li><li>Blaum-Roth: 要求W+1必须是素数</li><li>Lber8tion: 要求W必须等于8</li></ul><p>这三种编码效率相当。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note note-primary&quot;&gt;
            &lt;p&gt;本blog包括理论和实践两个部分，力求深入浅出，实践部分需要您事先部署成功Ceph集群！&lt;/p&gt;&lt;p&gt;参考《Ceph设计与实现》谢型果等，第三章。以及&lt;a href=&quot;https://d</summary>
      
    
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/categories/ceph/"/>
    
    <category term="纠删码" scheme="http://durantthorvalds.top/categories/ceph/%E7%BA%A0%E5%88%A0%E7%A0%81/"/>
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title>「核心」Ceph学习三部曲之一:A First Galance At Crush</title>
    <link href="http://durantthorvalds.top/2020/11/25/A%20first%20glance%20at%20CRUSH/"/>
    <id>http://durantthorvalds.top/2020/11/25/A%20first%20glance%20at%20CRUSH/</id>
    <published>2020-11-25T10:00:00.000Z</published>
    <updated>2020-12-16T08:33:14.942Z</updated>
    
    <content type="html"><![CDATA[<div class="note note-primary">            <p>本blog包括理论和实践两个部分，实践部分需要您事先部署成功Ceph集群！</p><p>参考《Ceph设计与实现》谢型果等，第一章。以及<a href="https://docs.ceph.com/en/latest/rados/operations/crush-map/?s">官方CRUSH教程</a>。</p>          </div><h1 id="浅析CRUSH算法"><a href="#浅析CRUSH算法" class="headerlink" title="浅析CRUSH算法"></a>浅析CRUSH算法</h1><blockquote><p>论文地址：</p><p><a href="https://ceph.com/wp-content/uploads/2016/08/weil-crush-sc06.pdf">https://ceph.com/wp-content/uploads/2016/08/weil-crush-sc06.pdf</a></p></blockquote><h1 id="1-CRUSH背景"><a href="#1-CRUSH背景" class="headerlink" title="1. CRUSH背景"></a>1. CRUSH背景</h1><p>大部分存储系统将数据写入到存储设备之后，数据很少在设备之间相互移动，这会导致一个潜在问题，即使是一个数据分布趋于完美的系统，随着时间的迁移，新的空闲设备不断加入，老设备不断退出，数据变得不均匀。<br>一种可行方案是将数据以足够小的粒度打散，均匀分布于整个存储系统，这样做有两个问题:</p><ul><li>如果设备数量发生变化， 如何最小化迁移量使得整个系统尽快恢复平衡。</li><li>在大型（PB以上）分布式存储系统，为保证数据可靠性一般采用多副本或者纠删码，如何合理分布它们。。</li></ul><p>CRUSH: Controlled Replication Under Scalable Hashing 基于可扩展哈希的受控副本分布策略。<br>它基于伪随机数哈希算法，以数据唯一标识符、当前存储集群拓扑以及数据备份策略作为输入，可以随时随地通过计算获取数据所在的底层存储设备的位置并之间与其通信，从而避免查表，失效去中心化和高度并发。</p><h1 id="2-Straw选择算法"><a href="#2-Straw选择算法" class="headerlink" title="2. Straw选择算法"></a>2. Straw选择算法</h1><p>网络中不同层级具有不同容忍灾难的能力，称之为容灾域。</p><p><img src="/img/image-20201128210418154.png" alt="image-20201128210418154"></p><p>Sage weil一共设计了四种选择算法，并按照添加删除数据的性能进行比较。结论是：考虑到存储空间需求爆炸式增长，在大型分布式存储系统中某些部件故障是常态，以及数据性可靠性要求，Straw将是不错的选择。我们重点分析。</p><ul><li>straw算法将所有元素（设备）比作吸管，为每个元素随机计算一个长度，最后从中选择长度最长的那个元素作为结果输出，这个过程被形象地称为抽签（draw）。</li><li>CRUSH引入了权重（weight）来区分不同容量的设备。大容量设备理应获得更大的权重。设输入为x，元素编号为i，权重为w，随机数种子为r。</li></ul><script type="math/tex; mode=display">C(r,x) = max_i(f(w_i)hash(x,r,i))</script><ul><li>当添加一个元素，straw会随机将一些原有元素中的数据随机映射至新加入的元素中；当删除一个元素x，straw会将全部数据重新映射到除x以外所有元素。</li></ul><p>当然straw也存在问题</p><ul><li>Straw算法将所有元素按权重逆序排列后逐个计算每个元素的Item_straw，会导致最终选择结果不断取决于每个元素自身权重还与集合当助其他元素强相关。因而会引起不相干的数据迁移。因而Sage Weil进行修正：在计算straw长度时仅使用元素自身的权重。从而得到straw改进算法straw2。</li></ul><p>原Straw算法：</p><pre><code class="hljs cpp">max_x = <span class="hljs-number">-1</span>max_item = <span class="hljs-number">-1</span><span class="hljs-keyword">for</span> each item:x = hash(input,r)x = x*item_straw<span class="hljs-keyword">if</span> x &gt; max_x:max_x = xmax_item = item<span class="hljs-keyword">return</span> max_item</code></pre><p>Straw2算法：</p><pre><code class="hljs properties"><span class="hljs-attr">max_x</span> = <span class="hljs-string">-1</span><span class="hljs-attr">max_item</span> = <span class="hljs-string">-1</span><span class="hljs-attr">for</span> <span class="hljs-string">each item:</span><span class="hljs-attr">x</span> = <span class="hljs-string">hash(input,r)</span><span class="hljs-attr">x</span> = <span class="hljs-string">ln(x/65536)/weight</span><span class="hljs-attr">if</span> <span class="hljs-string">x &gt; max_x:</span><span class="hljs-attr">max_x</span> = <span class="hljs-string">x</span><span class="hljs-attr">max_item</span> = <span class="hljs-string">item</span><span class="hljs-attr">return</span> <span class="hljs-string">max_item</span></code></pre><p>上述逻辑中，针对输入input和随机因子r执行哈希后，结果落在[0,65536]之间，x/65536必然小于1，取其自然对数ln(x/65536)后结果为负值，将其除以自身权重后，表现为权重越大，x越大，从而体现了我们所期望的每个元素对于抽签结果的正反馈作用。</p><h1 id="3-CRUSH算法"><a href="#3-CRUSH算法" class="headerlink" title="3 . CRUSH算法"></a>3 . CRUSH算法</h1><ul><li>针对特定输入x，CRUSH将输出一个包含n个不同存储对象的集合。我们称集群的拓扑为 Cluster Map , 不同数据分布是通过制定不同的placement rule实现的，它实际是一组包括最大副本数或纠删码策略、容灾级别的自定义约束条件。</li><li>x和cluster map和placement rule是CRUSH的哈希函数输入参数。因为使用伪随机哈希函数，CRUSH选择每个目标存储对象概率是相对独立的。</li></ul><h2 id="3-1-Cluster-Map"><a href="#3-1-Cluster-Map" class="headerlink" title="3.1 Cluster Map"></a>3.1 Cluster Map</h2><p><img src="/img/cluster_map.png" alt="image-20201128210954633"></p><p>实现上cluster map具有诸如 “数据中心→机架→主机→磁盘”这样的树状层次关系。每个叶子节点都是真实的物理设备（比如磁盘）称为device；所有的中间节点称为bucket；根节点称为root，是整个集群的入口。每个节点都用于唯一的数字ID和类型，但是只有叶子节点采用与非负ID。父节点的权重是所有孩子节点权重之和。</p><p>CRUSH放置策略可在故障域中分布对象副本，同时保持所需的分布。例如，为了解决并发故障的可能性，可能需要确保数据副本位于使用不同架子，机架，电源，控制器和/或物理位置的设备上。</p><p>常见的节点层级</p><ul><li><code>osd</code> (or <code>device</code>)</li><li><code>host</code></li><li><code>chassis</code></li><li><code>rack</code></li><li><code>row</code></li><li><code>pdu</code> 电源分配单元</li><li><code>pod</code></li><li><code>room</code></li><li><code>datacenter</code></li><li><code>zone</code></li><li><code>region</code></li><li><code>root</code></li></ul><p><img src="/img/cluster_mapdemo.png" alt="image-20201128211039048"></p><h2 id="3-2-数据分布策略——Placement-Rule"><a href="#3-2-数据分布策略——Placement-Rule" class="headerlink" title="3.2 数据分布策略——Placement Rule"></a>3.2 数据分布策略——Placement Rule</h2><p>CRUSH算法的核心包括三个步骤：TAKE，SELECT和EMIT。<br>$TAKE(a)$：从cluster_map选择指定编号的bucket并放入工作向量作为下一级SELECT的输入。系统默认采用root作为输入。</p><p><img src="/img/crush1.png" style="zoom:67%;" /></p><p>$SELECT(n,t)$:从bucket随机选择指定类型和数量的item。n: number，t: type。type可以设为 容灾域类型，比如rack 或host。Ceph当前支持两种备份策略——多副本和纠删码，相应的有两种选择方法first n 和 indep. 主要区别是纠删码要求结果是有序的。</p><ul><li><p>$f$在这里表示失败的尝试数，初始设为0.</p></li><li><p>$r$表示副本编号，它的范围是[1,n]。</p></li><li>CRUSH采用深度优先搜索方式遍历所有副本。</li></ul><p><img src="/img/crush2.png" style="zoom:67%;" /></p><p>我们下面再看一下选择算法。</p><p><img src="/img/crush4.png" alt="image-20201129194851670"></p><ul><li>（左图）first n：比如 n = 6， select(6, disk), 当第二个item被拒绝，其余节点会填充空位。尝试次数f 将更新 副本编号r。</li><li>（右图）每一个队列有概率上独立的顺序，这儿$f_r = 1, r’=r+f_rn=8$，对应device:h，因此会用h进行“填充”。</li></ul><p>因为在容灾域模式下会产生递归调用，所以还需要限制产生递归调用时作为下一级输入的全局尝试次数（<code>choose_total_tries</code>），因为这个限制会导致递归调用时全局尝试次数成倍增长，按照递归的概念，多次递归后这个全局尝试次数应该成指数增长，但是实际上至多调用一次，所以这里是将原始尝试次数放大N倍后作为下一级输入的全局尝试数，实现上采用一个布尔变量（<code>chooseleaf_descent_once</code>,i.e. “first n”）进行控制，如果为真，则在产生递归调用至多重试一次，否则则不进行重试，由调用者自身进行重试。N由<code>chooseleaf_vary_r</code>进行决定。</p><p><img src="/img/crush5.png" alt="image-20201129195221719" style="zoom:67%;" /></p><p>这儿的$b.c(r’,x)$即为第二节谈到的 Bucket Choose ， 我们采用Straw2算法。<br>如果得到的结果不是目标类型，则继续向下递归。并设置重试标记$retry_bucket$为true.</p><p><img src="/img/crush6.png" alt="image-20201129195537731" style="zoom:67%;" /></p><p>冲突（Collision）： 选中的条目已经存在于输出条目列表之中。<br>OSD过载或失效：</p><ol><li>由于集群规模较小，导致集群PG总数有限，CRUSH输入不够。</li><li>CRUSH本身缺陷，每次选择是单个条目被选中的独立概率，但是CRUSH所要求的副本策略使得针对同一个输入、多个副本直接的选择变成了条件概率。</li></ol><p>在老的CRUSH实现，为了避免每次回到初始输入的bucket下重试，可以在当前的bucket下直接进行重试。此时同样需要对局部尝试次数进行限制，称为(<code>choose_local_retries</code>)。</p><p>$Overload(o,x)$</p><p>除了由容量计算得到的真实权重之外，Ceph还设置了可以人工调整的权重（reweight）。算法正常选中一个OSD之后，最后还基于此reweight进行一次过载测试，如果测试失败，则将仍然拒绝该item。<br>我们可以通过设置reweight介于[0,0x10000]之间，如果为0就不能通过测试，为0x10000就是一定会通过测试。在实际应用中通过降低过载OSD或者增加空闲reweight都可以触发数据在OSD之间重新分布。并且可以区分暂时失效的OSD和永久失效的OSD。</p><p><img src="/img/reweight.png" alt="reweight" style="zoom:67%;" /></p><p>$EMIT$:输出最终选择结果给上级调用者并返回。</p><p><img src="/img/crush8.png" alt="image-20201129195731168" style="zoom:67%;" /></p><p>总结</p><p>我们以firstn为例展示从指定bucket查找指定数量item的过程。</p><p><img src="/img/crush9.png" alt="image-20201129195815305"></p><hr><h1 id="4-操作CRUSH"><a href="#4-操作CRUSH" class="headerlink" title="4 操作CRUSH"></a>4 操作CRUSH</h1><p>1 查看osd tree （含权重）</p><pre><code class="hljs dos">sudo ceph osd <span class="hljs-built_in">tree</span></code></pre><pre><code class="hljs lsl">ID  CLASS  WEIGHT   TYPE NAME       STATUS  REWEIGHT  PRI-AFF<span class="hljs-number">-1</span>         <span class="hljs-number">0.05846</span>  root <span class="hljs-section">default</span>                             <span class="hljs-number">-5</span>         <span class="hljs-number">0.01949</span>      host node3                            <span class="hljs-number">1</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.1</span>       up   <span class="hljs-number">1.00000</span>  <span class="hljs-number">1.00000</span><span class="hljs-number">-3</span>         <span class="hljs-number">0.01949</span>      host node4                            <span class="hljs-number">0</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.0</span>       up   <span class="hljs-number">1.00000</span>  <span class="hljs-number">1.00000</span><span class="hljs-number">-7</span>         <span class="hljs-number">0.01949</span>      host node5                            <span class="hljs-number">2</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.2</span>       up   <span class="hljs-number">1.00000</span>  <span class="hljs-number">1.00000</span></code></pre><p><code>ID</code>: 每个节点在集群唯一ID。<code>class</code>：每个节点的类别。<code>weight</code>:每个节点的权重。</p><p>2 查看整个集群空间利用率</p><pre><code class="hljs dos">sudo ceph osd df <span class="hljs-built_in">tree</span></code></pre><pre><code class="hljs angelscript">ID  CLASS  WEIGHT   REWEIGHT  SIZE    RAW USE  DATA     OMAP    META      AVAIL   %USE  VAR   PGS  STATUS  TYPE NAME     <span class="hljs-number">-1</span>         <span class="hljs-number">0.05998</span>         -  <span class="hljs-number">60</span> GiB  <span class="hljs-number">3.0</span> GiB  <span class="hljs-number">2.4</span> MiB  <span class="hljs-number">59</span> KiB   <span class="hljs-number">3.0</span> GiB  <span class="hljs-number">57</span> GiB  <span class="hljs-number">5.01</span>  <span class="hljs-number">1.00</span>    -          root <span class="hljs-keyword">default</span>  <span class="hljs-number">-5</span>         <span class="hljs-number">0.00999</span>         -  <span class="hljs-number">20</span> GiB  <span class="hljs-number">1.0</span> GiB  <span class="hljs-number">824</span> KiB  <span class="hljs-number">18</span> KiB  <span class="hljs-number">1024</span> MiB  <span class="hljs-number">19</span> GiB  <span class="hljs-number">5.01</span>  <span class="hljs-number">1.00</span>    -              host node3 <span class="hljs-number">1</span>    ssd  <span class="hljs-number">0.00999</span>   <span class="hljs-number">1.00000</span>  <span class="hljs-number">20</span> GiB  <span class="hljs-number">1.0</span> GiB  <span class="hljs-number">824</span> KiB  <span class="hljs-number">18</span> KiB  <span class="hljs-number">1024</span> MiB  <span class="hljs-number">19</span> GiB  <span class="hljs-number">5.01</span>  <span class="hljs-number">1.00</span>   <span class="hljs-number">81</span>      up          osd<span class="hljs-number">.1</span> <span class="hljs-number">-3</span>         <span class="hljs-number">0.01999</span>         -  <span class="hljs-number">20</span> GiB  <span class="hljs-number">1.0</span> GiB  <span class="hljs-number">824</span> KiB  <span class="hljs-number">17</span> KiB  <span class="hljs-number">1024</span> MiB  <span class="hljs-number">19</span> GiB  <span class="hljs-number">5.01</span>  <span class="hljs-number">1.00</span>    -              host node4 <span class="hljs-number">0</span>    ssd  <span class="hljs-number">0.01999</span>   <span class="hljs-number">1.00000</span>  <span class="hljs-number">20</span> GiB  <span class="hljs-number">1.0</span> GiB  <span class="hljs-number">824</span> KiB  <span class="hljs-number">17</span> KiB  <span class="hljs-number">1024</span> MiB  <span class="hljs-number">19</span> GiB  <span class="hljs-number">5.01</span>  <span class="hljs-number">1.00</span>   <span class="hljs-number">81</span>      up          osd<span class="hljs-number">.0</span> <span class="hljs-number">-7</span>         <span class="hljs-number">0.03000</span>         -  <span class="hljs-number">20</span> GiB  <span class="hljs-number">1.0</span> GiB  <span class="hljs-number">828</span> KiB  <span class="hljs-number">24</span> KiB  <span class="hljs-number">1024</span> MiB  <span class="hljs-number">19</span> GiB  <span class="hljs-number">5.01</span>  <span class="hljs-number">1.00</span>    -              host node5 <span class="hljs-number">2</span>    ssd  <span class="hljs-number">0.03000</span>   <span class="hljs-number">1.00000</span>  <span class="hljs-number">20</span> GiB  <span class="hljs-number">1.0</span> GiB  <span class="hljs-number">828</span> KiB  <span class="hljs-number">24</span> KiB  <span class="hljs-number">1024</span> MiB  <span class="hljs-number">19</span> GiB  <span class="hljs-number">5.01</span>  <span class="hljs-number">1.00</span>   <span class="hljs-number">81</span>      up          osd<span class="hljs-number">.2</span>                        TOTAL  <span class="hljs-number">60</span> GiB  <span class="hljs-number">3.0</span> GiB  <span class="hljs-number">2.4</span> MiB  <span class="hljs-number">61</span> KiB   <span class="hljs-number">3.0</span> GiB  <span class="hljs-number">57</span> GiB  <span class="hljs-number">5.01</span>                                   MIN/MAX VAR: <span class="hljs-number">1.00</span>/<span class="hljs-number">1.00</span>  STDDEV: <span class="hljs-number">0</span></code></pre><h2 id="4-1-Rules"><a href="#4-1-Rules" class="headerlink" title="4.1 Rules"></a>4.1 Rules</h2><p>查看集群的rules</p><pre><code class="hljs crmsh">sudo ceph osd crush <span class="hljs-keyword">rule</span> ls</code></pre><pre><code class="hljs ebnf"><span class="hljs-attribute">replicated_rule</span><span class="hljs-attribute">ecpool</span></code></pre><p>你也能打印出rules的细节</p><pre><code class="hljs crmsh">sudo ceph osd crush <span class="hljs-keyword">rule</span> dump</code></pre><pre><code class="hljs json">[    &#123;        <span class="hljs-attr">&quot;rule_id&quot;</span>: <span class="hljs-number">0</span>,        <span class="hljs-attr">&quot;rule_name&quot;</span>: <span class="hljs-string">&quot;replicated_rule&quot;</span>,        <span class="hljs-attr">&quot;ruleset&quot;</span>: <span class="hljs-number">0</span>,        <span class="hljs-attr">&quot;type&quot;</span>: <span class="hljs-number">1</span>,        <span class="hljs-attr">&quot;min_size&quot;</span>: <span class="hljs-number">1</span>,        <span class="hljs-attr">&quot;max_size&quot;</span>: <span class="hljs-number">10</span>,        <span class="hljs-attr">&quot;steps&quot;</span>: [            &#123;                <span class="hljs-attr">&quot;op&quot;</span>: <span class="hljs-string">&quot;take&quot;</span>,                <span class="hljs-attr">&quot;item&quot;</span>: <span class="hljs-number">-1</span>,                <span class="hljs-attr">&quot;item_name&quot;</span>: <span class="hljs-string">&quot;default&quot;</span>            &#125;,            &#123;                <span class="hljs-attr">&quot;op&quot;</span>: <span class="hljs-string">&quot;chooseleaf_firstn&quot;</span>,                <span class="hljs-attr">&quot;num&quot;</span>: <span class="hljs-number">0</span>,                <span class="hljs-attr">&quot;type&quot;</span>: <span class="hljs-string">&quot;host&quot;</span>            &#125;,            &#123;                <span class="hljs-attr">&quot;op&quot;</span>: <span class="hljs-string">&quot;emit&quot;</span>            &#125;        ]    &#125;,    &#123;        <span class="hljs-attr">&quot;rule_id&quot;</span>: <span class="hljs-number">1</span>,        <span class="hljs-attr">&quot;rule_name&quot;</span>: <span class="hljs-string">&quot;ecpool&quot;</span>,        <span class="hljs-attr">&quot;ruleset&quot;</span>: <span class="hljs-number">1</span>,        <span class="hljs-attr">&quot;type&quot;</span>: <span class="hljs-number">3</span>,        <span class="hljs-attr">&quot;min_size&quot;</span>: <span class="hljs-number">3</span>,        <span class="hljs-attr">&quot;max_size&quot;</span>: <span class="hljs-number">3</span>,        <span class="hljs-attr">&quot;steps&quot;</span>: [            &#123;                <span class="hljs-attr">&quot;op&quot;</span>: <span class="hljs-string">&quot;set_chooseleaf_tries&quot;</span>,                <span class="hljs-attr">&quot;num&quot;</span>: <span class="hljs-number">5</span>            &#125;,            &#123;                <span class="hljs-attr">&quot;op&quot;</span>: <span class="hljs-string">&quot;set_choose_tries&quot;</span>,                <span class="hljs-attr">&quot;num&quot;</span>: <span class="hljs-number">100</span>            &#125;,            &#123;                <span class="hljs-attr">&quot;op&quot;</span>: <span class="hljs-string">&quot;take&quot;</span>,                <span class="hljs-attr">&quot;item&quot;</span>: <span class="hljs-number">-1</span>,                <span class="hljs-attr">&quot;item_name&quot;</span>: <span class="hljs-string">&quot;default&quot;</span>            &#125;,            &#123;                <span class="hljs-attr">&quot;op&quot;</span>: <span class="hljs-string">&quot;chooseleaf_indep&quot;</span>,                <span class="hljs-attr">&quot;num&quot;</span>: <span class="hljs-number">0</span>,                <span class="hljs-attr">&quot;type&quot;</span>: <span class="hljs-string">&quot;host&quot;</span>            &#125;,            &#123;                <span class="hljs-attr">&quot;op&quot;</span>: <span class="hljs-string">&quot;emit&quot;</span>            &#125;        ]    &#125;]</code></pre><h2 id="4-2-Device-class"><a href="#4-2-Device-class" class="headerlink" title="4.2 Device class"></a>4.2 Device class</h2><p>可以通过以下命令设置device的类别（<code>hdd</code>, <code>ssd</code>, or <code>nvme</code>）</p><pre><code class="hljs dsconfig"><span class="hljs-string">sudo </span><span class="hljs-string">ceph </span><span class="hljs-string">osd </span><span class="hljs-string">crush </span><span class="hljs-built_in">set-device-class</span> &lt;<span class="hljs-string">class&gt;</span> &lt;<span class="hljs-string">osd-name&gt;</span> [...]</code></pre><p>可以通过以下命令更改为其它类别</p><pre><code class="hljs ruby">sudo ceph osd crush rm-device-<span class="hljs-class"><span class="hljs-keyword">class</span> &lt;osd-<span class="hljs-title">name</span>&gt; [...]</span></code></pre><p>如果我们想创建新的placement rule</p><pre><code class="hljs dsconfig"><span class="hljs-string">sudo </span><span class="hljs-string">ceph </span><span class="hljs-string">osd </span><span class="hljs-string">crush </span><span class="hljs-string">rule </span><span class="hljs-built_in">create-replicated</span> &lt;<span class="hljs-string">rule-name&gt;</span> &lt;<span class="hljs-string">root&gt;</span> &lt;<span class="hljs-string">failure-domain&gt;</span> &lt;<span class="hljs-string">class&gt;</span></code></pre><p>对于pool而言就是</p><pre><code class="hljs routeros">sudo ceph osd<span class="hljs-built_in"> pool </span><span class="hljs-builtin-name">set</span> &lt;pool-name&gt; crush_rule &lt;rule-name&gt;</code></pre><p>通过为使用中的每个仅包含该类设备的设备类创建一个“影子” CRUSH层次结构来实现设备类。然后，CRUSH规则可以在影子层次结构上分布数据。</p><pre><code class="hljs ada">sudo ceph osd crush tree <span class="hljs-comment">--show-shadow</span></code></pre><pre><code class="hljs lsl">ID  CLASS  WEIGHT   TYPE NAME         <span class="hljs-number">-2</span>    ssd  <span class="hljs-number">0.05846</span>  root <span class="hljs-section">default</span>~ssd  <span class="hljs-number">-6</span>    ssd  <span class="hljs-number">0.01949</span>      host node3~ssd <span class="hljs-number">1</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.1</span>     <span class="hljs-number">-4</span>    ssd  <span class="hljs-number">0.01949</span>      host node4~ssd <span class="hljs-number">0</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.0</span>     <span class="hljs-number">-8</span>    ssd  <span class="hljs-number">0.01949</span>      host node5~ssd <span class="hljs-number">2</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.2</span>     <span class="hljs-number">-1</span>         <span class="hljs-number">0.05846</span>  root <span class="hljs-section">default</span>      <span class="hljs-number">-5</span>         <span class="hljs-number">0.01949</span>      host node3     <span class="hljs-number">1</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.1</span>     <span class="hljs-number">-3</span>         <span class="hljs-number">0.01949</span>      host node4     <span class="hljs-number">0</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.0</span>     <span class="hljs-number">-7</span>         <span class="hljs-number">0.01949</span>      host node5     <span class="hljs-number">2</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.2</span></code></pre><h2 id="4-3-权重集"><a href="#4-3-权重集" class="headerlink" title="4.3 权重集"></a>4.3 权重集</h2><p>权重集使群集可以根据群集的详细信息（层次结构，池等）执行数值优化，以实现平衡分配。</p><p>支持两种类型的权重集，目前支持两种类型的weight set：</p><ul><li>Compat权重集，针对集群每个节点而设计的权重，具有良好的向后兼容性。</li><li>Per-pool权重集，针对数据池的权重集。</li></ul><h2 id="4-4-修改CRUSH-Map"><a href="#4-4-修改CRUSH-Map" class="headerlink" title="4.4 修改CRUSH Map"></a>4.4 修改CRUSH Map</h2><p>要在正在运行的群集的CRUSH映射中添加或移动OSD，请执行以下操作：</p><pre><code class="hljs sql">sudo ceph osd crush <span class="hljs-keyword">set</span> &#123;<span class="hljs-keyword">name</span>&#125; &#123;weight&#125; root=&#123;root&#125; [&#123;<span class="hljs-keyword">bucket</span>-<span class="hljs-keyword">type</span>&#125;=&#123;<span class="hljs-keyword">bucket</span>-<span class="hljs-keyword">name</span>&#125; ...]</code></pre><p>{name}指osd名称</p><h2 id="4-5-调整OSD权重¶"><a href="#4-5-调整OSD权重¶" class="headerlink" title="4.5 调整OSD权重¶"></a>4.5 调整OSD权重<a href="https://docs.ceph.com/en/latest/rados/operations/crush-map/#adjust-osd-weight">¶</a></h2><p>要在正在运行的群集的CRUSH映射中调整OSD的CRUSH权重，请执行以下操作：</p><pre><code class="hljs dust"><span class="xml">sudo ceph osd crush reweight </span><span class="hljs-template-variable">&#123;name&#125;</span><span class="xml"> </span><span class="hljs-template-variable">&#123;weight&#125;</span></code></pre><p>要从正在运行的群集的CRUSH映射中删除OSD，请执行以下操作：</p><pre><code class="hljs routeros">sudo ceph osd crush <span class="hljs-builtin-name">remove</span> &#123;name&#125;</code></pre><p>要在正在运行的集群的CRUSH映射中添加存储桶，请执行以下 命令：<code>sudo ceph osd crush add-bucket</code></p><pre><code class="hljs smali">sudo ceph osd crush<span class="hljs-built_in"> add-bucket </span>&#123;bucket-name&#125; &#123;bucket-type&#125;</code></pre><p>要将存储桶移动到CRUSH地图层次结构中的其他位置或位置，请执行以下操作：</p><pre><code class="hljs sqf">sudo ceph osd crush <span class="hljs-built_in">move</span> &#123;bucket-<span class="hljs-built_in">name</span>&#125; &#123;bucket-<span class="hljs-built_in">type</span>&#125;=&#123;bucket-<span class="hljs-built_in">name</span>&#125;, [...]</code></pre><p>要从CRUSH层次结构中删除存储桶，请执行以下操作：</p><pre><code class="hljs routeros">sudo ceph osd crush <span class="hljs-builtin-name">remove</span> &#123;bucket-name&#125;</code></pre><h2 id="4-6-创建一个Compat权重集"><a href="#4-6-创建一个Compat权重集" class="headerlink" title="4.6 创建一个Compat权重集"></a>4.6 创建一个Compat权重集</h2><p>要创建<em>兼容的权重集</em>：</p><pre><code class="hljs livecodeserver">sudo ceph osd crush weight-<span class="hljs-built_in">set</span> <span class="hljs-built_in">create</span>-compat</code></pre><p>兼容重量组的重量可以通过以下方式调整：</p><pre><code class="hljs applescript">sudo ceph osd crush weight-<span class="hljs-keyword">set</span> reweight-compat &#123;<span class="hljs-built_in">name</span>&#125; &#123;weight&#125;</code></pre><p>可以用以下方法删除：</p><pre><code class="hljs routeros">sudo ceph osd crush weight-<span class="hljs-builtin-name">set</span> rm-compat</code></pre><h2 id="4-7-创建per-pool的权重集"><a href="#4-7-创建per-pool的权重集" class="headerlink" title="4.7 创建per-pool的权重集"></a>4.7 创建per-pool的权重集</h2><p>要为特定池创建权重集，请执行以下操作：</p><pre><code class="hljs sql">sudo ceph osd crush weight-<span class="hljs-keyword">set</span> <span class="hljs-keyword">create</span> &#123;pool-<span class="hljs-keyword">name</span>&#125; &#123;<span class="hljs-keyword">mode</span>&#125;</code></pre><p>调整权重：</p><pre><code class="hljs applescript">sudo ceph osd crush weight-<span class="hljs-keyword">set</span> reweight &#123;pool-<span class="hljs-built_in">name</span>&#125; &#123;<span class="hljs-built_in">item</span>-<span class="hljs-built_in">name</span>&#125; &#123;weight [...]&#125;</code></pre><p>要列出现有的权重集，请执行以下操作：</p><pre><code class="hljs routeros">sudo ceph osd crush weight-<span class="hljs-builtin-name">set</span> ls</code></pre><p>要删除，请执行以下操作：</p><pre><code class="hljs applescript">sudo ceph osd crush weight-<span class="hljs-keyword">set</span> rm &#123;pool-<span class="hljs-built_in">name</span>&#125;</code></pre><h2 id="4-8-为副本创建规则"><a href="#4-8-为副本创建规则" class="headerlink" title="4.8 为副本创建规则"></a>4.8 为副本创建规则</h2><pre><code class="hljs dsconfig"><span class="hljs-string">sudo </span><span class="hljs-string">ceph </span><span class="hljs-string">osd </span><span class="hljs-string">crush </span><span class="hljs-string">rule </span><span class="hljs-built_in">create-replicated</span> &#123;<span class="hljs-string">name&#125;</span> &#123;<span class="hljs-string">root&#125;</span> &#123;<span class="hljs-string">failure-domain-</span><span class="hljs-string">type&#125;</span> [&#123;<span class="hljs-string">class&#125;</span>]</code></pre><h2 id="4-9-为纠删码创建规则"><a href="#4-9-为纠删码创建规则" class="headerlink" title="4.9 为纠删码创建规则"></a>4.9 为纠删码创建规则</h2><p>对于纠删码（EC）池，需要做出相同的基本决策：故障域是什么，层次结构中的哪个节点将数据放置在（通常为<code>default</code>）下，并且放置位置将限制为特定的设备类。但是，纠删码池的创建方式略有不同，因为需要根据所使用的删除代码仔细构建它们。因此，您必须在<em>纠删码配置文件中</em>包含此信息。使用配置文件创建池时，将根据该规则显式或自动创建CRUSH规则。</p><p>纠删码配置文件可以列出：</p><pre><code class="hljs vim">sudo ceph osd erasure-code-<span class="hljs-keyword">profile</span> <span class="hljs-keyword">ls</span></code></pre><p>查看某个特定配置</p><pre><code class="hljs vim">sudo ceph osd erasure-code-<span class="hljs-keyword">profile</span> <span class="hljs-built_in">get</span> &#123;<span class="hljs-keyword">profile</span>-name&#125;</code></pre><p>通常，绝对不要修改配置文件。而是在创建新池或为现有池创建新规则时创建并使用新配置文件。</p><p>感兴趣的纠删码配置文件属性为：</p><blockquote><ul><li><strong>rush-root</strong>：要在其下放置数据的CRUSH节点的名称[默认值：<code>default</code>]。</li><li><strong>rush-failure-domain</strong>：在其上分配擦除编码分片的CRUSH存储桶类型[默认值：<code>host</code>]。</li><li><strong>rush-device-class</strong>：放置数据的设备类[默认：无，表示使用了所有设备]。</li><li><strong>k</strong>和<strong>m</strong>（对于<code>lrc</code>插件，为<strong>l</strong>）：它们确定擦除代码分片的数量，影响最终的CRUSH规则。</li></ul></blockquote><p>定义配置文件后，您可以使用以下方法创建CRUSH规则：</p><pre><code class="hljs dsconfig"><span class="hljs-string">sudo </span><span class="hljs-string">ceph </span><span class="hljs-string">osd </span><span class="hljs-string">crush </span><span class="hljs-string">rule </span><span class="hljs-built_in">create-erasure</span> &#123;<span class="hljs-string">name&#125;</span> &#123;<span class="hljs-string">profile-name&#125;</span><span class="hljs-comment">#&#123;name&#125;为规则名称</span></code></pre><p>可以通过以下方式删除池未使用的规则：</p><pre><code class="hljs pgsql">sudo ceph osd crush <span class="hljs-keyword">rule</span> rm &#123;<span class="hljs-keyword">rule</span>-<span class="hljs-type">name</span>&#125;</code></pre><h2 id="4-10-自定义CRUSH规则♥"><a href="#4-10-自定义CRUSH规则♥" class="headerlink" title="4.10 自定义CRUSH规则♥"></a>4.10 自定义CRUSH规则♥</h2><blockquote><p><a href="https://docs.ceph.com/en/latest/rados/operations/crush-map-edits/">https://docs.ceph.com/en/latest/rados/operations/crush-map-edits/</a></p></blockquote><p>我们可以通过CLI来很方便的修改CRUSH各项配置，但是如果修改项目过多，而集群较多，直接编辑CRUSH map 会是更好的选择。在一些特殊情况下，比如集群HDD和SSD和NVME混合则必须单独配置CRUSH rules。</p><h3 id="（1）获取CRUSH-Map"><a href="#（1）获取CRUSH-Map" class="headerlink" title="（1）获取CRUSH Map"></a>（1）获取CRUSH Map</h3><pre><code class="hljs dts">sudo ceph osd getcrushmap -<span class="hljs-class">o </span>&#123;compilefilename&#125;</code></pre><p>之后我们将其解码为txt</p><pre><code class="hljs dts">crushtool -<span class="hljs-class">d </span>&#123;compilefilename&#125; -<span class="hljs-class">o </span>&#123;outputfilename&#125;.txt</code></pre><p>例如 </p><pre><code class="hljs css"><span class="hljs-selector-tag">crushtool</span> <span class="hljs-selector-tag">-d</span> <span class="hljs-selector-tag">mycrushmap</span> <span class="hljs-selector-tag">-o</span> <span class="hljs-selector-tag">mycrushmap</span><span class="hljs-selector-class">.txt</span></code></pre><p>典型的crush map如下:</p><p>它包含6个部分：</p><ol><li><strong>可调项：</strong> tunable</li><li><strong>设备：</strong>设备是存储数据的单个OSD。</li><li><strong>types</strong>：存储桶<code>types</code>定义在CRUSH层次结构中使用的存储桶的类型。存储桶由存储位置（例如，行，机架，机箱，主机等）及其分配的权重的分层聚合组成。</li><li><strong>存储桶：</strong>定义存储桶类型后，必须定义层次结构中的每个节点，其类型以及它包含的设备或其他节点。</li><li><strong>规则：</strong>规则定义有关数据如何在层次结构中的各个设备之间分配的策略。</li><li>choice_args <strong>：</strong> Choose_args是与层次结构关联的替代权重，这些权重已进行调整以优化数据放置。单个choose_args映射可以用于整个集群，也可以为每个单独的池创建一个映射。</li></ol><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash"> begin crush map</span>tunable choose_local_tries 0tunable choose_local_fallback_tries 0tunable choose_total_tries 50tunable chooseleaf_descend_once 1tunable chooseleaf_vary_r 1tunable chooseleaf_stable 1tunable straw_calc_version 1tunable allowed_bucket_algs 54<span class="hljs-meta">#</span><span class="bash"> devices</span>device 0 osd.0 class ssddevice 1 osd.1 class ssddevice 2 osd.2 class ssd<span class="hljs-meta">#</span><span class="bash"> types</span>type 0 osdtype 1 hosttype 2 chassistype 3 racktype 4 rowtype 5 pdutype 6 podtype 7 roomtype 8 datacentertype 9 zonetype 10 regiontype 11 root<span class="hljs-meta">#</span><span class="bash"> buckets</span>host node4 &#123;        id -3           # do not change unnecessarily        id -4 class ssd         # do not change unnecessarily        # weight 0.020        alg straw2        hash 0  # rjenkins1        item osd.0 weight 0.020&#125;...root default &#123;        id -1           # do not change unnecessarily        id -2 class ssd         # do not change unnecessarily        # weight 0.060        alg straw2        hash 0  # rjenkins1        item node4 weight 0.020        item node3 weight 0.010        item node5 weight 0.030&#125;<span class="hljs-meta">#</span><span class="bash">rules</span>rule replicated_rule &#123;        id 0        type replicated        min_size 1        max_size 10        step take default        step chooseleaf firstn 0 type host        step emit&#125;rule ecpool &#123;        id 1        type erasure        min_size 3        max_size 3        step set_chooseleaf_tries 5        step set_choose_tries 100        step take default        step chooseleaf indep 0 type host        step emit&#125;...<span class="hljs-meta">#</span><span class="bash"> choose_args</span>choose_args 4 &#123;  &#123;    bucket_id -1    weight_set [      [ 0.020 0.010 0.030 ]    ]  &#125;&#125;...<span class="hljs-meta">#</span><span class="bash"> end crush map</span></code></pre><p>我们对ruleset中参数稍作解释</p><p><code>step</code> 包括三个部分 take, chooseleaf, emit</p><ul><li>chooseleaf, 容灾域模式，可以替换为choose，即非容灾域模式。</li><li>firstn, 两种选择算法之一，参看前面理论部分，可以替换为indep.</li><li>0, 表示由具体的调用者指定输出的副本数，例如不同的pool可以使用同一套ruleset（拥有相同的备份策略），但是可以拥有不同的副本数。</li><li>type，对应chooseleaf操作，指示输出必须是分布在由本选项指定类型的、不同的bucket之下的叶子节点；对应choose操作，指示输出类型。</li></ul><p><code>set_chooseleaf_tries</code>: 容灾域下产生递归调用时的尝试次数。</p><p><code>set_choose_tries</code>: 非容灾域下产生递归调用的尝试次数。</p><p><code>min_size</code>: 如果池中的副本数少于此数量，则CRUSH将 <strong>不会</strong>选择此规则。</p><p><code>max_size</code>: 如果池中的副本数量超过此数量，则CRUSH将 <strong>不会</strong>选择此规则。</p><blockquote><p><code>firstn</code> 与 <code>indep</code></p><ul><li><p>描述</p><p>控制在CRUSH映射中标记了项目（OSD）时CRUSH使用的替换策略。<strong>如果此规则将用于复制池，则应使用<code>firstn</code>；如果是擦除编码池，则应使用<code>indep</code></strong>。原因与先前选择的设备发生故障时它们的行为有关。假设您有一个PG存储在OSD 1、2、3、4、5上。然后3下降。在“ firstn”模式下，CRUSH只需将其计算调整为选择1和2，然后选择3，但发现它已关闭，因此它重试并选择4和5，然后继续选择一个新的OSD6。因此最终的CRUSH映射更改为1、2、3、4、5-&gt; 1、2、4、5、6。但是，如果要存储EC池，则意味着您只需更改映射到OSD 4、5和6的数据！因此，“独立”模式试图不这样做。相反，您可以期望它在选择失败的OSD 3时再次尝试并选择6，以进行以下最终转换：1，2，3，4，5-&gt; 1，2，6，4，5</p></li></ul></blockquote><div class="note note-danger">            <p>重要 :给定的CRUSH规则可以分配给多个池，但是单个池不可能具有多个CRUSH规则。</p>          </div><h3 id="（2）修改并编译CRUSH-Map"><a href="#（2）修改并编译CRUSH-Map" class="headerlink" title="（2）修改并编译CRUSH Map"></a>（2）修改并编译CRUSH Map</h3><p>我们需要进行编译才能被ceph识别</p><pre><code class="hljs dts">crushtool - <span class="hljs-class">c </span>&#123;decompiled_filename&#125; -<span class="hljs-class">o </span>&#123;compiled_filename&#125;</code></pre><h3 id="（3）测试"><a href="#（3）测试" class="headerlink" title="（3）测试"></a>（3）测试</h3><p>例如我们打印出输入范围为[0,9]、副本数3，采用编号为0的ruleset映射的结果。</p><pre><code class="hljs brainfuck"><span class="hljs-comment">sudo</span> <span class="hljs-comment">crushtool</span> <span class="hljs-literal">-</span><span class="hljs-comment">i</span> <span class="hljs-comment">&#123;compiled_filename&#125;</span> --<span class="hljs-comment">test</span> --<span class="hljs-comment">min</span><span class="hljs-literal">-</span><span class="hljs-comment">x</span> <span class="hljs-comment">0</span> --<span class="hljs-comment">max</span><span class="hljs-literal">-</span><span class="hljs-comment">x</span> <span class="hljs-comment">9</span> --<span class="hljs-comment">num</span><span class="hljs-literal">-</span><span class="hljs-comment">rep</span> <span class="hljs-comment">3</span> --<span class="hljs-comment">ruleset</span> <span class="hljs-comment">0\</span><span class="hljs-comment"></span> --<span class="hljs-comment">show_mappings</span></code></pre><pre><code class="hljs angelscript">CRUSH rule <span class="hljs-number">0</span> x <span class="hljs-number">0</span> [<span class="hljs-number">1</span>,<span class="hljs-number">0</span>,<span class="hljs-number">2</span>]CRUSH rule <span class="hljs-number">0</span> x <span class="hljs-number">1</span> [<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]CRUSH rule <span class="hljs-number">0</span> x <span class="hljs-number">2</span> [<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]CRUSH rule <span class="hljs-number">0</span> x <span class="hljs-number">3</span> [<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>]CRUSH rule <span class="hljs-number">0</span> x <span class="hljs-number">4</span> [<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]CRUSH rule <span class="hljs-number">0</span> x <span class="hljs-number">5</span> [<span class="hljs-number">0</span>,<span class="hljs-number">2</span>,<span class="hljs-number">1</span>]CRUSH rule <span class="hljs-number">0</span> x <span class="hljs-number">6</span> [<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]CRUSH rule <span class="hljs-number">0</span> x <span class="hljs-number">7</span> [<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">0</span>]CRUSH rule <span class="hljs-number">0</span> x <span class="hljs-number">8</span> [<span class="hljs-number">2</span>,<span class="hljs-number">0</span>,<span class="hljs-number">1</span>]CRUSH rule <span class="hljs-number">0</span> x <span class="hljs-number">9</span> [<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">0</span>]</code></pre><p>也可以仅统计结果分布情况，输入变为[0,100000]</p><pre><code class="hljs brainfuck"><span class="hljs-comment">sudo</span> <span class="hljs-comment">crushtool</span> <span class="hljs-literal">-</span><span class="hljs-comment">i</span> <span class="hljs-comment">mycrushmap</span> --<span class="hljs-comment">test</span> --<span class="hljs-comment">min</span><span class="hljs-literal">-</span><span class="hljs-comment">x</span> <span class="hljs-comment">0</span> --<span class="hljs-comment">max</span><span class="hljs-literal">-</span><span class="hljs-comment">x</span> <span class="hljs-comment">100000</span> --<span class="hljs-comment">num</span><span class="hljs-literal">-</span><span class="hljs-comment">rep</span> <span class="hljs-comment">3\</span><span class="hljs-comment"></span> --<span class="hljs-comment">ruleset</span> <span class="hljs-comment">0</span> --<span class="hljs-comment">show_utilization</span></code></pre><pre><code class="hljs yaml"><span class="hljs-string">rule</span> <span class="hljs-number">0</span> <span class="hljs-string">(replicated_rule),</span> <span class="hljs-string">x</span> <span class="hljs-string">=</span> <span class="hljs-number">0</span><span class="hljs-string">..100000,</span> <span class="hljs-string">numrep</span> <span class="hljs-string">=</span> <span class="hljs-number">3</span><span class="hljs-string">..3</span><span class="hljs-string">rule</span> <span class="hljs-number">0</span> <span class="hljs-string">(replicated_rule)</span> <span class="hljs-string">num_rep</span> <span class="hljs-number">3</span> <span class="hljs-string">result</span> <span class="hljs-string">size</span> <span class="hljs-string">==</span> <span class="hljs-attr">2:</span><span class="hljs-number">3</span><span class="hljs-string">/100001</span><span class="hljs-string">rule</span> <span class="hljs-number">0</span> <span class="hljs-string">(replicated_rule)</span> <span class="hljs-string">num_rep</span> <span class="hljs-number">3</span> <span class="hljs-string">result</span> <span class="hljs-string">size</span> <span class="hljs-string">==</span> <span class="hljs-attr">3:</span><span class="hljs-number">99998</span><span class="hljs-string">/100001</span>  <span class="hljs-attr">device 0:</span> <span class="hljs-attr">stored :</span> <span class="hljs-number">100001</span> <span class="hljs-attr">expected :</span> <span class="hljs-number">100001</span>  <span class="hljs-attr">device 1:</span> <span class="hljs-attr">stored :</span> <span class="hljs-number">99998</span> <span class="hljs-attr">expected :</span> <span class="hljs-number">100001</span>  <span class="hljs-attr">device 2:</span> <span class="hljs-attr">stored :</span> <span class="hljs-number">100001</span> <span class="hljs-attr">expected :</span> <span class="hljs-number">100001</span></code></pre><p>需要注意的是，除了叶子节点，其它的层级均为虚拟的，例如下面这个例子，我们让所有副本都必须分布在编号为0,1,2者三个特定的osd上。</p><p>可以通过如下语句声明存储桶：</p><pre><code class="hljs clojure">[bucket-type] [bucket-name] &#123;        id [a unique negative numeric ID]        weight [the relative capacity/capability of the item(<span class="hljs-name">s</span>)]        alg [the bucket type: uniform | list | tree | straw | straw2 ]        hash [the hash type: <span class="hljs-number">0</span> by default]        item [item-name] weight [weight]&#125;</code></pre><pre><code class="hljs routeros">vim mycrushmap.txthost virtualhost&#123;id -14#weight 3.00alg straw2hash 0 # rejenkins1item osd.0 weight 1.00item osd.1 weight 1.00item osd.2 weight 1.00&#125;<span class="hljs-comment">#rules</span>rule customized_ruleset&#123;ruleset 1<span class="hljs-built_in">type </span>replicated min_size 1max_size 10<span class="hljs-keyword">step</span> take virtualhost<span class="hljs-keyword">step</span> chooseleaf firstn 0<span class="hljs-built_in"> type </span>osd<span class="hljs-keyword">step</span> emit&#125;</code></pre><h3 id="（4）注入集群"><a href="#（4）注入集群" class="headerlink" title="（4）注入集群"></a>（4）注入集群</h3><pre><code class="hljs dts">sudo ceph osd setcrushmap -<span class="hljs-class">i </span>&#123;compiledfilename&#125;</code></pre><h2 id="4-11数据重平衡"><a href="#4-11数据重平衡" class="headerlink" title="4.11数据重平衡"></a>4.11数据重平衡</h2><p>找到空间利用率比较高的osd然后执行</p><pre><code class="hljs \">sudo ceph osd reweight &#123;osd_num_id&#125; &#123;reweight&#125;</code></pre><p>当然也可以批量调整：目前有两种模式</p><ul><li>按照OSD当前的空间利用率(<code>reweight-by-utilization</code>) ;</li><li>按照PG在OSD之间的分布(<code>reweight-by-pg</code>)。</li></ul><p>为防止影响前端业务，可以先进行测试，这会触发PG进行迁移量统计。</p><p>例如：</p><pre><code class="hljs dust"><span class="xml">sudo ceph osd test-reweight-by-utilization </span><span class="hljs-template-variable">&#123;oload&#125;</span><span class="xml"> </span><span class="hljs-template-variable">&#123;max_change&#125;</span><span class="xml">\</span><span class="hljs-template-variable">&#123;max_osds&#125;</span><span class="xml"> </span><span class="hljs-template-variable">&#123;--no-increasing&#125;</span></code></pre><div class="table-container"><table><thead><tr><th style="text-align:center">参数</th><th style="text-align:center">含义</th></tr></thead><tbody><tr><td style="text-align:center">oload</td><td style="text-align:center">可选；整型，≥100，默认值120；当且仅当某个OSD的空间利用率大于等于集群瓶颈空间利用率的overload/100时，调整其reweight</td></tr><tr><td style="text-align:center">max_change</td><td style="text-align:center">可选，浮点数，[0,1]；默认受<code>mon_reweight_max_change</code>控制，目前为0.05.每次调整reweight的最大幅度，即调整上限。实际每个osd调整幅度取决于自身空间利用率与集群平均空间利用率的偏离程度——偏离越多调整越大</td></tr><tr><td style="text-align:center">max_osds</td><td style="text-align:center">可选，整型，默认受<code>mon_reweight_max_osds</code>控制，目前为4.每次至多调整的osd数目。</td></tr><tr><td style="text-align:center">—no-increasing</td><td style="text-align:center">可选,字符类型，如果携带，则从不将reweight进行上调（上调指将当前的underload的OSD权重调大，让其分担更多PG）；如果不携带，至多将OSD的reweight调整至1.0/</td></tr></tbody></table></div><p>使用以下参数进行确认</p><pre><code class="hljs dust"><span class="xml">sudo ceph osd reweight-by-utilization </span><span class="hljs-template-variable">&#123;oload&#125;</span><span class="xml"> </span><span class="hljs-template-variable">&#123;max_change&#125;</span><span class="xml">\</span><span class="hljs-template-variable">&#123;max_osds&#125;</span><span class="xml"> </span><span class="hljs-template-variable">&#123;--no-increasing&#125;</span></code></pre><blockquote><p>合理设置weights</p><p>Ceph将weights表示为两倍，从而可以进行精细调整。 weight是设备容量之间的相对差。 我们建议将1.00用作1TB存储设备的相对重量。 在这种情况下，权重为0.5代表大约500GB，权重为3.00代表大约3TB。 较高级别的存储桶的权重是该存储桶聚合的所有叶子项的总和。</p><p>桶项目weight是一维的，但您也可以计算项目重量以反映存储驱动器的性能。 例如，如果您有许多1TB驱动器，其中一些具有较低的数据传输速率，而另一些具有较高的数据传输速率，则即使它们具有相同的容量（例如，硬盘的权重为0.80），也可以对其进行不同的加权。 第一组总吞吐量较低的驱动器，以及1.20第二组总吞吐量较高的驱动器）。</p></blockquote>]]></content>
    
    
      
      
    <summary type="html">&lt;div class=&quot;note note-primary&quot;&gt;
            &lt;p&gt;本blog包括理论和实践两个部分，实践部分需要您事先部署成功Ceph集群！&lt;/p&gt;&lt;p&gt;参考《Ceph设计与实现》谢型果等，第一章。以及&lt;a href=&quot;https://docs.cep</summary>
      
    
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/categories/ceph/"/>
    
    <category term="分布式存储" scheme="http://durantthorvalds.top/categories/ceph/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/"/>
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/tags/ceph/"/>
    
    <category term="理论" scheme="http://durantthorvalds.top/tags/%E7%90%86%E8%AE%BA/"/>
    
    <category term="crush" scheme="http://durantthorvalds.top/tags/crush/"/>
    
  </entry>
  
  <entry>
    <title>「入门部署」Ceph-ansible部署集群</title>
    <link href="http://durantthorvalds.top/2020/11/24/Ceph-ansible%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/"/>
    <id>http://durantthorvalds.top/2020/11/24/Ceph-ansible%E9%83%A8%E7%BD%B2%E8%B8%A9%E5%9D%91%E6%97%A5%E8%AE%B0/</id>
    <published>2020-11-24T10:00:00.000Z</published>
    <updated>2020-12-16T08:34:15.044Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ceph-ansible部署踩坑日记"><a href="#Ceph-ansible部署踩坑日记" class="headerlink" title="Ceph-ansible部署踩坑日记"></a>Ceph-ansible部署踩坑日记</h1><blockquote><p>官方文档：<a href="https://docs.ceph.com/projects/ceph-ansible/en/latest/">https://docs.ceph.com/projects/ceph-ansible/en/latest/</a></p></blockquote><h1 id="Quick-Deployment-快速部署"><a href="#Quick-Deployment-快速部署" class="headerlink" title="Quick Deployment:快速部署"></a>Quick Deployment:快速部署</h1><div class="note note-danger">            <p>Important:</p><p>ceph-deploy 不再经常性维护， 并且在高于Nautilus的版本没有进行过测试。不推荐使用! </p>          </div><p><strong>Cephadm</strong>：Cephadm完美支持新的编排API、CLI和仪表盘特性，可用于快速部署Octopus及更新版本的Ceph集群。Cephadm更加简单，且不依赖其它自动化部署工具，但该工具不支持部署旧版本的Ceph（如14的Nautilus），所有Ceph进程也是运行在容器中的，意味着在修改源码的情况下还需要制作新的镜像，比较麻烦。<strong>官方文档中指出，Cephadm暂时不推荐用于生产环境。</strong></p><p><strong>Rook</strong>：可以把Ceph部署在Kubernetes集群中运行。与1类似的是，Ceph也是运行在容器中的。</p><blockquote><p>上述的两种方法都是容器部署</p></blockquote><p>第三方部署工具</p><p>【推荐👍】 <strong>ceph-ansible</strong>. 它被广泛使用。ceph-ansible未与Nautlius和Octopus中引入的新的Orchestrator API集成在一起，这意味着更新的管理功能和仪表板集成不可用。</p><p><a href="https://github.com/SUSE/DeepSea">DeepSea</a>使用Salt安装Ceph。</p><p><a href="https://jaas.ai/ceph-mon">jaas.ai/ceph-mon</a>使用Juju安装Ceph。</p><p><a href="https://github.com/openstack/puppet-ceph">github.com/openstack/puppet-ceph</a> 通过Puppet安装Ceph。</p><p>官方的最低要求是 <strong>3</strong> Monitors + <strong>3</strong> Managers + <strong>3</strong> OSDs 。 我们尝试用虚拟机搭建最小集群。</p><p>在运行ceph-mon守护程序的每个节点上，还应该设置一个ceph-mgr守护程序。</p><div class="table-container"><table><thead><tr><th style="text-align:center">虚拟机节点名称</th><th style="text-align:center">职责</th><th style="text-align:center">IP地址</th></tr></thead><tbody><tr><td style="text-align:center">ceph-master (w/ source-code compiled)</td><td style="text-align:center">mon0 + mgr0+osd0(部署节点)</td><td style="text-align:center">192.168.161.134</td></tr><tr><td style="text-align:center">ceph-node1</td><td style="text-align:center">mon1+mgr1</td><td style="text-align:center">192.168.161.130</td></tr><tr><td style="text-align:center">ceph-node2</td><td style="text-align:center">mon2+mgr2</td><td style="text-align:center">192.168.161.131</td></tr><tr><td style="text-align:center">ceph-osd1</td><td style="text-align:center">osd1</td><td style="text-align:center">192.168.161.132</td></tr><tr><td style="text-align:center">ceph-osd2</td><td style="text-align:center">osd2</td><td style="text-align:center">192.168.161.133</td></tr></tbody></table></div><div class="note note-primary">            <p>小技巧：我们可以先在1台虚拟机上配置好通用的预备环境，再克隆出另外的2台，随后调整部分配置后即可（如IP、主机名等）。克隆后记得重新生成网卡MAC地址</p>          </div><h3 id="安装前准备"><a href="#安装前准备" class="headerlink" title="安装前准备"></a>安装前准备</h3><p>关闭firewalld，设置selinux为disabled状态，设置ssh免密登录，配置时钟同步服务。</p><pre><code class="hljs nginx"><span class="hljs-attribute">sudo</span> ufw status<span class="hljs-comment">#查看防火墙状态 active:开启 inactive：关闭</span></code></pre><pre><code class="hljs puppet"><span class="hljs-comment"># mon作为控制节点</span>sudo apt install openssh-serverssh-keygen -t rsa ssh-copy-<span class="hljs-keyword">id</span> &#123;<span class="hljs-built_in">hostname</span>&#125;@&#123;ip&#125;<span class="hljs-comment">#复制密钥到各节点</span><span class="hljs-keyword">ssh</span> &#123;<span class="hljs-built_in">hostname</span>&#125;@&#123;ip&#125;</code></pre><p>mon节点作为时钟同步节点</p><pre><code class="hljs stylus">sudo apt install ntpsudo vim /etc/ntp.conf#在/etc/ntp.conf添加<span class="hljs-selector-id">#server</span> <span class="hljs-number">127.127</span>.<span class="hljs-number">1.0</span><span class="hljs-selector-id">#fudge</span> <span class="hljs-number">127.127</span>.<span class="hljs-number">1.0</span> stratum <span class="hljs-number">10</span>#并注释下列四行<span class="hljs-selector-id">#pool</span> <span class="hljs-number">0</span><span class="hljs-selector-class">.ubuntu</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> iburst<span class="hljs-selector-id">#pool</span> <span class="hljs-number">1</span><span class="hljs-selector-class">.ubuntu</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> iburst<span class="hljs-selector-id">#pool</span> <span class="hljs-number">2</span><span class="hljs-selector-class">.ubuntu</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> iburst<span class="hljs-selector-id">#pool</span> <span class="hljs-number">3</span><span class="hljs-selector-class">.ubuntu</span><span class="hljs-selector-class">.pool</span><span class="hljs-selector-class">.ntp</span><span class="hljs-selector-class">.org</span> iburst</code></pre><p>在其它节点</p><pre><code class="hljs routeros">sudo apt install ntpdate openssh-server --assume-yessudo /etc/init.d<span class="hljs-built_in">/ntp </span>restart sudo systemctl <span class="hljs-builtin-name">enable</span> ntp.service #启动ntpsudo ntpdate &#123;mon-hostname&#125;</code></pre><p>会得到矫正的时间</p><pre><code class="hljs routeros">Nov 06:31:02 ntpdate[8540]: adjust time<span class="hljs-built_in"> server </span>192.168.161.129 offset 0.097653 sec</code></pre><p>有可能出现 name or server not known 错误</p><p>在每个节点 \etc\hosts 加入所有其它节点映射，比如</p><pre><code class="hljs accesslog"><span class="hljs-number">192.168.161.129</span>  ceph-master</code></pre><p>再ping 或者 nslookup测试一下就行。</p><div class="note note-warning">            <p>不要在同一个节点同时安装ntp和ntpdate</p>          </div><p>另一种方法是直接和aliyun服务器同步，在ntp.conf末尾加上<code>server ntp.aliyun.com</code></p><p>再重启</p><pre><code class="hljs routeros">sudo /etc/init.d<span class="hljs-built_in">/ntp </span>restart</code></pre><h2 id="ceph-ansible-😁"><a href="#ceph-ansible-😁" class="headerlink" title="ceph-ansible 😁"></a>ceph-ansible <a href="https://docs.ceph.com/projects/ceph-ansible/en/latest/index.html#configuration-and-usage">😁</a></h2><blockquote><p>参考：<a href="https://www.cnblogs.com/zyxnhr/p/10543814.html">https://www.cnblogs.com/zyxnhr/p/10543814.html</a> 写的非常细致。</p><p><a href="https://blog.csdn.net/liuzhupeng/article/details/106767126">https://blog.csdn.net/liuzhupeng/article/details/106767126</a></p></blockquote><p> 三要素：inventory file, playbook and configuration。</p><p>Dependency: <code>python2</code>所有节点</p><p>首先测试能否连通其它节点</p><pre><code class="hljs routeros">ansible all -m<span class="hljs-built_in"> ping </span>#注意这儿不能加sudo，否则会permission denied</code></pre><p>如果没有问题</p><pre><code class="hljs arcade">node1 | <span class="hljs-function"><span class="hljs-params">SUCCESS</span> =&gt;</span> &#123;    <span class="hljs-string">&quot;ansible_facts&quot;</span>: &#123;        <span class="hljs-string">&quot;discovered_interpreter_python&quot;</span>: <span class="hljs-string">&quot;/usr/bin/python&quot;</span>    &#125;,    <span class="hljs-string">&quot;changed&quot;</span>: <span class="hljs-literal">false</span>,    <span class="hljs-string">&quot;ping&quot;</span>: <span class="hljs-string">&quot;pong&quot;</span>&#125;node2 | <span class="hljs-function"><span class="hljs-params">SUCCESS</span> =&gt;</span> &#123;    <span class="hljs-string">&quot;ansible_facts&quot;</span>: &#123;        <span class="hljs-string">&quot;discovered_interpreter_python&quot;</span>: <span class="hljs-string">&quot;/usr/bin/python3&quot;</span>    &#125;,    <span class="hljs-string">&quot;changed&quot;</span>: <span class="hljs-literal">false</span>,    <span class="hljs-string">&quot;ping&quot;</span>: <span class="hljs-string">&quot;pong&quot;</span>&#125;node3 | <span class="hljs-function"><span class="hljs-params">SUCCESS</span> =&gt;</span> &#123;    <span class="hljs-string">&quot;ansible_facts&quot;</span>: &#123;        <span class="hljs-string">&quot;discovered_interpreter_python&quot;</span>: <span class="hljs-string">&quot;/usr/bin/python3&quot;</span>    &#125;,    <span class="hljs-string">&quot;changed&quot;</span>: <span class="hljs-literal">false</span>,    <span class="hljs-string">&quot;ping&quot;</span>: <span class="hljs-string">&quot;pong&quot;</span>&#125;</code></pre><ol><li><h3 id="我们首先安装ceph-ansble"><a href="#我们首先安装ceph-ansble" class="headerlink" title="我们首先安装ceph-ansble."></a>我们首先安装ceph-ansble.</h3></li></ol><pre><code class="hljs awk">git clone https:<span class="hljs-regexp">//gi</span>thub.com<span class="hljs-regexp">/ceph/</span>ceph-ansible.gitgit checkout <span class="hljs-variable">$branch</span> <span class="hljs-comment">#默认master分支</span>pip install -r requirements.txt sudo apt install ansible</code></pre><ol><li><h3 id="再配置inventory"><a href="#再配置inventory" class="headerlink" title="再配置inventory"></a>再配置inventory</h3></li></ol><p>在 /etc/ansible/下创建<code>hosts</code>文件，clients节点不应该与mon osd等重叠。在最新版本，还需要设置<code>[monitoring]</code>. 个人感觉和mon节点设成一样就行了。</p><pre><code class="hljs csharp">[<span class="hljs-meta">mons</span>]node1node2node3[<span class="hljs-meta">osds</span>]node1node2node3[<span class="hljs-meta">rgws</span>]node1node2node3[<span class="hljs-meta">clients</span>]node4node5[<span class="hljs-meta">mgrs</span>]node1node2node3[<span class="hljs-meta">monitoring</span>]node1node2node3</code></pre><ol><li><strong>然后在下载下来的ansible目录下拷贝文件，根据节点的角色拷贝具体的文件</strong></li></ol><pre><code class="hljs stylus">#除了site<span class="hljs-selector-class">.yml</span>.sample，all<span class="hljs-selector-class">.yml</span>.sample是必须要修改的之外，其他文件根据要安装的角色自行修改cp site<span class="hljs-selector-class">.yml</span><span class="hljs-selector-class">.sample</span> site.ymlcp group_vars/osds<span class="hljs-selector-class">.yml</span><span class="hljs-selector-class">.sample</span> group_vars/osds.ymlcp group_vars/clients<span class="hljs-selector-class">.yml</span><span class="hljs-selector-class">.sample</span> group_vars/clients.ymlcp group_vars/mons<span class="hljs-selector-class">.yml</span><span class="hljs-selector-class">.sample</span> group_vars/mons.ymlcp group_vars/mgrs<span class="hljs-selector-class">.yml</span><span class="hljs-selector-class">.sample</span> group_vars/mgrs.ymlcp group_vars/all<span class="hljs-selector-class">.yml</span><span class="hljs-selector-class">.sample</span> group_vars/all.yml</code></pre><ol><li><h3 id="配置all-yml"><a href="#配置all-yml" class="headerlink" title="配置all.yml"></a>配置all.yml</h3></li></ol><p>我们需要修改osds.yml部分：</p><pre><code class="hljs yaml"><span class="hljs-string">--</span><span class="hljs-attr">dummy:</span><span class="hljs-attr">ceph_release_num:</span>  <span class="hljs-attr">octopus:</span> <span class="hljs-number">15</span><span class="hljs-attr">cluster:</span> <span class="hljs-string">ceph-test</span><span class="hljs-attr">ceph_origin:</span> <span class="hljs-string">repository</span><span class="hljs-attr">ceph_repository:</span> <span class="hljs-string">community</span><span class="hljs-attr">ceph_mirror:</span> <span class="hljs-string">https://mirrors.aliyun.com/ceph/</span><span class="hljs-attr">ceph_stable_key:</span> <span class="hljs-string">https://mirrors.aliyun.com/ceph/keys/release.asc</span><span class="hljs-attr">ceph_stable_release:</span> <span class="hljs-string">octopus</span><span class="hljs-attr">monitor_interface:</span> <span class="hljs-string">ens33</span><span class="hljs-attr">monitor_address:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.161</span><span class="hljs-number">.135</span><span class="hljs-attr">ip_version:</span> <span class="hljs-string">ipv4</span><span class="hljs-attr">public_network:</span> <span class="hljs-number">192.168</span><span class="hljs-number">.161</span><span class="hljs-number">.0</span><span class="hljs-string">/24</span><span class="hljs-attr">cluster_network:</span> <span class="hljs-string">&quot;<span class="hljs-template-variable">&#123;&#123; public_network | regex_replace(&#x27; &#x27;, &#x27;&#x27;) &#125;&#125;</span>&quot;</span><span class="hljs-attr">osd_mkfs_type:</span> <span class="hljs-string">xfs</span><span class="hljs-attr">osd_mkfs_options_xfs:</span> <span class="hljs-string">-f</span> <span class="hljs-string">-i</span> <span class="hljs-string">size=2048</span><span class="hljs-attr">osd_mount_options_xfs:</span> <span class="hljs-string">noatime,largeio,inode64,swalloc</span><span class="hljs-attr">osd_objectstore:</span> <span class="hljs-string">bluestore</span><span class="hljs-attr">dashboard_enabled:</span> <span class="hljs-literal">False</span></code></pre><p>devices：指定osd使用的硬盘</p><p>osd_scenario：collocated启用并置journal  【笔者没有找到】</p><p>下面是一些trick</p><pre><code class="hljs elixir"><span class="hljs-variable">$ </span>sudo fdisk -l <span class="hljs-comment">#查看磁盘信息</span></code></pre><p>查看你的更改</p><pre><code class="hljs vim">$<span class="hljs-keyword">grep</span> -v <span class="hljs-string">&#x27;^#&#x27;</span> <span class="hljs-keyword">all</span>.yml | <span class="hljs-keyword">grep</span> -v <span class="hljs-string">&#x27;^&amp;&#x27;</span> <span class="hljs-keyword">all</span>.yml</code></pre><p>或者查看所有修改后文件</p><pre><code class="hljs \">grep -Ev &quot;^$|^\s*#&quot;  *.yml</code></pre><ol><li><h3 id="配置osd"><a href="#配置osd" class="headerlink" title="配置osd"></a>配置osd</h3></li></ol><pre><code class="hljs arcade">devices:   - <span class="hljs-regexp">/dev/</span>vdb   - <span class="hljs-regexp">/dev/</span>vdc   - <span class="hljs-regexp">/dev/</span>vdd</code></pre><ol><li><h3 id="定义ansible的入口文件"><a href="#定义ansible的入口文件" class="headerlink" title="定义ansible的入口文件"></a>定义ansible的入口文件</h3></li></ol><pre><code class="hljs vala">- hosts:  - mons<span class="hljs-meta">#  - agents</span>  - osds<span class="hljs-meta">#  - mdss</span><span class="hljs-meta">#  - rgws</span><span class="hljs-meta">#  - nfss</span><span class="hljs-meta">#  - restapis</span><span class="hljs-meta">#  - rbdmirrors</span>  - clients  - mgrs<span class="hljs-meta">#  - iscsi-gws</span></code></pre><ol><li><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3></li></ol><pre><code class="hljs 1c">ansible-playbook  site.yml <span class="hljs-meta">#注意同样没有sudo</span></code></pre><pre><code class="hljs routeros">PLAY RECAP *********************************************************************node1                      : <span class="hljs-attribute">ok</span>=340  <span class="hljs-attribute">changed</span>=33   <span class="hljs-attribute">unreachable</span>=0    <span class="hljs-attribute">failed</span>=0    <span class="hljs-attribute">skipped</span>=547  <span class="hljs-attribute">rescued</span>=0    <span class="hljs-attribute">ignored</span>=0   node2                      : <span class="hljs-attribute">ok</span>=109  <span class="hljs-attribute">changed</span>=12   <span class="hljs-attribute">unreachable</span>=0    <span class="hljs-attribute">failed</span>=0    <span class="hljs-attribute">skipped</span>=261  <span class="hljs-attribute">rescued</span>=0    <span class="hljs-attribute">ignored</span>=0   node3                      : <span class="hljs-attribute">ok</span>=112  <span class="hljs-attribute">changed</span>=12   <span class="hljs-attribute">unreachable</span>=0    <span class="hljs-attribute">failed</span>=0    <span class="hljs-attribute">skipped</span>=260  <span class="hljs-attribute">rescued</span>=0    <span class="hljs-attribute">ignored</span>=0   INSTALLER STATUS ***************************************************************Install Ceph Monitor           : Complete (0:00:32)Install Ceph Manager           : Complete (0:00:09)Install Ceph OSD               : Complete (0:00:34)Install Ceph<span class="hljs-built_in"> Client </span>           : Complete (0:00:31)</code></pre><p>如果<code>failed=1</code>那就说明安装失败，你需要根据错误进行修改，如果打印的信息太少，你可以使用</p><pre><code class="hljs css"><span class="hljs-selector-tag">ansible-playbook</span> <span class="hljs-selector-tag">-vvv</span> <span class="hljs-selector-tag">site</span><span class="hljs-selector-class">.yml</span></code></pre><p>来打印更多信息。</p><ol><li><h3 id="测试"><a href="#测试" class="headerlink" title="测试"></a><strong>测试</strong></h3></li></ol><p>接下来我们看看集群健康状况 ，在ceph-mon节点执行</p><pre><code class="hljs ebnf"><span class="hljs-attribute">ceph -s</span></code></pre><p>有可能会提示ceph RADOS object not found. 笔者怀疑是 /etc/ceph/下的conf文件名不是ceph所以导致无法识别出集群，后来干脆把集群名字改成<code>ceph</code>。是不是很傻X呢？</p><pre><code class="hljs apache"><span class="hljs-attribute">cluster</span>:  <span class="hljs-attribute">id</span>:     <span class="hljs-number">0</span>d<span class="hljs-number">3</span>c<span class="hljs-number">793</span>b-<span class="hljs-number">1</span>ee<span class="hljs-number">0</span>-<span class="hljs-number">43</span>ca-<span class="hljs-number">8</span>f<span class="hljs-number">28</span>-<span class="hljs-number">6</span>dbf<span class="hljs-number">695578</span>cf  <span class="hljs-attribute">health</span>: HEALTH_OK <span class="hljs-attribute">services</span>:  <span class="hljs-attribute">mon</span>: <span class="hljs-number">1</span> daemons, quorum node<span class="hljs-number">2</span> (age <span class="hljs-number">5</span>m)  <span class="hljs-attribute">mgr</span>: node<span class="hljs-number">2</span>(active, since <span class="hljs-number">5</span>m)  <span class="hljs-attribute">mds</span>: cephfs:<span class="hljs-number">1</span> &#123;<span class="hljs-number">0</span>=node<span class="hljs-number">3</span>=up:active&#125; <span class="hljs-number">2</span> up:standby  <span class="hljs-attribute">osd</span>: <span class="hljs-number">3</span> osds: <span class="hljs-number">3</span> up (since <span class="hljs-number">3</span>m), <span class="hljs-number">3</span> in (since <span class="hljs-number">4</span>m) <span class="hljs-attribute">task</span> status:  <span class="hljs-attribute">scrub</span> status:      <span class="hljs-attribute">mds</span>.node<span class="hljs-number">3</span>: idle <span class="hljs-attribute">data</span>:  <span class="hljs-attribute">pools</span>:   <span class="hljs-number">3</span> pools, <span class="hljs-number">65</span> pgs  <span class="hljs-attribute">objects</span>: <span class="hljs-number">22</span> objects, <span class="hljs-number">2</span>.<span class="hljs-number">2</span> KiB  <span class="hljs-attribute">usage</span>:   <span class="hljs-number">3</span>.<span class="hljs-number">0</span> GiB used, <span class="hljs-number">57</span> GiB / <span class="hljs-number">60</span> GiB avail  <span class="hljs-attribute">pgs</span>:     <span class="hljs-number">65</span> active+clean</code></pre><p>以及<code>sudo fidsk -l</code> 查看osd分配磁盘。</p><p>查看osd 拓扑。这有助于我们理解CRUSH算法。</p><pre><code class="hljs dos">sudo ceph osd <span class="hljs-built_in">tree</span></code></pre><pre><code class="hljs lsl">ID  CLASS  WEIGHT   TYPE NAME       STATUS  REWEIGHT  PRI-AFF<span class="hljs-number">-1</span>         <span class="hljs-number">0.05846</span>  root <span class="hljs-section">default</span>                             <span class="hljs-number">-5</span>         <span class="hljs-number">0.01949</span>      host node3                            <span class="hljs-number">1</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.1</span>       up   <span class="hljs-number">1.00000</span>  <span class="hljs-number">1.00000</span><span class="hljs-number">-3</span>         <span class="hljs-number">0.01949</span>      host node4                            <span class="hljs-number">0</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.0</span>       up   <span class="hljs-number">1.00000</span>  <span class="hljs-number">1.00000</span><span class="hljs-number">-7</span>         <span class="hljs-number">0.01949</span>      host node5                            <span class="hljs-number">2</span>    ssd  <span class="hljs-number">0.01949</span>          osd<span class="hljs-number">.2</span>       up   <span class="hljs-number">1.00000</span>  <span class="hljs-number">1.00000</span></code></pre><p>EOF</p><hr><p>优质博文参考：<a href="https://blog.51cto.com/14210294/2353243">https://blog.51cto.com/14210294/2353243</a></p><p><a href="https://www.cnblogs.com/zyxnhr/p/10543814.html">https://www.cnblogs.com/zyxnhr/p/10543814.html</a></p><hr><h2 id="Trouble-Shooting"><a href="#Trouble-Shooting" class="headerlink" title="Trouble Shooting"></a>Trouble Shooting</h2><ol><li>Devices are not disjoint</li></ol><p>设备存在交集。如果存储方式是bluestore, 那么block，wal和db必须是不同的存储盘。并且：</p><pre><code class="hljs angelscript">$ mount | grep osdtmpfs on /var/lib/ceph/osd/ceph<span class="hljs-number">-0</span> type tmpfs (rw,relatime,seclabel)$ ls -Alh /var/lib/ceph/osd/ceph<span class="hljs-number">-0</span>lrwxrwxrwx. <span class="hljs-number">1</span> ceph ceph <span class="hljs-number">19</span> Apr  <span class="hljs-number">7</span> <span class="hljs-number">21</span>:<span class="hljs-number">36</span> block -&gt; /dev/ceph-pool/osd0lrwxrwxrwx. <span class="hljs-number">1</span> root root <span class="hljs-number">22</span> Apr  <span class="hljs-number">7</span> <span class="hljs-number">21</span>:<span class="hljs-number">36</span> block.db -&gt; /dev/ceph-pool/osd0.dblrwxrwxrwx. <span class="hljs-number">1</span> root root <span class="hljs-number">23</span> Apr  <span class="hljs-number">7</span> <span class="hljs-number">21</span>:<span class="hljs-number">36</span> block.wal -&gt; /dev/ceph-pool/osd0.wal-rw-------. <span class="hljs-number">1</span> ceph ceph <span class="hljs-number">37</span> Apr  <span class="hljs-number">7</span> <span class="hljs-number">21</span>:<span class="hljs-number">36</span> ceph_fsid-rw-------. <span class="hljs-number">1</span> ceph ceph <span class="hljs-number">37</span> Apr  <span class="hljs-number">7</span> <span class="hljs-number">21</span>:<span class="hljs-number">36</span> fsid-rw-------. <span class="hljs-number">1</span> ceph ceph <span class="hljs-number">55</span> Apr  <span class="hljs-number">7</span> <span class="hljs-number">21</span>:<span class="hljs-number">36</span> keyring-rw-------. <span class="hljs-number">1</span> ceph ceph  <span class="hljs-number">6</span> Apr  <span class="hljs-number">7</span> <span class="hljs-number">21</span>:<span class="hljs-number">36</span> ready-rw-------. <span class="hljs-number">1</span> ceph ceph <span class="hljs-number">10</span> Apr  <span class="hljs-number">7</span> <span class="hljs-number">21</span>:<span class="hljs-number">36</span> type-rw-------. <span class="hljs-number">1</span> ceph ceph  <span class="hljs-number">2</span> Apr  <span class="hljs-number">7</span> <span class="hljs-number">21</span>:<span class="hljs-number">36</span> whoami</code></pre>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Ceph-ansible部署踩坑日记&quot;&gt;&lt;a href=&quot;#Ceph-ansible部署踩坑日记&quot; class=&quot;headerlink&quot; title=&quot;Ceph-ansible部署踩坑日记&quot;&gt;&lt;/a&gt;Ceph-ansible部署踩坑日记&lt;/h1&gt;&lt;blockquo</summary>
      
    
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/categories/ceph/"/>
    
    <category term="分布式存储" scheme="http://durantthorvalds.top/categories/ceph/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/"/>
    
    
    <category term="系统架构" scheme="http://durantthorvalds.top/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
    <category term="ceph" scheme="http://durantthorvalds.top/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title>「基础理论」CEPH 基础介绍</title>
    <link href="http://durantthorvalds.top/2020/11/22/CEPH%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA/"/>
    <id>http://durantthorvalds.top/2020/11/22/CEPH%E5%9F%BA%E7%A1%80%E7%90%86%E8%AE%BA/</id>
    <published>2020-11-21T16:00:00.000Z</published>
    <updated>2020-12-16T08:34:33.010Z</updated>
    
    <content type="html"><![CDATA[<h1 id="CEPH基础理论学习"><a href="#CEPH基础理论学习" class="headerlink" title="CEPH基础理论学习"></a>CEPH基础理论学习</h1><hr><h1 id="第一部分"><a href="#第一部分" class="headerlink" title="第一部分"></a>第一部分</h1><h2 id="1-Ceph简介"><a href="#1-Ceph简介" class="headerlink" title="1 Ceph简介"></a><strong>1 Ceph简介</strong></h2><blockquote><p>Ceph是一个统一的分布式存储系统，设计初衷是提供较好的性能、可靠性和可扩展性。它是一个统一的存储系统，既支持传统的块、文件存储协议，例如SAN和NAS，也支持新兴的对象存储协议，如S3和Swift，这使得Ceph理论上可以满足时下一切主流的存储应用的要求。</p></blockquote><p>Ceph项目最早起源于Sage就读博士期间的工作（最早的成果于2004年发表），并随后贡献给开源社区。在经过了数年的发展之后，目前已得到众多云计算厂商的支持并被广泛应用。RedHat及OpenStack都可与Ceph整合以支持虚拟机镜像的后端存储。</p><ul><li>Ceph摒弃了传统的集中式存储元数据的方案，采用CRUSH算法，数据分布均衡，并行度高。</li><li>考虑了容灾区的隔离，能够实现各类负载的副本放置规则，例如跨机房，机架感知。</li><li>能够支持上千个存储节点的规模，支持TB到PB级的数据。</li></ul><p><strong>高可用性</strong></p><ul><li>a. 副本数可以灵活控制。</li><li>b. 支持故障域分隔，数据强一致性。</li><li>c. 多种故障场景自动进行修复自愈。</li><li>d. 没有单点故障，自动管理。</li></ul><p><strong>高可扩展性</strong></p><ul><li>a. 去中心化。</li><li>b. 扩展灵活。</li><li>c. 随着节点增加而线性增长。</li></ul><p><strong>特性丰富</strong></p><p>a. 支持三种存储接口：块存储、文件存储、对象存储。</p><p>b. 支持自定义接口，支持多种语言驱动。</p><p>特点：</p><ul><li><p>高性能</p></li><li><p>高可用性</p></li><li><p>高可扩展性</p></li><li><p>特性丰富</p></li></ul><p><strong>支持三种接口</strong>：</p><ul><li>Object：有原生的API，而且也兼容Swift和S3的API。</li><li>Block：支持精简配置、快照、克隆。</li><li>File：Posix接口，支持快照。</li></ul><p><img src="\img\ceph-st1.jpg" alt="640?wx_fmt=png"></p><ul><li><p>Monitor</p><p><code>ceph-mon</code>，一个Ceph集群需要多个Monitor组成的小集群，它们通过Paxos同步数据，用来保存OSD的元数据。<a href="http://docs.ceph.org.cn/glossary/#term-ceph-monitor"><em>Ceph Monitor</em></a>维护着展示集群状态的各种图表，包括监视器图、 OSD 图、归置组（ PG ）图、和 CRUSH 图。 Ceph 保存着发生在Monitors 、 OSD 和 PG上的每一次状态变更的历史信息（称为 epoch ）。通常至少需要三个监视器才能实现冗余和高可用性。</p></li><li><p>Manager</p><p><a href="https://docs.ceph.com/en/latest/glossary/#term-Ceph-Manager">Ceph Manager</a>守护进程（<code>ceph-mgr</code>）负责跟踪运行时指标和Ceph集群的当前状态，包括存储利用率，当前性能指标和系统负载。Ceph Manager守护进程还托管基于python的模块，以管理和公开Ceph集群信息，包括基于Web的<a href="https://docs.ceph.com/en/latest/mgr/dashboard/#mgr-dashboard">Ceph仪表板</a>和 <a href="https://docs.ceph.com/en/latest/mgr/restful">REST API</a>。通常，至少需要两个管理器才能实现高可用性。</p></li><li><p>OSD</p><p>OSD全称Object Storage Daemon（<code>ceph-osd</code>），也就是负责响应客户端请求返回具体数据的进程。一个Ceph集群一般都有很多个OSD。<a href="http://docs.ceph.org.cn/glossary/#term-56"><em>Ceph OSD 守护进程</em></a>（ Ceph OSD ）的功能是存储数据，处理数据的复制、恢复、回填、再均衡，并通过检查其他OSD 守护进程的心跳来向 Ceph Monitors 提供一些监控信息。当 Ceph 存储集群设定为有2个副本时，至少需要2个 OSD 守护进程，集群才能达到 <code>active+clean</code> 状态（ Ceph 默认有3个副本，但你可以调整副本数）</p></li></ul><ul><li><p>MDS</p><p>MDS全称Ceph Metadata Server（<code>ceph-mds</code>），是CephFS服务依赖的元数据服务。<a href="http://docs.ceph.org.cn/glossary/#term-63"><em>Ceph 元数据服务器</em></a>（ MDS ）为 <a href="http://docs.ceph.org.cn/glossary/#term-45"><em>Ceph 文件系统</em></a>存储元数据（也就是说，Ceph 块设备和 Ceph 对象存储不使用MDS ）。元数据服务器使得 POSIX 文件系统的用户们，可以在不对 Ceph 存储集群造成负担的前提下，执行诸如 <code>ls</code>、<code>find</code> 等基本命令。</p></li></ul><ul><li><p>Object</p><p>Ceph最底层的存储单元是Object对象，每个Object包含元数据和原始数据。</p></li></ul><ul><li><p>PG</p><p>PG全称Placement Groups归置组，是一个逻辑的概念，一个PG包含多个OSD。引入PG这一层其实是为了更好的分配数据和定位数据。</p></li></ul><ul><li><p>RADOS</p><p>RADOS全称Reliable Autonomic Distributed Object Store （可靠自治的分布式对象存储），是Ceph集群的<strong>精华</strong>，用户实现数据分配、Failover等集群操作。具有自愈，自管理能力的智能存储节点构建的高可靠，自治，分布式对象存储系统。</p></li></ul><ul><li><p>Libradio</p><p>Librados是Rados提供库，因为RADOS是协议很难直接访问，因此上层的RBD、RGW和CephFS都是通过librados访问的，目前提供PHP、Ruby、Java、Python、C和C++支持。</p></li></ul><ul><li><p>CRUSH<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="  Weil S A Brandt S A , Miller E L , et al. CRUSH: Controlled, Scalable, Decentralized Placement of Replicated Data[C]// IEEE Sc Conference. ACM, 2006.">[1]</span></a></sup></p><p>CRUSH是Ceph使用的数据分布算法，类似一致性哈希，让数据分配到预期的地方。</p></li></ul><ul><li><p>RBD</p><p>RBD全称RADOS block device，是Ceph对外提供的块设备服务。采用全分布式，可靠的块设备访问接口，同时提供Linux内核态和用户态客户端访问支持，以及QEMU/KVM驱动。</p></li></ul><ul><li><p>RGW</p><p>RGW全称RADOS gateway，基于Bucket的REST网关，是Ceph对外提供的对象存储服务，接口与S3和Swift兼容。</p></li></ul><ul><li><p>CephFS</p><p>CephFS全称Ceph File System，是Ceph对外提供的文件系统服务。与POSIX兼容，同时提供Linux内核态用户端和FUSE访问支持。</p></li></ul><blockquote><p>基于 RADOS 的 Ceph 对象存储集群包括两类守护进程：term:对象存储守护进程（ OSD ）把存储节点上的数据存储为对象； term:Ceph 监视器（ MON ）维护集群运行图的主拷贝。一个 Ceph 集群可以包含数千个存储节点，最简系统至少需要一个监视器和两个 OSD 才能做到数据复制。</p></blockquote><h3 id="ceph读写流程"><a href="#ceph读写流程" class="headerlink" title="ceph读写流程"></a>ceph读写流程</h3><p>Read：</p><ul><li>Client app 发送读请求，RADOS将请求发送给Primary OSD。</li><li>主要OSD在本地磁盘读数据并完成读请求。</li></ul><p>Write:</p><ul><li><p>Client App 写数据，RADOS将数据发送给Primary OSD。</p></li><li><p>Primary OSD识别Replica OSDs并且向他们发送数据，由他们写数据到本地磁盘。</p></li><li>Replica OSDs 完成写并通知Primary OSD。</li><li>Primary OSDs 通知client APP 写完成。</li><li><img src="\img\ceph-b.png" alt="image-20201122180847737"></li></ul><h3 id="三种存储方式"><a href="#三种存储方式" class="headerlink" title="三种存储方式"></a>三种存储方式</h3><h4 id="1-块设备"><a href="#1-块设备" class="headerlink" title="1. 块设备"></a>1. 块设备</h4><p><strong>典型设备：</strong> 磁盘阵列，硬盘</p><p>主要是将裸磁盘空间映射给主机使用的。</p><p><strong>优点：</strong></p><ul><li>通过RAID与LVM（逻辑卷管理）等手段，对数据提供了保护。</li><li>多块廉价的硬盘组合起来，提高容量。</li><li>多块磁盘组合出来的逻辑盘，提升读写效率。</li></ul><p><strong>缺点：</strong></p><ul><li>采用SAN架构组网时，光纤交换机，造价成本高。</li><li>主机之间无法共享数据。</li></ul><p><strong>使用场景：</strong></p><ul><li>docker容器、虚拟机磁盘存储分配。</li><li>日志存储。</li><li>文件存储。</li><li>…</li></ul><h4 id="2-文件存储"><a href="#2-文件存储" class="headerlink" title="2.文件存储"></a>2.文件存储</h4><p><strong>典型设备：</strong> FTP、NFS服务器<br> 为了克服块存储文件无法共享的问题，所以有了文件存储。<br> 在服务器上架设FTP与NFS服务，就是文件存储。</p><p><strong>优点：</strong></p><ul><li>造价低，随便一台机器就可以了。</li><li>方便文件共享。</li></ul><p><strong>缺点：</strong></p><ul><li>读写速率低。</li><li>传输速率慢。</li></ul><p><strong>使用场景：</strong></p><ul><li>日志存储。</li><li>有目录结构的文件存储。</li><li>…</li></ul><h4 id="3-对象存储"><a href="#3-对象存储" class="headerlink" title="3.对象存储"></a>3.对象存储</h4><p><img src="\img\ceph-c.jpg" alt="img"></p><p><strong>典型设备：</strong> 内置大容量硬盘的分布式服务器(swift, s3)<br> 多台服务器内置大容量硬盘，安装上对象存储管理软件，对外提供读写访问功能。</p><p><strong>优点：</strong></p><ul><li>具备块存储的读写高速。</li><li>具备文件存储的共享等特性。</li></ul><p><strong>使用场景：</strong> (适合更新变动较少的数据)</p><ul><li>图片存储。</li><li>视频存储。</li><li>…</li></ul><h3 id=""><a href="#" class="headerlink" title=" "></a> </h3><hr><h2 id="2-Ceph-I-O流程和数据分布"><a href="#2-Ceph-I-O流程和数据分布" class="headerlink" title="2 Ceph I/O流程和数据分布"></a>2 Ceph I/O流程和数据分布</h2><p><img src="\img\ceph-d.png" alt="img"></p><p><img src="\img\ceph_io2.png" alt="img"></p><p><strong>步骤：</strong></p><ol><li>client 创建cluster handler。</li><li>client 读取配置文件。</li><li>client 连接上monitor，获取集群map信息。</li><li>client 读写io 根据crushmap 算法请求对应的主osd数据节点。</li><li>主osd数据节点同时写入另外两个副本节点数据。</li><li>等待主节点以及另外两个副本节点写完数据状态。</li><li>主节点及副本节点写入状态都成功后，返回给client，io写入完成。</li></ol><h3 id="新主I-O流程图"><a href="#新主I-O流程图" class="headerlink" title="新主I/O流程图"></a>新主I/O流程图</h3><p><img src="\img\ceph-e.jpg" alt="img"></p><p><strong>步骤：</strong></p><ol><li>client连接monitor获取集群map信息。</li><li>同时新主osd1由于没有pg数据会主动上报monitor告知让osd2临时接替为主。</li><li>临时主osd2会把数据全量同步给新主osd1。</li><li>client IO读写直接连接临时主osd2进行读写。</li><li>osd2收到读写io，同时写入另外两副本节点。</li><li>等待osd2以及另外两副本写入成功。</li><li>osd2三份数据都写入成功返回给client, 此时client io读写完毕。</li><li>如果osd1数据同步完毕，临时主osd2会交出主角色。</li><li>osd1成为主节点，osd2变成副本。</li></ol><h3 id="Ceph-I-O算法流程"><a href="#Ceph-I-O算法流程" class="headerlink" title="Ceph I/O算法流程"></a>Ceph I/O算法流程</h3><p><img src="\img\ceph-arch.png" alt="img"></p><ol><li>File用户需要读写的文件。File-&gt;Object映射：</li></ol><ul><li>a. ino (File的元数据，File的唯一id)。</li><li>b. ono(File切分产生的某个object的序号，默认以4M切分一个块大小)。</li><li>c. oid(object id: ino + ono)。</li></ul><ol><li>Object是RADOS需要的对象。Ceph指定一个静态hash函数计算oid的值，将oid映射成一个近似均匀分布的伪随机值，然后和mask按位相与，得到pgid。Object-&gt;PG映射：</li></ol><ul><li>a. hash(oid) &amp; mask-&gt; pgid 。</li><li>b. mask = PG总数m(m为2的整数幂)-1 。</li></ul><ol><li>PG(Placement Group),用途是对object的存储进行组织和位置映射, (类似于redis cluster里面的slot的概念) 一个PG里面会有很多object。采用CRUSH算法，将pgid代入其中，然后得到一组OSD。PG-&gt;OSD映射：</li></ol><ul><li>a. CRUSH(pgid)-&gt;(osd1,osd2,osd3) 。</li></ul><pre><code class="hljs ini"><span class="hljs-attr">locator</span> = object_name<span class="hljs-attr">obj_hash</span> =  hash(locator)<span class="hljs-attr">pg</span> = obj_hash % num_pg<span class="hljs-attr">osds_for_pg</span> = crush(pg)  <span class="hljs-comment"># returns a list of osds</span><span class="hljs-attr">primary</span> = osds_for_pg[<span class="hljs-number">0</span>]<span class="hljs-attr">replicas</span> = osds_for_pg[<span class="hljs-number">1</span>:]</code></pre><h3 id="Ceph-RBD-IO流程"><a href="#Ceph-RBD-IO流程" class="headerlink" title="Ceph RBD IO流程"></a>Ceph RBD IO流程</h3><p><img src="/img/ceph-f.png" alt="img"></p><ol><li><p>客户端创建一个pool，需要为这个pool指定pg的数量。</p></li><li><p>创建pool/image rbd设备进行挂载。</p></li><li><p>用户写入的数据进行切块，每个块的大小默认为4M，并且每个块都有一个名字，名字就是object+序号。</p></li><li><p>将每个object通过pg进行副本位置的分配。</p></li><li><p>pg根据cursh算法会寻找3个osd，把这个object分别保存在这三个osd上。</p></li><li><p>osd上实际是把底层的disk进行了格式化操作，一般部署工具会将它格式化为xfs文件系统。</p></li><li><p>object的存储就变成了存储一个文rbd0.object1.file。</p></li></ol><p><img src="/img/ceph-g.png" alt="img"></p><p><strong>客户端写数据osd过程：</strong></p><ol><li>采用的是librbd的形式，使用librbd创建一个块设备，向这个块设备中写入数据。</li><li>在客户端本地同过调用librados接口，然后经过pool，rbd，object、pg进行层层映射,在PG这一层中，可以知道数据保存在哪3个OSD上，这3个OSD分为主从的关系。</li><li>客户端与primay OSD建立SOCKET 通信，将要写入的数据传给primary OSD，由primary OSD再将数据发送给其他replica OSD数据节点。</li></ol><h3 id="Ceph-Pool和PG分布情况"><a href="#Ceph-Pool和PG分布情况" class="headerlink" title="Ceph Pool和PG分布情况"></a>Ceph Pool和PG分布情况</h3><p><img src="/img/ceph-h.jpg" alt="img"></p><ul><li><p>pool是ceph存储数据时的逻辑分区，它起到namespace的作用。</p></li><li><p>每个pool包含一定数量(可配置)的PG。</p></li><li><p>PG里的对象被映射到不同的Object上。</p></li><li><p>pool是分布到整个集群的。</p></li><li><p>pool可以做故障隔离域，根据不同的用户场景不一进行隔离。</p></li></ul><h3 id="Ceph-数据扩容PG分布"><a href="#Ceph-数据扩容PG分布" class="headerlink" title="Ceph 数据扩容PG分布"></a>Ceph 数据扩容PG分布</h3><p><strong>场景数据迁移流程：</strong></p><ul><li>现状3个OSD, 4个PG</li><li>扩容到4个OSD, 4个PG</li></ul><p><strong>扩容前</strong></p><p><img src="/img/ceph-i.jpg" alt="img"></p><p><strong>扩容后</strong></p><p><img src="/img/ceph-j.png" alt="img"></p><p><strong>说明</strong><br>每个OSD上分布很多PG, 并且每个PG会自动散落在不同的OSD上。如果扩容那么相应的PG会进行迁移到新的OSD上，保证PG数量的均衡。</p><h3 id="PG状态及其含义"><a href="#PG状态及其含义" class="headerlink" title="PG状态及其含义"></a>PG状态及其含义</h3><div class="table-container"><table><thead><tr><th style="text-align:center">PG状态</th><th style="text-align:left">含义</th></tr></thead><tbody><tr><td style="text-align:center">down</td><td style="text-align:left">Peering过程中，PG检测到某个Interval中，当前剩余的OSD不足以完成数据修复</td></tr><tr><td style="text-align:center">repair</td><td style="text-align:left">PG正在被检查，被发现的任何不一致都将尽可能的被修复</td></tr><tr><td style="text-align:center">peering（等待互联）</td><td style="text-align:left">PG处于 peering 过程中, peering 由主 osd 发起的使存放 PG 副本的所有 OSD 就 PG 的所有对象和元素数据的状态达成一致的过程, peering 过程完成后, 主 OSD 就可以接受客户端写请求.</td></tr><tr><td style="text-align:center">active</td><td style="text-align:left">当 ceph 完成 peering 过程, pg 将会变成 active, active 状态意味着 pg 中的数据变得可用, 主 pg 将可执行读写操作 .</td></tr><tr><td style="text-align:center">clean</td><td style="text-align:left">干净态。前不存在待修复的对象， Acting Set和Up Set内容一致，并且大小等于存储池的副本数</td></tr><tr><td style="text-align:center">replay（重做）</td><td style="text-align:left">某OSD崩溃后，PG正在等待客户端重新发起操作</td></tr><tr><td style="text-align:center">degraded</td><td style="text-align:left">1.PG 处于 active+degraded 原因是因为 OSD 是处于活跃, 但并没有完成所有的对象副本写入, PG 中部分对象的副本数量未达到规定的数量.当 OSD 重新上线, OSD 将会重新恢复,  假如 OSD DOWN 并且 degraded 状态持续, CEPH 会标记 DOWN OSD, 并会对集群迁移相关 OSD 的数据, 对应时间由<code>mon osd down out interval</code> 参数决定 .</td></tr><tr><td style="text-align:center">inconsistent</td><td style="text-align:left">PG通过Scrub检测到某些对象在PG实例间出现不一致（主要是因为静默错误）</td></tr><tr><td style="text-align:center">recovering</td><td style="text-align:left">PG正在对不一致对象进行同步/修复。</td></tr><tr><td style="text-align:center">back filling</td><td style="text-align:left">当新 OSD 加入集群, CRUSH 将会为集群新添加的 OSD 重新分配 PG, 强制新的 OSD 接受重新分配的 PG 并把一定数量的负载转移到新 OSD 中,back filling OSD 会在后台处理, 当 backfilling 完成, 新的 OSD 完成后, 将开始对请求进行服务</td></tr><tr><td style="text-align:center">remapped</td><td style="text-align:left">当 pg 改变, 数据从旧的 osd 迁移到新的 osd, 新的主 osd 应该请求将会花费一段时间, 在这段时间内, 将会继续向旧主 osd 请求服务, 直到 PG 迁移完成, 当数据迁移完成, mapping 将会使用新的 OSD 响应主 OSD 服务</td></tr><tr><td style="text-align:center">stale（旧）</td><td style="text-align:left">当 ceph 使用 heartbeat 确认主机与进程是否运行, ceph osd daemon 可能由于网络临时故障, 获得一个卡住状态 (stuck state) 没有得到心跳回应 默认, osd daemon 会每 0.5 秒报告 PG, up 状态, 启动与故障分析, 假如 PG 中主 OSD 因为故障没有回应 monitor 或者其他 OSD 报告 主 osd down, 那么 monitor 将会标记 PG stale</td></tr><tr><td style="text-align:center">scrubbing</td><td style="text-align:left">scrubbing（清理中）, PG 在做一致性校验</td></tr><tr><td style="text-align:center">inactive</td><td style="text-align:left">inactive ：PG 很长时间没有显示为 active 状态, (不可执行读写请求), PG 不可以执行读写, 因为等待 OSD 更新数据到最新的备份状态</td></tr><tr><td style="text-align:center">unclean</td><td style="text-align:left">unclean：PG 很长时间都不是 clean 状态 (不可以完成之前恢复的操作), PG 包含对象没有完成相应的复制副本数量, 通常都要执行恢复操作。</td></tr><tr><td style="text-align:center">stale（新）</td><td style="text-align:left">stale：PG 状态很长时间没有被 ceph-osd 更新过, 标识存储在该 GP 中的节点显示为 DOWN, PG 处于 unknown 状态, 因为 OSD 没有报告 monitor 由 mon osd report timeout 定义超时时间</td></tr></tbody></table></div><hr><h2 id="3-Ceph心跳机制"><a href="#3-Ceph心跳机制" class="headerlink" title="3 Ceph心跳机制"></a>3 Ceph心跳机制</h2><p>心跳是用于节点间检测对方是否故障的，以便及时发现故障节点进入相应的故障处理流程。</p><p><strong>问题：</strong></p><ul><li>故障检测时间和心跳报文带来的负载之间做权衡。</li><li>心跳频率太高则过多的心跳报文会影响系统性能。</li><li>心跳频率过低则会延长发现故障节点的时间，从而影响系统的可用性。</li></ul><p><strong>故障检测策略应该能够做到：</strong></p><ul><li><strong>及时</strong>：节点发生异常如宕机或网络中断时，集群可以在可接受的时间范围内感知。</li><li><strong>适当的压力</strong>：包括对节点的压力，和对网络的压力。</li><li><strong>容忍网络抖动</strong>：网络偶尔延迟。</li><li><strong>扩散机制</strong>：节点存活状态改变导致的元信息变化需要通过某种机制扩展到整个集群。</li></ul><h3 id="心跳检测"><a href="#心跳检测" class="headerlink" title="心跳检测"></a>心跳检测</h3><p><img src="\img\ceph-webp.png" alt="img"></p><p><strong>OSD节点会监听public、cluster、front和back四个端口</strong></p><ul><li><strong>public端口</strong>：监听来自Monitor和Client的连接。</li><li><strong>cluster端口</strong>：监听来自OSD Peer的连接。</li><li><strong>front端口</strong>：供客户端连接集群使用的网卡, 这里临时给集群内部之间进行心跳。</li><li><strong>back端口</strong>：供客集群内部使用的网卡。集群内部之间进行心跳。</li><li><strong>hbclient</strong>：发送ping心跳的messenger。</li></ul><h3 id="Ceph-OSD之间相互心跳检测"><a href="#Ceph-OSD之间相互心跳检测" class="headerlink" title="Ceph OSD之间相互心跳检测"></a>Ceph OSD之间相互心跳检测</h3><p><img src="/img/ceph-k.jpg" alt="img"></p><ul><li>同一个PG内OSD互相心跳，他们互相发送PING/PONG信息。</li><li>每隔6s检测一次(实际会在这个基础上加一个随机时间来避免峰值)。</li><li>20s没有检测到心跳回复，加入failure队列。</li></ul><h3 id="Ceph-OSD与Mon心跳检测"><a href="#Ceph-OSD与Mon心跳检测" class="headerlink" title="Ceph OSD与Mon心跳检测"></a>Ceph OSD与Mon心跳检测</h3><p><img src="/img/ceph-l.jpg" alt="img"></p><p><strong>OSD报告给Monitor：</strong></p><ul><li>OSD有事件发生时（比如故障、PG变更）。</li><li>自身启动5秒内。</li><li>OSD周期性的上报给Monito<ul><li>OSD检查failure_queue中的伙伴OSD失败信息。</li><li>向Monitor发送失效报告，并将失败信息加入failure_pending队列，然后将其从failure_queue移除。</li><li>收到来自failure_queue或者failure_pending中的OSD的心跳时，将其从两个队列中移除，并告知Monitor取消之前的失效报告。</li><li>当发生与Monitor网络重连时，会将failure_pending中的错误报告加回到failure_queue中，并再次发送给Monitor。</li></ul></li></ul><p>Monitor统计下线OSD</p><ul><li>Monitor收集来自OSD的伙伴失效报告。</li><li>当错误报告指向的OSD失效超过一定阈值，且有足够多的OSD报告其失效时，将该OSD下线。</li></ul><h3 id="Ceph心跳检测总结"><a href="#Ceph心跳检测总结" class="headerlink" title="Ceph心跳检测总结"></a>Ceph心跳检测总结</h3><p>Ceph通过伙伴OSD汇报失效节点和Monitor统计来自OSD的心跳两种方式判定OSD节点失效。</p><ul><li><strong>及时</strong>：伙伴OSD可以在秒级发现节点失效并汇报Monitor，并在几分钟内由Monitor将失效OSD下线。</li><li><strong>适当的压力</strong>：由于有伙伴OSD汇报机制，Monitor与OSD之间的心跳统计更像是一种保险措施，因此OSD向Monitor发送心跳的间隔可以长达600秒，Monitor的检测阈值也可以长达900秒。Ceph实际上是将故障检测过程中中心节点的压力分散到所有的OSD上，以此提高中心节点Monitor的可靠性，进而提高整个集群的可扩展性。</li><li><strong>容忍网络抖动</strong>：Monitor收到OSD对其伙伴OSD的汇报后，并没有马上将目标OSD下线，而是周期性的等待几个条件：<ul><li>目标OSD的失效时间大于通过固定量osd_heartbeat_grace和历史网络条件动态确定的阈值。</li><li>来自不同主机的汇报达到mon_osd_min_down_reporters。</li><li>满足前两个条件前失效汇报没有被源OSD取消。</li></ul></li><li><strong>扩散</strong>：作为中心节点的Monitor并没有在更新OSDMap后尝试广播通知所有的OSD和Client，而是惰性的等待OSD和Client来获取。以此来减少Monitor压力并简化交互逻辑。</li></ul><h2 id="4-Ceph通信框架"><a href="#4-Ceph通信框架" class="headerlink" title="4 Ceph通信框架"></a>4 Ceph通信框架</h2><p><strong>Simple线程模式</strong></p><ul><li><strong>特点</strong>：每一个网络链接，都会创建两个线程，一个用于接收，一个用于发送。</li><li><strong>缺点</strong>：大量的链接会产生大量的线程，会消耗CPU资源，影响性能。</li></ul><p><strong>Async事件的I/O多路复用模式</strong></p><ul><li><strong>特点</strong>：这种是目前网络通信中广泛采用的方式。k版默认已经使用Asnyc了。</li></ul><p><strong>XIO方式使用了开源的网络通信库accelio来实现</strong></p><ul><li><strong>特点</strong>：这种方式需要依赖第三方的库accelio稳定性，目前处于试验阶段。</li></ul><h3 id="Ceph通信框架设计模式"><a href="#Ceph通信框架设计模式" class="headerlink" title="Ceph通信框架设计模式"></a>Ceph通信框架设计模式</h3><p><strong>设计模式(Subscribe/Publish)</strong></p><p>订阅发布模式又名观察者模式，它意图是“定义对象间的一种一对多的依赖关系，<br> 当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新”。</p><p><img src="/img/ceph-m.jpg" alt="img"></p><p>Accepter监听peer的请求, 调用 SimpleMessenger::add_accept_pipe() 创建新的 Pipe 到 SimpleMessenger::pipes 来处理该请求。</p><p>Pipe用于消息的读取和发送。该类主要有两个组件，Pipe::Reader，Pipe::Writer用来处理消息读取和发送。</p><p>Messenger作为消息的发布者, 各个 Dispatcher 子类作为消息的订阅者, Messenger 收到消息之后，  通过 Pipe 读取消息，然后转给 Dispatcher 处理。</p><p>Dispatcher调度员是订阅者的基类，具体的订阅后端继承该类,初始化的时候通过 Messenger::add_dispatcher_tail/head 注册到 Messenger::dispatchers. 收到消息后，通知该类处理。</p><p>DispatchQueue该类用来缓存收到的消息, 然后唤醒 DispatchQueue::dispatch_thread 线程找到后端的 Dispatch 处理消息。</p><p><img src="/img/ceph-u.png" alt=""></p><h3 id="通信类框架图"><a href="#通信类框架图" class="headerlink" title="通信类框架图"></a>通信类框架图</h3><p><img src="/img/ceph-n.jpg" alt="img"></p><h3 id="通信数据格式"><a href="#通信数据格式" class="headerlink" title="通信数据格式"></a>通信数据格式</h3><p>通信协议格式需要双方约定数据格式。</p><p><strong>消息的内容主要分为三部分：</strong></p><ul><li>header //消息头类型消息的信封</li><li>user data //需要发送的实际数据<ul><li>payload     //操作保存元数据</li><li>middle      //预留字段</li><li>data       //读写数据</li></ul></li><li>footer       //消息的结束标记</li></ul><pre><code class="hljs cpp"><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Message</span> :</span> <span class="hljs-keyword">public</span> RefCountedObject &#123;<span class="hljs-keyword">protected</span>:  ceph_msg_header  header;      <span class="hljs-comment">// 消息头</span>  ceph_msg_footer  footer;      <span class="hljs-comment">// 消息尾</span>  bufferlist       payload;  <span class="hljs-comment">// &quot;front&quot; unaligned blob</span>  bufferlist       middle;   <span class="hljs-comment">// &quot;middle&quot; unaligned blob</span>  bufferlist       data;     <span class="hljs-comment">// data payload (page-alignment will be preserved where possible)</span>  <span class="hljs-comment">/* recv_stamp is set when the Messenger starts reading the</span><span class="hljs-comment">   * Message off the wire */</span>  <span class="hljs-keyword">utime_t</span> recv_stamp;       <span class="hljs-comment">//开始接收数据的时间戳</span>  <span class="hljs-comment">/* dispatch_stamp is set when the Messenger starts calling dispatch() on</span><span class="hljs-comment">   * its endpoints */</span>  <span class="hljs-keyword">utime_t</span> dispatch_stamp;   <span class="hljs-comment">//dispatch 的时间戳</span>  <span class="hljs-comment">/* throttle_stamp is the point at which we got throttle */</span>  <span class="hljs-keyword">utime_t</span> throttle_stamp;   <span class="hljs-comment">//获取throttle 的slot的时间戳</span>  <span class="hljs-comment">/* time at which message was fully read */</span>  <span class="hljs-keyword">utime_t</span> recv_complete_stamp;  <span class="hljs-comment">//接收完成的时间戳</span>  ConnectionRef connection;     <span class="hljs-comment">//网络连接</span>  <span class="hljs-keyword">uint32_t</span> magic = <span class="hljs-number">0</span>;           <span class="hljs-comment">//消息的魔术字</span>  bi::list_member_hook&lt;&gt; dispatch_q;    <span class="hljs-comment">//boost::intrusive 成员字段</span>&#125;;<span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">ceph_msg_header</span> &#123;</span>    __le64 seq;       <span class="hljs-comment">// 当前session内 消息的唯一 序号</span>    __le64 tid;       <span class="hljs-comment">// 消息的全局唯一的 id</span>    __le16 type;      <span class="hljs-comment">// 消息类型</span>    __le16 priority;  <span class="hljs-comment">// 优先级</span>    __le16 version;   <span class="hljs-comment">// 版本号</span>    __le32 front_len; <span class="hljs-comment">// payload 的长度</span>    __le32 middle_len;<span class="hljs-comment">// middle 的长度</span>    __le32 data_len;  <span class="hljs-comment">// data 的 长度</span>    __le16 data_off;  <span class="hljs-comment">// 对象的数据偏移量</span>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">ceph_entity_name</span> <span class="hljs-title">src</span>;</span> <span class="hljs-comment">//消息源</span>    <span class="hljs-comment">/* oldest code we think can decode this.  unknown if zero. */</span>    __le16 compat_version;    __le16 reserved;    __le32 crc;       <span class="hljs-comment">/* header crc32c */</span>&#125; __attribute__ ((packed));<span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">ceph_msg_footer</span> &#123;</span>    __le32 front_crc, middle_crc, data_crc; <span class="hljs-comment">//crc校验码</span>    __le64  sig; <span class="hljs-comment">//消息的64位signature</span>    __u8 flags; <span class="hljs-comment">//结束标志</span>&#125; __attribute__ ((packed));</code></pre><hr><h2 id="5-Ceph-CRUSH算法"><a href="#5-Ceph-CRUSH算法" class="headerlink" title="5 Ceph CRUSH算法"></a>5 Ceph CRUSH算法</h2><blockquote><p>Controlled Replication Under Scalable Hashing, 可扩展哈希下的可控复制。以数据唯一标识符、当前存储集群的拓扑结构以及数据备份策略作为CRUSH输入，可以随时随地的通过计算获取数控所在的底层存储设备的位置并直接与其通信，从而避免查表操作，实现去中心化和高度并发。</p><p>CRUSH是一种伪随机算法，采用<strong>一致性哈希</strong>。</p><p>OSD MAP: 包含当前所有pool的状态，和所有OSD状态。</p><p>CRUSH MAP: 包含当前磁盘、服务器、机架的层次结构。</p><p>CRUSH Rules：数据映射的策略。以便灵活放置Object。</p></blockquote><h3 id="数据分布算法挑战"><a href="#数据分布算法挑战" class="headerlink" title="数据分布算法挑战"></a>数据分布算法挑战</h3><p><strong>数据分布和负载均衡</strong>：</p><ul><li>a. 数据分布均衡，使数据能均匀的分布到各个节点上。</li><li>b. 负载均衡，使数据访问读写操作的负载在各个节点和磁盘的负载均衡。</li></ul><p><strong>灵活应对集群伸缩</strong>：</p><ul><li>a. 系统可以方便的增加或者删除节点设备，并且对节点失效进行处理。</li><li>b. 增加或者删除节点设备后，能自动实现数据的均衡，并且尽可能少的迁移数据。</li></ul><p><strong>支持大规模集群</strong>：</p><ul><li>a. 要求数据分布算法维护的元数据相对较小，并且计算量不能太大。随着集群规模的增 加，数据分布算法开销相对比较小。</li></ul><h3 id="Ceph-CRUSH算法原理"><a href="#Ceph-CRUSH算法原理" class="headerlink" title="Ceph CRUSH算法原理"></a>Ceph CRUSH算法原理</h3><p><strong>CRUSH算法因子：</strong></p><ul><li>层次化的Cluster Map<br> 实际应用中设备具有形如“数据中心 → 机架→主机→磁盘”这样的树状层级，所以Cluster Map采用树来实现，每个叶子节点都是真实的最小物理存储设备，称为devices，而所有中间节点称为root，是整个集群的入口。每个节点都拥有唯一的数字ID和类型，但是只有叶子节点才拥有非负ID，表明它们是终端设备。</li></ul><blockquote><p>​                                                    下表展示了Cluster Map一些常见节点的层级</p></blockquote><ul><li>| 类型ID |  类型名称  |<br> | :——: | :————: |<br>|   0    |    osd     |<br> |   1    |    host    |<br> |   2    |  chassis   |<br> |   3    |    rack    |<br> |   4    |    row     |<br> |   5    |    pdu     |<br> |   6    |    pod     |<br> |   7    |    room    |<br> |   8    | datacenter |<br> |   9    |   region   |<br> |   10   |    root    |</li></ul><p><img src="/img/ceph-o.png" alt=" "></p><ul><li>CRUSH Map是一个树形结构，OSDMap更多记录的是OSDMap的属性(epoch/fsid/pool信息以及osd的ip等等)。</li></ul><p>叶子节点是device（也就是osd），其他的节点称为bucket节点，这些bucket都是虚构的节点，可以根据物理结构进行抽象，当然树形结构只有一个最终的根节点称之为root节点，中间虚拟的bucket节点可以是数据中心抽象、机房抽象、机架抽象、主机抽象等。</p><h3 id="数据分布策略Placement-Rules"><a href="#数据分布策略Placement-Rules" class="headerlink" title="数据分布策略Placement Rules"></a>数据分布策略Placement Rules</h3><p>在完成了使用clustermap建立对应的集群的拓扑结构描述后，可以定义placement rule 来完成<strong>数据映射</strong>.</p><p>这些操作有三种类型：</p><ul><li><p>take</p><p>take从cluster map选择指定编号的bucket ，并以此作为后续步骤的输入。例如系统默认以root节点作为输入。</p></li><li><p>select*</p><p>select从输入的bucket中随机选择指定类型和数量的条目。Ceph支持两种类型的备份策略，多副本和<strong>纠删码</strong>，对应两种算法，firstn和<strong>indep</strong>。以上两种算法都是dfs，无明显区别，唯一区别是纠删码是要求结果是有序的，i.e.总是返回指定长度的结果，如果对应条目不存在，采用空穴进行填充。</p><p>select操作也支持容灾模式，例如设置为rack，select保证所有选出的副本位于不同的机架上，也可以设置为host，即所有选出的副本位于不同的主机的磁盘上。</p></li><li><p>emit</p><p>输出最终的选择结果给上级调用并返回。</p></li></ul><p><strong>数据分布策略Placement Rules主要有特点：</strong></p><ul><li>a. 从CRUSH Map中的哪个节点开始查找</li><li>b. 使用那个节点作为故障隔离域</li><li>c. 定位副本的搜索模式（广度优先 or 深度优先）</li></ul><pre><code class="hljs bash">rule replicated_ruleset  <span class="hljs-comment">#规则集的命名，创建pool时可以指定rule集</span>&#123;    ruleset 0                <span class="hljs-comment">#rules集的编号，顺序编即可   </span>    <span class="hljs-built_in">type</span> replicated          <span class="hljs-comment">#定义pool类型为replicated(还有erasure模式)   </span>    min_size 1                <span class="hljs-comment">#pool中最小指定的副本数量不能小1</span>    max_size 10               <span class="hljs-comment">#pool中最大指定的副本数量不能大于10       </span>    step take default         <span class="hljs-comment">#查找bucket入口点，一般是root类型的bucket    </span>    step chooseleaf  firstn  0  <span class="hljs-built_in">type</span>  host <span class="hljs-comment">#选择一个host,并递归选择叶子节点osd     </span>    step emit        <span class="hljs-comment">#结束</span>&#125;</code></pre><h3 id="Bucket随机算法类型"><a href="#Bucket随机算法类型" class="headerlink" title="Bucket随机算法类型"></a>Bucket随机算法类型</h3><p><img src="/img/ceph-p.jpg" alt=""></p><p><strong>一般的buckets</strong>：适合所有子节点权重相同，而且很少添加删除item。</p><p><strong>list buckets</strong>：适用于集群扩展类型。增加item，产生最优的数据移动，查找item，时间复杂度O(n)。</p><p><strong>tree buckets</strong>：查找负责度是O (log n), 添加删除叶子节点时，其他节点node_id不变。</p><p><strong>straw buckets</strong>：允许所有项通过类似抽签的方式来与其他项公平“竞争”。定位副本时，bucket中的每一项都对应一个随机长度的straw，且拥有最长长度的straw会获得胜利（被选中），添加或者重新计算，子树之间的数据移动提供最优的解决方案。</p><h3 id="STRAW算法"><a href="#STRAW算法" class="headerlink" title="STRAW算法"></a>STRAW算法</h3><p>straw将所有元素比喻成吸管，针对指定输入，为每个元素随机计算一个长度，最后选择长度最长的那个元素作为结果输出，这个过程也被形象地称为抽签（draw），对应元素的长度称为签长。因为存储设备随着时间推移会趋于异构化，随意我们引入权重来让容量大的设备分担更多的数据，而容量小的设备分担更少的数据，从而使得数据在异构网络中也能获得合理的分布。</p><p>将所有元素按逆序排列，我们设签长为$L$，用$\triangle W_{pre}$表示当前元素与之前元素权重的差值，$R$表示剩余元素个数，$\triangle W_{next}$表示下一个元素与现在元素的权重差值,$S$表示累计权重占有的比重。</p><script type="math/tex; mode=display">S = \frac{\sum \triangle W_{pre}}{\sum \triangle W_{pre}+\triangle W_{next}}\\L = \prod{(1/S)^{1/R}}</script><p>再把L乘上0x10000。</p><p>上述算法，最终选择结果不仅与每个元素自身权重有关，还与集合中其它元素相关，修正后的straw2算法，则更加简单，</p><pre><code class="hljs properties"><span class="hljs-attr">max_x</span> = <span class="hljs-string">-1</span><span class="hljs-attr">max_item</span> = <span class="hljs-string">-1</span><span class="hljs-attr">foreach</span> <span class="hljs-string">in item:</span><span class="hljs-attr">x</span> = <span class="hljs-string">hash(input, r)</span><span class="hljs-attr">x</span> = <span class="hljs-string">ln(x/65536)/weight</span><span class="hljs-attr">if</span> <span class="hljs-string">x &gt; x_max:</span><span class="hljs-attr">x_max</span> = <span class="hljs-string">x</span><span class="hljs-attr">max_item</span> = <span class="hljs-string">item</span><span class="hljs-attr">return</span> <span class="hljs-string">max_item</span></code></pre><h3 id="CRUSH算法案例"><a href="#CRUSH算法案例" class="headerlink" title="CRUSH算法案例"></a>CRUSH算法案例</h3><p>集群中有部分sas和ssd磁盘，现在有个业务线性能及可用性优先级高于其他业务线，能否让这个高优业务线的数据都存放在ssd磁盘上。</p><p><strong>普通用户：</strong></p><p><img src="/img/ceph-q.jpg" alt="img"></p><p><strong>高优用户</strong></p><p><img src="/img/ceph-r.jpg" alt="img"></p><p>配置规则</p><p>作者：<img src="/img/ceph-t.jpg" alt="img"></p><p>限于篇幅，我们对CRUSH的介绍十分简略，更详细的请看<a href="https://durantthorvalds.top/2020/11/27/A%20first%20glance%20at%20CRUSH/">A First Galance At Crush</a>一文.</p><hr><h2 id="6-定制化Ceph-RBD-QOS"><a href="#6-定制化Ceph-RBD-QOS" class="headerlink" title="6 定制化Ceph RBD QOS"></a>6 定制化Ceph RBD QOS</h2><p>QoS （Quality of Service，服务质量）起源于网络技术，它用来解决网络延迟和阻塞等问题，能够为指定的网络通信提供更好的服务能力。</p><p>我们总的Ceph集群的iIO能力是有限的，比如带宽，IOPS。如何避免用户争取资源，如果保证集群所有用户资源的高可用性，以及如何保证高优用户资源的可用性。所以我们需要把有限的IO能力合理分配。</p><h3 id="Ceph-IO操作类型"><a href="#Ceph-IO操作类型" class="headerlink" title="Ceph IO操作类型"></a>Ceph IO操作类型</h3><ul><li><p><strong>ClientOp</strong>：来自客户端的读写I/O请求。</p></li><li><p><strong>SubOp</strong>：osd之间的I/O请求。主要包括由客户端I/O产生的副本间数据读写请求，以及由数据同步、数据扫描、负载均衡等引起的I/O请求。</p></li><li><p><strong>SnapTrim</strong>：快照数据删除。从客户端发送快照删除命令后，删除相关元数据便直接返回，之后由后台线程删除真实的快照数据。通过控制snaptrim的速率间接控制删除速率。</p></li><li><p><strong>Scrub</strong>：用于发现对象的静默数据错误，扫描元数据的Scrub和对象整体扫描的deep Scrub。</p></li><li><p><strong>Recovery</strong>：数据恢复和迁移。集群扩/缩容、osd失效/从新加入等过程。</p></li></ul><h2 id="7-CephFS"><a href="#7-CephFS" class="headerlink" title="7.CephFS"></a>7.CephFS</h2><p><img src="/img/ceph-lec.jpg" alt="image-20201122181939220"></p><h2 id="8-BlueStore-分布式对象存储"><a href="#8-BlueStore-分布式对象存储" class="headerlink" title="8.BlueStore 分布式对象存储"></a>8.BlueStore 分布式对象存储</h2><blockquote><p>与一般的FS相比，BlueStore绕过了系统的本地文件系统，由自身接管磁盘，所以其性能更好。并且充分考虑了对下一代全SSD以及全NVMe SSD闪存的支持。例如支持RocksDB。</p></blockquote><p>先介绍一些术语：</p><p>$ACID$，分别表示$Atomicity, Consistency,Isolation,Durability$。原子性，一致性，隔离性，持久性。一个支持事务$Transcation$d的系统必须支持这四种特性。</p><ol><li><strong>block-size</strong></li></ol><p>对磁盘进行操作的最小粒度（原子粒度），对普通的机械硬盘，最小粒度512字节，即一个扇区。现代SSD一般使用更大的块，4KB。</p><ol><li><strong>RMW（Read Modify Write）</strong></li></ol><p>指覆盖写，如果本次改写的内容不足一个磁盘块大小，那么需要先将对应的块读上来，然后将待修改的内容与原先的内容进行合并，最后将更新后的块重新写入原先的位置。 有两个问题：1. 额外的惩罚读 2. 因为要针对已有的内容执行覆盖写。解决方法是引入日志，数据线写入日志盘再更新数据盘。</p><ol><li><strong>COW（Copy On Write）</strong></li></ol><p>指当覆盖写发生时，不是直接更新磁盘对应位置的已有内容，而是重新在磁盘上分配一块新的空间，用于存放本次新写入的内容，这个过程也称为写时重定向。当新写完成，对应的地址更新时，即可释放原有数据对应的磁盘空间。</p><p>它自身的缺陷是：1. 破坏了数据在磁盘分布的物理连续性，经过多次COW后，前端任何大范围的顺序读后续都将变为随机读。在SSD普及后，这种情况有所好转。2. 将新的内容写入新块后，原有的块因为仍然保留了部分有效内容，所以COW之后不能释放。因为COW涉及空间重分配和地址指针重定向，所以COW将引入更多元数据。对存储系统而言，元数据的多少关乎功能的丰富与否。</p><p>BlueStore针对写操作综合运用了RMW和COW策略——任何一个写请求，根据磁盘的大小，将其切分为三个部分。<strong>首尾非块大小对齐部分</strong>，<strong>中间块大小对齐部分</strong>，然后针对中间块对齐部分采用<strong>COW策略</strong>，首尾非块对齐部分采用<strong>RMW策略</strong>。</p><p>BlueStore主要提供了读写两种类型的多线程访问接口，这些接口是基于PG粒度的。因为读请求可以并发，而写请求出于效率考虑一般被设计为异步，（所以PG内部使用读写锁来实现上述语义），实现上还需要为每个PG设计一个队列，用于对所有操作该PG的写请求进行保序。称为$OpSequencer$，不同类型的ObjectStore略有不同，在BlueStore实现中，$OpSequencer$包含两个FIFO。用于将所有进入覆盖写数据阶段的带日志写请求在线程池中再次进行排序。所有写请求通过标准的<code>queue_transcations</code>接口提交至BlueStore.</p><blockquote><p><a href="https://github.com/ceph/ceph/pull/9398">多对象事务语义支持参考</a></p></blockquote><h2 id="磁盘数据结构"><a href="#磁盘数据结构" class="headerlink" title="磁盘数据结构"></a>磁盘数据结构</h2><p>BlueStore习惯上磁盘格式用<code>_t</code>结尾而内存格式不以<code>_t</code>结尾并且只有首大写字母。所有元数据被设计成可以和用户数据分开存放，以键值对形式存放在$kvDB$中。</p><h3 id="PG"><a href="#PG" class="headerlink" title="PG"></a>PG</h3><p>ceph对所有存储资源进行池化管理。资源池(pool), 是一个虚拟概念，表示一组CRUSH规则的约束条件。比如我们可以针对不同的pool指定不同的备份策略，针对时延敏感的应用采用副本策略，而在一些不重要的应用采用纠删码。Ceph将任意类型的前端数据都抽象为对象，每一个对象 采用一定的策略可以生成一个全局唯一的对象标识符（$ObjectID,OID$）基于此策略的对象标识最终可以形成一个扁平的寻址空间，从而大大提高索引效率。</p><p>为了实现不同pool之间的策略隔离，Ceph引入了一个中间结构，称为PG，（归置组），实现两级映射。</p><ul><li>第一级映射是静态的，负责将任何前端类型 的应用数据按照固定的大小进行分割·编号作为伪随机哈希函数的输入，均匀映射至PG，以实现负载均衡。</li><li>第二集映射实现PG到OSD的映射，这级映射仍采用伪随机哈希函数，但是除输入的五安居唯一的PGID外，还引入了集群拓扑，并且使用CRUSH规则对计算过程进行调整，以帮助PG在不同OSD之间进行灵活迁移，进而实现数据可靠性和自动平衡等。最终pool以PG作为基本单位进行组织。</li></ul><p>为了维持扁平的寻址空间。PG也有一个全局唯一的ID——$PGID$，所有的pool由Monitor统一管理，集群内唯一pool-id。事实上，为了保证Monitor分布一致性，采用Paxos算法，我们只需要为pool内每个PG分配一个pool内唯一的编号即可。</p><blockquote><p>思考：如何使得同一个pool下的不同的PG低n位相同？</p><p>首先由特定类型的Client根据其操作的对象名计算出一个32位的哈希值，然后根据其操作的对象名计算出一个32位的哈希值，然后根据归属的pool及此时的哈希值，通过简单的计算，比如取模，即可找到最终承载该对象的PG。</p><p>我们发现如果pool内的PG数目如果能写成$2^n$形式，那么其低n比特都是相同的。我们将$2^n-1$称为PG的<strong>掩码</strong>。否则，若PG不能写成$2^n$的形式，则不能保证针对不同的输入低n比特相同这一“稳定”的性质。（比如有12个PG，那么对于属于同一个pool的PGID只有低两位相同）</p><p>因此一种行之有效的方法是用掩码代替取模。取hash低n-1位，即$hash\&amp;(2^n-1)$ .但这种映射存在问题，如果PG数目不能被2整除，那么采用这种方式会导致空穴，也就是取模结果没有实际PG对应。</p><p>比如一个pool有12个PG，n=4，但是12-15这些值都浪费了：</p><div class="table-container"><table><thead><tr><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>x</td><td>x</td><td>x</td><td>x</td></tr></tbody></table></div><p>我们可以想办法压缩空间 ，$hash\&amp;(2^{n-1}-1)$，使得不能被2整除的PGID仍能被合理映射。</p><div class="table-container"><table><thead><tr><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th><th>7</th><th>8</th><th>9</th><th>10</th><th>11</th><th>12</th><th>13</th><th>14</th><th>15</th></tr></thead><tbody><tr><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td></td><td>0</td><td>1</td><td>2</td><td>3</td><td>4</td><td>5</td><td>6</td><td>7</td></tr></tbody></table></div><p>如果$hash\&amp;(2^{n}-1)&lt;pg_num$，那么可以直接返回$hash\&amp;(2^n-1)$.</p><p>否则，我们返回$hash\&amp;(2^{n-1}-1)$.</p><p>在参考书上被称为稳定哈希（stable hash）。</p></blockquote><p>Ceph主要设计理念之一是高扩展性。当集群中PG增加，新的PG会被随机均匀地映射至所有OSD上。作为stable hash的输入的PG数目已经发生变化，导致某些对象从旧PG重新映射至新PG，因此需要转移这部分对象，我们称为<strong>PG分裂</strong>。</p><h3 id="对象"><a href="#对象" class="headerlink" title="对象"></a>对象</h3><p>BlueStore中的对象非常类似于文件，其最基本单元是<strong>逻辑段</strong>（extent）.</p><p>可以写成 $\{offset, length , data\}$，</p><ul><li>offset表示对象逻辑偏移，从0开始编址</li><li>逻辑段长度</li><li>抽象数据类型</li></ul><p>—-更新中</p><p>参考资料</p><p><a href="https://www.jianshu.com/p/cc3ece850433">https://www.jianshu.com/p/cc3ece850433</a></p><hr><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>Weil S A Brandt S A , Miller E L , et al. CRUSH: Controlled, Scalable, Decentralized Placement of Replicated Data[C]// IEEE Sc Conference. ACM, 2006.<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;CEPH基础理论学习&quot;&gt;&lt;a href=&quot;#CEPH基础理论学习&quot; class=&quot;headerlink&quot; title=&quot;CEPH基础理论学习&quot;&gt;&lt;/a&gt;CEPH基础理论学习&lt;/h1&gt;&lt;hr&gt;
&lt;h1 id=&quot;第一部分&quot;&gt;&lt;a href=&quot;#第一部分&quot; class=</summary>
      
    
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/categories/ceph/"/>
    
    <category term="理论" scheme="http://durantthorvalds.top/categories/ceph/%E7%90%86%E8%AE%BA/"/>
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title>日语名谚语系列</title>
    <link href="http://durantthorvalds.top/2020/11/19/%E6%AF%8E%E6%97%A5%E6%94%BE%E9%80%81%EF%BC%8D%E6%97%A5%E6%9C%AC%E3%81%AE%E8%AB%BA/"/>
    <id>http://durantthorvalds.top/2020/11/19/%E6%AF%8E%E6%97%A5%E6%94%BE%E9%80%81%EF%BC%8D%E6%97%A5%E6%9C%AC%E3%81%AE%E8%AB%BA/</id>
    <published>2020-11-18T16:00:00.000Z</published>
    <updated>2020-12-15T11:04:14.969Z</updated>
    
    <content type="html"><![CDATA[<h1 id="毎日放送－日本の諺"><a href="#毎日放送－日本の諺" class="headerlink" title="毎日放送－日本の諺"></a>毎日放送－日本の諺</h1><p>每日一句日语谚语，让你口语和写作更地道一点吧。</p><p>1.　失敗は成功の元。　しっぱいはせいこうのもと。失败是成功之母。<br>2.　習うより慣れよ。习惯成自然。<br>3.　今日の後に今日なし。光阴似箭，日月如梭。<br>4.　急がは回れ。欲速则不达。<br>5.　人は見かけによらず。人不可貌相。<br>6.　覆水盆に返らず。ふくすいぼんにかえらず。覆水难收。<br>7.　石の上にも三年。功夫不负有心人。<br>8.　努力に勝る天才なし。どりょくにまさるてんさいなし。勤能补拙。<br>9.　私は神様ではない。人非圣贤，孰能无过。<br>10.　千里の道も一歩より。せんりのみちもいっぽより。千里之行始于足下。<br>11.　命あっての物種。いのちあってのものだね。留得青山在，不怕没柴烧。<br>12.　会うは別れの始め。あうのはわかれのはじめ。天下无不散之宴席。<br>13.　郷に入っては郷に従え。ごうにいればごうにしたがう。入乡随俗。<br>14.　怪我の功名。けがのこうめい。塞翁失马焉知非福。<br>15.　黒に染まれば黒くなる。くろにそまればくろくなる。近朱者赤近墨者黑。<br>16.　血は水より濃い。血浓于水。<br>17.　敵は本能寺にあり。てきはほんのうじにあり。醉翁之意不在酒。<br>18.　情けは人の為ならず。なさけないひとのためならず。好人有好报。<br>19.　火のない所に煙は立たぬ。无风不起浪。<br>20.　焼け石に水。杯水车薪。<br>21.　一を聞いて十を知る。举一反三。<br>22.　とおいいっかよりちかい隣。远亲不如近邻。<br>23.　かわいい娘には旅をさせよ。玉不琢不成器。<br>24.　三人寄れば文殊の知恵。三个臭皮匠顶一个诸葛亮。<br>25.　可愛い子には旅をさせよ。玉不琢不成器。<br>26.　たびはみちずれ、よはなさけ。在家靠亲戚，出门靠朋友。<br>27.　良薬は口に苦し。<br>28.　ねこにはんこ。明珠暗投。<br>29.　泣き面に蜂。なきつらにはち。雪上加霜。<br>30.　馬の耳に念仏。耳边风。<br>31.　氏より育て柄。后天教育比出身重要。<br>32.　芸は身を助く。技多不压身。<br>33.　得手に帆を揚げる。扬长避短。<br>34.　猿も木から落ちる。智者千虑，必有一失。<br>35.　若い時は二度無い。花无百日好，人无二度春。<br>36.　立て板に水。口若悬河。<br>37.　稼ぐに追いつく貧乏なし。勤劳致富。<br>38.　寝耳に水。晴天霹雳。<br>39.　鬼に金棒。如虎添翼。<br>40.　負けるが勝ち。胜负乃兵家常事。<br>41.　餅は餅屋。外行看热闹，内行看门道。<br>42.　地獄の沙汰も金次第。有钱能使鬼推磨。<br>43.　仏の顔も三度。人的忍耐是有限度的。<br>44.　損して得取れ。损人利己。<br>45.　自画自賛。<br>46.　自業自得。自作自受。<br>47.　人の噂も七十五日。风言风语长不了。<br>48.　人の花は赤い。什么都是别人的好。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;毎日放送－日本の諺&quot;&gt;&lt;a href=&quot;#毎日放送－日本の諺&quot; class=&quot;headerlink&quot; title=&quot;毎日放送－日本の諺&quot;&gt;&lt;/a&gt;毎日放送－日本の諺&lt;/h1&gt;&lt;p&gt;每日一句日语谚语，让你口语和写作更地道一点吧。&lt;/p&gt;
&lt;p&gt;1.　失敗は成功の元。</summary>
      
    
    
    
    <category term="日语" scheme="http://durantthorvalds.top/categories/%E6%97%A5%E8%AF%AD/"/>
    
    <category term="文化" scheme="http://durantthorvalds.top/categories/%E6%97%A5%E8%AF%AD/%E6%96%87%E5%8C%96/"/>
    
    
    <category term="日语" scheme="http://durantthorvalds.top/tags/%E6%97%A5%E8%AF%AD/"/>
    
  </entry>
  
  <entry>
    <title>「入门部署」Ceph-deploy流程</title>
    <link href="http://durantthorvalds.top/2020/11/19/Ceph-deploy%E6%B5%81%E7%A8%8B/"/>
    <id>http://durantthorvalds.top/2020/11/19/Ceph-deploy%E6%B5%81%E7%A8%8B/</id>
    <published>2020-11-18T16:00:00.000Z</published>
    <updated>2020-12-16T08:33:46.367Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ceph-deploy流程"><a href="#Ceph-deploy流程" class="headerlink" title="Ceph-deploy流程"></a>Ceph-deploy流程</h1><p>本文介绍了借助Ceph-deploy工具安装Ceph并搭建集群的过程。按照下文的步骤，你可以快速搭建一个基础的Ceph环境，并且了解Ceph集群的组成和工作原理。文章首先会简单介绍Ceph及其安装和环境部署方法，接着给出了预备环境的搭建过程，最后详细地列出了Ceph的安装及配置过程。本文附录还给出了Ceph的编译过程示例。</p><h2 id="1-Ceph基础"><a href="#1-Ceph基础" class="headerlink" title="1  Ceph基础"></a>1  Ceph基础</h2><h3 id="1-1-Ceph介绍"><a href="#1-1-Ceph介绍" class="headerlink" title="1.1 Ceph介绍"></a>1.1 Ceph介绍</h3><p>Ceph 是一个可靠的、自动重均衡、自动恢复的分布式存储系统，根据场景划分可以将 Ceph 分为三大块，分别是对象存储、块设备存储和文件系统服务。三种应用场景都在底层的RADOS之上运行，最后都会被转换成对象存储在各个pool的placement group(PG)中。</p><p>Ceph 的核心组件包括 Ceph OSD、Ceph Monitor、Ceph Manager和 Ceph MDS。</p><ul><li><em>Ceph OSD</em>：OSD 的英文全称是 Object Storage Device，它的主要功能是存储数据、复制数据、平衡数据、恢复数据等，Ceph OSD 的架构实现由物理磁盘驱动器、Linux文件系统和 Ceph OSD 服务组成。</li><li><em>Ceph Monitor</em>：负责监视 Ceph 集群，维护Ceph 集群的健康状态，同时维护着 Ceph 集群中的各种 Map 图，比如 OSD Map、Monitor Map、PG Map 和 CRUSH Map。</li><li><em>Ceph  Manager</em>: 负责跟踪运行时指标和Ceph集群的当前状态，包括存储利用率、当前性能指标和系统负载。</li><li><em>Ceph MDS</em>：全称是 Ceph MetaData Server，主要保存的文件系统服务的元数据，但对象存储和块存储设备是不需要使用该服务的。</li></ul><p>对于一个用于对象存储的Ceph集群来说，它至少需要部署一个Monitor服务、一个Manager服务和一个OSD服务。其中，这些组件可以部署在同一台机器，即一个机器可以拥有多个角色（服务）。</p><p>若要保证数据可靠性，系统中应当有多个OSD节点，以实现副本或纠删码功能。Ceph默认的策略是3副本，这意味着在该策略下集群中至少要有3个OSD节点才能正常运作。（副本策略和纠删码配置均可更改）</p><h3 id="1-2-Ceph的安装方法"><a href="#1-2-Ceph的安装方法" class="headerlink" title="1.2 Ceph的安装方法"></a>1.2 Ceph的安装方法</h3><p>Ceph主要编写的语言是C++，其代码规模可达100+万行，同时Ceph涉及的依赖软件众多，任何一个环节出问题都有可能导致Ceph安装失败，这对新手来说是一个挑战。</p><p> Ceph的安装方法有以下三种：</p><ol><li>手动编译安装。官方提供了依赖软件的安装脚本，源码中还自带CMake规则，生成对应makfile后由make调用gcc/g++编译完成。理论上Ceph的编译安装过程可以使用自动化工具简单几步就完成，但不同机器的系统和环境不同，先前安装的软件或者环境变量设置不当也有可能会给安装过程带来一些障碍。手动编译是比较容易出问题的，也是耗时最长的。一般来说在使用官方版本入门探索时不推荐手动安装。若要修改源代码，则必须使用手动方法安装。具体的手动编译安装流程见文章附录。</li><li>使用包管理工具安装。官方及各大开源镜像站都提供了官方标准版本的软件源，我们可以添加对应的密钥和仓库链接后，使用系统自带的包管理工具轻松安装。如Ubuntu/Debian中的apt，CentOS/RHEL中的yum。这种方法简单方便，但要注意只能安装官方标准版本。</li><li><p>使用部署工具安装。下文提及的自动化部署工具中带有Ceph组件的安装功能，如Ceph-deploy，它本质上还是调用包管理工具进行安装。（Docker等容器方法暂不在讨论范围之内）</p><p>简而言之，除了有修改源代码的需求外，一般优先推荐使用方法2或方法3安装Ceph。</p></li></ol><h3 id="1-3-Ceph的部署方法"><a href="#1-3-Ceph的部署方法" class="headerlink" title="1.3 Ceph的部署方法"></a>1.3 Ceph的部署方法</h3><p>Ceph是一个分布式存储系统，这意味着还需要一系列的配置文件、设置来告诉系统中的节点分别如何工作。在每一台节点上分别手动配置是可行的，但过程繁琐且复杂，还容易出问题，一般不推荐。下面我们介绍几种用于部署Ceph的自动化工具。</p><ol><li>Cephadm：它是在Ceph官方在新版本Octopus（15）中推行的全新部署工具。Cephadm完美支持新的编排API、CLI和仪表盘特性，可用于快速部署Octopus及更新版本的Ceph集群。Cephadm更加简单，且不依赖其它自动化部署工具，但该工具不支持部署旧版本的Ceph（如14的Nautilus），所有Ceph进程也是运行在容器中的，意味着在修改源码的情况下还需要制作新的镜像，比较麻烦。官方文档中指出，Cephadm暂时不推荐用于生产环境。</li><li>Rook：可以把Ceph部署在Kubernetes集群中运行。与1类似的是，Ceph也是运行在容器中的。</li><li>Ceph-deploy：在v14 Nautilus及之前的官方推荐部署工具（目前已不再维护）。其原理是借助ssh集中控制集群主机，让它们分别执行特定命令和传输配置文件。通过Ceph-deploy安装的Ceph是直接运行在目的主机的操作系统上的（而非容器），同时Ceph的安装与集群的部署是可以分开进行的。</li><li><p>其它：ceph-ansible、DeepSea、puppet-ceph等工具都需要第三方部署工具的支持。</p><p>假设我们有Ceph源代码修改的需求，1和2的容器运行环境会让事情变得更加复杂（如重新制作镜像并上传），使得快速修改代码后测试也变得困难，因此我们暂不采用。而Ceph-deploy工具比较灵活，无论是使用官方标准版本Ceph进行入门探索，亦或是测试修改源码后的Ceph，它都有较好的支持。虽然官方已不再维护，但对于一般科研用途而言，Ceph-deploy工具已经能够满足需求，可以帮助用户快速搭建出一个简单的Ceph集群。下文中我们将着重介绍基于Ceph-deploy的安装和部署流程。</p></li></ol><h2 id="2-预备条件"><a href="#2-预备条件" class="headerlink" title="2  预备条件"></a>2  预备条件</h2><p>下文将在Ubuntu 18.04的环境下，选择Ceph v14.2.13（Nautilus）作为目标版本，以使用Ceph-deploy 2.0.1安装和部署带3个OSD的Ceph纠删码集群为例，一步步地引导读者搭建出一个基础的Ceph环境。</p><p>要实现这一目标，我们需要准备3台机器，其中1台同时充当用于控制部署的admin_node。部署的控制也可以在另一个存储节点上进行，但这里为了方便理解我们指定node_0来控制部署流程。注意：经测试发现，当前版本的Ceph只能使用物理块设备来部署存储服务，因此每个存储节点都需要除系统盘外的额外一块空硬盘供Ceph使用，该硬盘将被重新格式化。</p><p>本文中的示例集群如下：</p><div class="table-container"><table><thead><tr><th>主机名</th><th>IP地址</th><th>角色</th></tr></thead><tbody><tr><td>node_0</td><td>192.168.248.100</td><td>deploy_admin  / monitor / manager / osd_0</td></tr><tr><td>node_1</td><td>192.168.248.101</td><td>osd_1</td></tr><tr><td>node_2</td><td>192.168.248.102</td><td>osd_2</td></tr></tbody></table></div><p> 我们将在虚拟机中进行演示，其中每个主机都含有8 GiB的RAM，60 GB的系统盘以及10 GB的数据盘。</p><p>（小技巧：我们可以先在1台虚拟机上配置好通用的预备环境，再克隆出另外的2台，随后调整部分配置后即可（如IP、主机名等）。克隆后记得重新生成网卡MAC地址）</p><h2 id="3-预备环境配置"><a href="#3-预备环境配置" class="headerlink" title="3  预备环境配置"></a>3  预备环境配置</h2><h3 id="3-1-网络配置"><a href="#3-1-网络配置" class="headerlink" title="3.1 网络配置"></a>3.1 网络配置</h3><p>所有节点都需要执行以下步骤。</p><ol><li><p>IP配置。最简单的方法是在GUI的设置中直接修改网络配置，也可以手动修改网络配置文件。这一步我们不再赘述。</p></li><li><p>修改主机名。修改文件 /etc/hostname ，把内容替换为对应的主机名。重启后生效。</p><pre><code class="hljs bash">$  sudo vim /etc/hostname   <span class="hljs-comment"># 以node_0为例，替换为如下内容</span>    node_0</code></pre></li><li><p>添加域名映射。修改 /etc/hosts ，添加对应映射内容：</p> <pre><code class="hljs bash">$  sudo vim /etc/hosts   <span class="hljs-comment"># 添加如下内容</span>192.168.248.100 node_0192.168.248.101 node_1192.168.248.102 node_2</code></pre></li></ol><h3 id="3-2-软件仓库配置"><a href="#3-2-软件仓库配置" class="headerlink" title="3.2 软件仓库配置"></a>3.2 软件仓库配置</h3><p>所有节点都需要执行以下步骤。</p><ol><li>建议使用国内软件源，如阿里、网易、清华、中科大、华科开源镜像站等，在后面安装包时能获得更好的体验。最简单的方法是在GUI中的“软件与更新”设置中选择国内源，手动配置则具体见 <a href="http://mirrors.ustc.edu.cn/help/ubuntu.html">http://mirrors.ustc.edu.cn/help/ubuntu.html</a></li><li><p>配置国内Ceph源。以中科大镜像站为例：</p> <pre><code class="hljs bash">$  wget -q -O- <span class="hljs-string">&#x27;http://mirrors.ustc.edu.cn/ceph/keys/release.asc&#x27;</span> | sudo apt-key add -$  <span class="hljs-built_in">echo</span> deb http://mirrors.ustc.edu.cn/ceph/debian-nautilus/ $(lsb_release -sc) main | sudo tee /etc/apt/sources.list.d/ceph.list$  vim ~/.bashrc  <span class="hljs-comment"># 添加如下内容</span><span class="hljs-built_in">export</span> CEPH_DEPLOY_REPO_URL=http://mirrors.ustc.edu.cn/ceph/debian-nautilus/ <span class="hljs-built_in">export</span> CEPH_DEPLOY_GPG_URL=http://mirrors.ustc.edu.cn/ceph/keys/release.asc$  <span class="hljs-built_in">source</span> ~/.bashrc$  sudo apt update</code></pre></li></ol><p>注意：其中URL处的“debian-nautilus”可以根据不同的目标Ceph版本和操作系统更改为不同的对应名称。</p><h3 id="3-3-Ceph专门用户"><a href="#3-3-Ceph专门用户" class="headerlink" title="3.3 Ceph专门用户"></a>3.3 Ceph专门用户</h3><p>我们将创建 cephuser 用户作为Ceph运行专门的用户。所有节点都需要执行以下步骤。</p><pre><code class="hljs bash">$  sudo useradd cephuser -m -d /home/cephuser -s /bin/bash$  sudo passwd cephuser  <span class="hljs-comment"># 输入密码</span>$  <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;cephuser ALL = (root) NOPASSWD:ALL&quot;</span> | sudo tee /etc/sudoers.d/cephuser$  sudo chmod 0440 /etc/sudoers.d/cephuser$  su cephuser</code></pre><h3 id="3-4-安装支撑软件"><a href="#3-4-安装支撑软件" class="headerlink" title="3.4 安装支撑软件"></a>3.4 安装支撑软件</h3><p>所有节点都需要执行以下步骤。</p><ul><li><p>安装ssh服务端</p>  <pre><code class="hljs bash">$  sudo apt-get install openssh-server</code></pre></li><li><p>安装python，用于执行ceph-deploy受控端的脚本</p>  <pre><code class="hljs bash">$  sudo apt install python-minimal</code></pre></li></ul><h3 id="3-5-使用ntp校准时间"><a href="#3-5-使用ntp校准时间" class="headerlink" title="3.5 使用ntp校准时间"></a>3.5 使用ntp校准时间</h3><p>分布式系统对时间尤其敏感，若系统中各个节点时间误差很大，有可能造成系统奔溃。我们使用ntp来校准时间，保证每台主机的时间对齐。所有节点都需要执行以下步骤。</p><ul><li><p>安装ntp</p>  <pre><code class="hljs bash">$  sudo apt install ntp</code></pre></li><li><p>启动ntp服务</p>  <pre><code class="hljs bash">$  sudo /etc/init.d/ntp restart $  sudo systemctl <span class="hljs-built_in">enable</span> ntp.service</code></pre></li><li><p>添加阿里云ntp服务器</p>  <pre><code class="hljs bash">$  sudo vim /etc/ntp.conf    <span class="hljs-comment"># 末尾添加 server ntp.aliyun.com</span>$  sudo /etc/init.d/ntp restart</code></pre></li></ul><h3 id="3-6-配置ssh无密码访问"><a href="#3-6-配置ssh无密码访问" class="headerlink" title="3.6 配置ssh无密码访问"></a>3.6 配置ssh无密码访问</h3><p>Ceph-deploy需要管理节点获得其它节点的ssh无密码访问权限。以下步骤只需在admin_node（node_0）上执行。</p><ul><li><p>创建密钥，一路回车选择默认值即可。</p>  <pre><code class="hljs bash">$  ssh-keygen</code></pre></li><li><p>把公钥复制到其它节点</p>  <pre><code class="hljs bash">$  ssh-copy-id node_1$  ssh-copy-id node_2</code></pre></li><li><p>配置ssh登录的默认指定用户名，为ceph-deploy做准备。</p>  <pre><code class="hljs bash">$  vim ~/.ssh/config  <span class="hljs-comment"># 添加如下内容</span>Host node_1 Hostname node_1 User cephuserHost node_2 Hostname node_2 User cephuser</code></pre></li></ul><h2 id="4-Ceph的安装与部署"><a href="#4-Ceph的安装与部署" class="headerlink" title="4  Ceph的安装与部署"></a>4  Ceph的安装与部署</h2><p>以下步骤如没有特别申明，均只需在admin_node（node_0）上执行。</p><h3 id="4-1-安装ceph-deploy"><a href="#4-1-安装ceph-deploy" class="headerlink" title="4.1 安装ceph-deploy"></a>4.1 安装ceph-deploy</h3><ul><li><p>前面已配置过ceph源，直接使用apt安装</p>  <pre><code class="hljs bash">$  sudo apt install ceph-deploy</code></pre></li><li><p>创建保存配置文件的工作环境</p>  <pre><code class="hljs bash">$  mkdir ~/ceph_cluster$  <span class="hljs-built_in">cd</span> ~/ceph_cluster/</code></pre></li></ul><h3 id="4-2-安装ceph"><a href="#4-2-安装ceph" class="headerlink" title="4.2 安装ceph"></a>4.2 安装ceph</h3><p>下面命令采用了ceph-deploy远程控制的方式安装仓库中的官方标准版本。若需要从本地（修改后）源码安装，请查看附录中的编译安装部分。</p><pre><code class="hljs bash">$  ceph-deploy install --no-adjust-repos node_0 node_1 node_2</code></pre><p>由于我们已在前面配置好了国内ceph源，所以使用—no-adjust-repos参数防止覆盖。</p><p>如果出现问题：</p><pre><code class="hljs oxygene">Runtime Error: <span class="hljs-keyword">module</span> <span class="hljs-keyword">platform</span> <span class="hljs-keyword">has</span> no attribute <span class="hljs-string">&#x27;linux_distribution&#x27;</span>.</code></pre><p>python3.7以后<code>platform.linux_distribution()</code>被移除了. 而笔者用的是3.8. </p><p>若安装成功，可在各个节点上分别打印出ceph的版本号。</p><pre><code class="hljs bash">$  ceph -vceph version 14.2.13 (1778d63e55dbff6cedb071ab7d367f8f52a8699f) nautilus (stable)</code></pre><h3 id="4-3-部署MON节点"><a href="#4-3-部署MON节点" class="headerlink" title="4.3 部署MON节点"></a>4.3 部署MON节点</h3><p>此次规划在 node_0 上部署 mon、mgr、osd 进程，node_1 和 node_2 仅部署 osd 进程。在 node_0 节点上执行，创建 1 个 MON 服务进程，配置并同步 ceph.conf 配置文件，不部署日志盘和缓存盘。 </p><ul><li><p>创建集群配置，其中     —cluster-network和 —public-network参数指定集群的子网，若不配置后面执行Ceph-deploy时可能会出错。</p>  <pre><code class="hljs bash">$  ceph-deploy new --cluster-network 192.168.248.0/24 --public-network 192.168.248.0/24 node_0</code></pre></li></ul><p>命令末尾的node_0 为打算部署 mon 的节点。执行成功后会在当前目录下会自动生成：ceph.conf、ceph.mon.keyring 两个文件外加一个 log 文件。</p><ul><li><p>部署MON节点，并收集密钥</p>  <pre><code class="hljs bash">$  ceph-deploy mon create-initial</code></pre></li></ul><p>执行完之后，本地目录下会生成若干keyring结尾的密钥文件</p><ul><li><p>同步集群配置文件及admin keyring文件</p>  <pre><code class="hljs bash">$  ceph-deploy admin node_0$  ceph-deploy admin node_1$  ceph-deploy admin node_2</code></pre></li><li><p>检查配置是否成功</p>  <pre><code class="hljs bash">$  ceph -s  cluster:    id:     f564cb33-e2c7-44cb-a645-df9d20824667    health: HEALTH_OK   services:    mon: 1 daemons, quorum node_0 (age 31s)    mgr: no daemons active    osd: 0 osds: 0 up, 0 <span class="hljs-keyword">in</span>   data:    pools:   0 pools, 0 pgs    objects: 0 objects, 0 B    usage:   0 B used, 0 B / 0 B avail    pgs:</code></pre></li></ul><p>若出现：</p><pre><code class="hljs bash">[errno 2] error connecting to the cluster</code></pre><p>则是文件权限的问题，可以通过下面命令更改文件夹权限</p><pre><code class="hljs bash">$  sudo chown cephuser:cephuser -R /etc/ceph</code></pre><p>或  加sudo执行ceph </p><h3 id="4-4-部署MGR节点"><a href="#4-4-部署MGR节点" class="headerlink" title="4.4 部署MGR节点"></a>4.4 部署MGR节点</h3><pre><code class="hljs bash">$  ceph-deploy mgr create node_0</code></pre><ul><li><p>检查配置是否成功</p>  <pre><code class="hljs bash">$  ceph -s  cluster:    id:     f564cb33-e2c7-44cb-a645-df9d20824667    health: HEALTH_OK   services:    mon: 1 daemons, quorum node_0 (age 111s)    mgr: node_0(active, since 2s)    osd: 0 osds: 0 up, 0 <span class="hljs-keyword">in</span>   data:    pools:   0 pools, 0 pgs    objects: 0 objects, 0 B    usage:   0 B used, 0 B / 0 B avail    pgs:</code></pre></li></ul><p>可以看到，mgr服务已运行在node_0上。</p><h3 id="4-5-部署OSD节点"><a href="#4-5-部署OSD节点" class="headerlink" title="4.5 部署OSD节点"></a>4.5 部署OSD节点</h3><p>本节只举例在使用磁盘 sdb 作为 OSD 数据盘的情况。</p><ul><li><p>先清除数据盘的格式与文件系统（在所有存储节点上执行）</p>  <pre><code class="hljs bash">$  sudo wipefs -af /dev/sdb</code></pre></li><li><p>分别在三个节点上创建OSD</p>  <pre><code class="hljs bash">$  ceph-deploy osd create --data /dev/sdb node_0$  ceph-deploy osd create --data /dev/sdb node_1 $  ceph-deploy osd create --data /dev/sdb node_2</code></pre></li><li><p>检查配置是否成功</p>  <pre><code class="hljs bash">$  ceph -s  cluster:    id:     f564cb33-e2c7-44cb-a645-df9d20824667    health: HEALTH_OK   services:    mon: 1 daemons, quorum node_0 (age 3m)    mgr: node_0(active, since 95s)    osd: 3 osds: 3 up (since 5s), 3 <span class="hljs-keyword">in</span> (since 5s)   data:    pools:   0 pools, 0 pgs    objects: 0 objects, 0 B    usage:   3.0 GiB used, 27 GiB / 30 GiB avail    pgs:</code></pre></li></ul><p>可以看到，我们成功启动了3个OSD，整个ceph集群获得了30 GiB的存储空间。</p><h3 id="4-6-配置纠删码池"><a href="#4-6-配置纠删码池" class="headerlink" title="4.6 配置纠删码池"></a>4.6 配置纠删码池</h3><p>至此我们的Ceph还没有存储任何的数据。下面我们将配置一个使用纠删码的池。</p><ul><li><p>创建自定义纠删码配置，以2+1的RS code配置为例</p>  <pre><code class="hljs bash">$  ceph osd erasure-code-profile <span class="hljs-built_in">set</span> toy_ec k=2 m=1</code></pre></li><li><p>查看配置</p>  <pre><code class="hljs bash">$  ceph osd erasure-code-profile get toy_eccrush-device-class=crush-failure-domain=hostcrush-root=defaultjerasure-per-chunk-alignment=<span class="hljs-literal">false</span>k=2m=1plugin=jerasuretechnique=reed_sol_vanw=8</code></pre></li><li><p>创建EC池</p>  <pre><code class="hljs bash">$  ceph osd pool create ecpool 16 16 erasure toy_ecpool <span class="hljs-string">&#x27;ecpool&#x27;</span> created</code></pre></li><li><p>启用对象存储应用</p>  <pre><code class="hljs bash">$  ceph osd pool application <span class="hljs-built_in">enable</span> ecpool rgwenabled application <span class="hljs-string">&#x27;rgw&#x27;</span> on pool <span class="hljs-string">&#x27;ecpool&#x27;</span></code></pre></li><li><p>测试ecpool</p>  <pre><code class="hljs bash">$  <span class="hljs-built_in">echo</span> ABCDEFGHI | rados --pool ecpool put NYAN -</code></pre></li><li><p>获取对象</p>  <pre><code class="hljs bash">$  rados --pool ecpool get NYAN -ABCDEFGHI</code></pre></li></ul><p>若正常输出内容，就意味着我们的Ceph基础集群搭建成功了。</p><p>如果需要进一步部署块存储、对象存储、文件存储三大组件，可参考官方文档（见参考资料6）。</p><hr><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><ol><li>Ceph - a     scalable distributed storage system, <a href="https://github.com/ceph/ceph">https://github.com/ceph/ceph</a></li><li>BUG #13137:Ceph-deploy had failed to create cluster in LXC container, <a href="https://tracker.ceph.com/issues/13137">https://tracker.ceph.com/issues/13137</a></li><li>Ceph实战教程(一)让Ceph集群运行起来, <a href="https://blog.51cto.com/happylab/2474943">https://blog.51cto.com/happylab/2474943</a></li><li>Ceph v12.2     Luminous基于ubuntu16.04集群部署, <a href="https://segmentfault.com/a/1190000011581513">https://segmentfault.com/a/1190000011581513</a></li><li>Ceph Deployment - Ceph Documentation, <a href="https://docs.ceph.com/en/nautilus/rados/deployment/">https://docs.ceph.com/en/nautilus/rados/deployment/</a></li><li>Installation (ceph-deploy) — Ceph Documentation, <a href="https://docs.ceph.com/en/nautilus/start/">https://docs.ceph.com/en/nautilus/start/</a></li><li>分布式存储（Ceph）环境搭建指导书Ubuntu 18.04.3, <a href="https://bbs.huaweicloud.com/forum/thread-40539-1-1.html">https://bbs.huaweicloud.com/forum/thread-40539-1-1.html</a> </li></ol><hr><h2 id="附录-Ceph编译安装"><a href="#附录-Ceph编译安装" class="headerlink" title="附录  Ceph编译安装"></a>附录  Ceph编译安装</h2><p>下面我们以在 Ubuntu 18.04 上编译安装Ceph 14.2.13为例，演示如何正确编译Ceph源代码。</p><p>值得一提的是，官方提供的安装脚本有点小问题，若直接按照官方README步骤安装，可能会有很多麻烦。为了避免安装过程中出现错误，我们首先需要配置一点东西。</p><h3 id="1-环境配置"><a href="#1-环境配置" class="headerlink" title="#1 环境配置"></a>#1 环境配置</h3><p>建议读者至少留50 GB的磁盘空闲空间用于编译和安装Ceph。</p><ul><li>配置Ubuntu国内源，见3.2小节。</li><li><p>增加toolchain-r源，为部分高版本的依赖工具链做准备。</p>  <pre><code class="hljs bash">$  wget http://mirror.cs.uchicago.edu/ubuntu-toolchain-r/key.pgp$  sudo apt-key add key.pgp$  sudo vim /etc/apt/sources.list.d/toolchain.list  <span class="hljs-comment"># 添加如下内容</span>deb [arch=amd64 lang=none] http://mirror.cs.uchicago.edu/ubuntu-toolchain-r bionic main$  sudo apt update</code></pre></li><li><p>修改为国内pypi源。修改 ~/.pip/pip.conf ，替换为以下内容。若不存在则新建该文件（夹）。</p>  <pre><code class="hljs ini"><span class="hljs-section">[global]</span><span class="hljs-attr">index-url</span> = https://pypi.doubanio.com/simple<span class="hljs-section">[install]</span><span class="hljs-attr">trusted-host</span> = pypi.doubanio.com</code></pre></li><li><p>安装curl</p>  <pre><code class="hljs bash">$  sudo apt install curl</code></pre></li><li><p>安装nodejs、npm（为ceph-dashboard组件准备）</p></li></ul><p>我们使用nvm来获取较新稳定版本的nodejs和npm。</p><pre><code class="hljs bash">$  curl -o- https://raw.githubusercontent.com/creationix/nvm/master/install.sh | bash$  nvm install --lts  <span class="hljs-comment"># 需重新打开终端，nvm才能生效</span></code></pre><p>检验是否安装成功<br><pre><code class="hljs bash">$  npm -v6.14.8$  node -vv14.15.0</code></pre></p><p>我们更换国内npm源以获得更好的体验</p><pre><code class="hljs bash">$  npm install -g cnpm --registry=https://registry.npm.taobao.org</code></pre><p>检验是否安装成功</p><pre><code class="hljs bash">$  cnpm -vcnpm@6.1.1 (/home/yao/.nvm/versions/node/v14.15.0/lib/node_modules/cnpm/lib/parse_argv.js)npm@6.14.8 (/home/yao/.nvm/versions/node/v14.15.0/lib/node_modules/cnpm/node_modules/npm/lib/npm.js)node@14.15.0 (/home/yao/.nvm/versions/node/v14.15.0/bin/node)npminstall@3.28.0 (/home/yao/.nvm/versions/node/v14.15.0/lib/node_modules/cnpm/node_modules/npminstall/lib/index.js)prefix=/home/yao/.nvm/versions/node/v14.15.0 linux x64 5.4.0-42-generic registry=https://r.npm.taobao.org</code></pre><ul><li><p>安装angular（为ceph-dashboard组件准备）</p>  <pre><code class="hljs bash">$  cnpm install -g @angular/cli$  ng --version</code></pre></li></ul><h3 id="2-编译源码"><a href="#2-编译源码" class="headerlink" title="#2 编译源码"></a>#2 编译源码</h3><ul><li>获取源码。我们选择从中科大镜像站上下载tar包，其中链接末尾的版本号可更改为想要获取的指定版本数字。</li></ul><p>（若使用本地修改后的源代码进行编译可跳过）</p><pre><code class="hljs bash">$  wget http://mirrors.ustc.edu.cn/ceph/tarballs/ceph-14.2.13.tar.gz$  tar -zxvf ceph-14.2.13.tar.gz -C ~ <span class="hljs-comment"># 解压tar包</span></code></pre><ul><li><p>安装依赖软件</p>  <pre><code class="hljs bash">$  <span class="hljs-built_in">cd</span> ~/ceph-14.2.13$  sudo ./install-deps.sh</code></pre></li><li><p>生成makefile</p>  <pre><code class="hljs bash">$  ./do_cmake.sh</code></pre><p>  值得一提的是，默认编译的版本是debug版本，各种调试信息的输出可能会大大降低ceph的性能。若要编译非debug版本，应在调用cmake时传递参数<code>-DCMAKE_BUILD_TYPE=RelWithDebInfo</code></p><p>  我们还可以添加参数<code>-DWITH_MGR_DASHBOARD_FRONTEND=OFF</code>来跳过前端控制台dashboard（减少后面的编译和安装时间）。</p></li><li><p>开始编译</p>  <pre><code class="hljs bash">$  <span class="hljs-built_in">cd</span> build$  sudo make -j4</code></pre><p>  其中j后面的数字代表make多线程编译的线程数（建议设置为CPU物理核心个数）。若编译进程无故中断，重新执行上述make命令以继续即可。注意：有时候线程数过多会导致频繁奔溃，适当减少线程数可能效果会更好。</p></li><li><p>安装到系统</p>  <pre><code class="hljs bash">$  sudo make install$  sudo ldconfig</code></pre></li><li><p>验证是否安装成功</p>  <pre><code class="hljs bash">$  ceph -vceph version 14.2.13 (1778d63e55dbff6cedb071ab7d367f8f52a8699f) nautilus (stable)</code></pre></li></ul><p>如果顺利将显示所安装ceph的版本号。至此，编译安装成功。</p><h3 id="3-备注"><a href="#3-备注" class="headerlink" title="#3 备注"></a>#3 备注</h3><p>截止至本文完成时，Ceph官方的libboost软件仓库部分针对Ubuntu 16.04 (Xenial) 的安装包丢失，因此在Ubuntu 16.04上编译安装Ceph 14.2.13时会遇到依赖环境安装失败的情况（可能暂时无法解决）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Ceph-deploy流程&quot;&gt;&lt;a href=&quot;#Ceph-deploy流程&quot; class=&quot;headerlink&quot; title=&quot;Ceph-deploy流程&quot;&gt;&lt;/a&gt;Ceph-deploy流程&lt;/h1&gt;&lt;p&gt;本文介绍了借助Ceph-deploy工具安装Ceph</summary>
      
    
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/categories/ceph/"/>
    
    <category term="实践" scheme="http://durantthorvalds.top/categories/ceph/%E5%AE%9E%E8%B7%B5/"/>
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title>「核心」Ceph学习三部曲之五:控制先行——Ceph的QoS策略</title>
    <link href="http://durantthorvalds.top/2020/11/15/%E6%8E%A7%E5%88%B6%E5%85%88%E8%A1%8C-Ceph%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0QoS/"/>
    <id>http://durantthorvalds.top/2020/11/15/%E6%8E%A7%E5%88%B6%E5%85%88%E8%A1%8C-Ceph%E5%A6%82%E4%BD%95%E5%AE%9E%E7%8E%B0QoS/</id>
    <published>2020-11-14T16:00:00.000Z</published>
    <updated>2020-12-16T08:32:45.032Z</updated>
    
    <content type="html"><![CDATA[<h1 id="控制先行——Ceph的QoS策略"><a href="#控制先行——Ceph的QoS策略" class="headerlink" title="控制先行——Ceph的QoS策略"></a>控制先行——Ceph的QoS策略</h1><p>Ceph作为开源社区的明星，因为其高可扩展性、高可靠性，受到各大厂商的热烈追捧，并成为OpenStack事实上的默认存储后端。但是人非圣贤，孰能无过。它也同样面临I/O资源分配的问题。为了保证客户能够体验更好的服务，Ceph引入了QoS($Quality of Service$).</p><p>$dmClock$是一种分布式系统的I/O调度算法，它起源于mClock（<a href="https://www.usenix.org/legacy/events/osdi10/tech/full_papers/Gulati.pdf">论文地址</a>）,目前被应用于Ceph中。</p><p>Ceph作为分布式存储系统集大成者，不能像传统QoS实现位置首选的中心节点，必须在每个OSD中实现QoS。下图是整体架构，细节我们在后面会讲到。</p><p><img src="https://www.xsky.com/wp-content/uploads/2017/11/96-2.jpg" alt="img" style="zoom: 67%;" /></p><h2 id="1-dmClock算法原理"><a href="#1-dmClock算法原理" class="headerlink" title="1 dmClock算法原理"></a>1 dmClock算法原理</h2><p>首先我们先了解mClock，这是一种基于时间标签的I/O调度算法，最先被VMware提出了的用于集中式管理的存储系统。它使用了reservation（预留，表示客户端获得的最低I/O资源）、weight（权重，表示客户端占用共享I/O资源的权重，共享I/O指满足预留之后剩余的I/O资源）以及limit（上限，表示用户所能使用的最大I/O）作为一套模板（QoS spec），作用于不同的客户端。下图是其典型应用模型：</p><p><img src="../img/dmClock.png" alt="image-20201216151614635"></p><p>mClock是典型的C/S架构，Client可以驻留在实际的客户端或者服务器端，主要负责下发QoS模板的参数值、收集请求的完成信息等；server为mClock的服务端，实现I/O调度的核心功能。</p><p>其算法流程如下：</p><ol><li>Server为每个客户端设置一套QoS模板参数，包括预留（r），权重（w）和上限（l）三个部分，并依次计算出I/O请求的时间标签，其中预留和上限为绝对时间，权重标签为相对时间。</li><li>服务器分为两个阶段来处理I/O请求：一是Constarint-based，只处理满足预留时间标签的请求；二是Weight-based阶段，处理满足上限的时间标签的权重标签请求。</li><li>服务器先工作也Constraint-based，再转入Weight-based阶段。</li></ol><p>如果用$q_i$表示QoS的模板参数$q_i\in\{r_i,w_i,l_i\}$，$Q^r_i$表示来自第i个客户的第r个请求的时间标签。有如下公式：</p><script type="math/tex; mode=display">Q_i^r=max\{Q^{r-1}_i+1/q_i,current\_time\}</script><p>以第一个请求到达时间作为初始基准标签，后续标签依据预设的模板参数值，对单位时间进行均匀切分计算而来。在Constraint-based阶段 ，各客户端请求被均匀的处理，而在weight-based阶段，则将出现竞争，由于权重标签是相对值，它和真实的时间之差通常会很大，从而出现饥饿现象。因此需要调整旧client的权重标签，以新client的权重时间标签为基准，添加一个补偿值。</p><p>dmClock是mClock 的分布式版本，</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;控制先行——Ceph的QoS策略&quot;&gt;&lt;a href=&quot;#控制先行——Ceph的QoS策略&quot; class=&quot;headerlink&quot; title=&quot;控制先行——Ceph的QoS策略&quot;&gt;&lt;/a&gt;控制先行——Ceph的QoS策略&lt;/h1&gt;&lt;p&gt;Ceph作为开源社区的明星，</summary>
      
    
    
    
    <category term="Ceph" scheme="http://durantthorvalds.top/categories/Ceph/"/>
    
    <category term="理论" scheme="http://durantthorvalds.top/categories/Ceph/%E7%90%86%E8%AE%BA/"/>
    
    
    <category term="QoS" scheme="http://durantthorvalds.top/tags/QoS/"/>
    
  </entry>
  
  <entry>
    <title>「综述」纠删码综述</title>
    <link href="http://durantthorvalds.top/2020/11/15/%E7%BA%A0%E5%88%A0%E7%A0%81%E5%9C%A8%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BA%94%E7%94%A8/"/>
    <id>http://durantthorvalds.top/2020/11/15/%E7%BA%A0%E5%88%A0%E7%A0%81%E5%9C%A8%E5%AD%98%E5%82%A8%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%BA%94%E7%94%A8/</id>
    <published>2020-11-14T16:00:00.000Z</published>
    <updated>2020-12-16T08:34:00.053Z</updated>
    
    <content type="html"><![CDATA[<h1 id="「综述」纠删码理论"><a href="#「综述」纠删码理论" class="headerlink" title="「综述」纠删码理论"></a>「综述」纠删码理论</h1><blockquote><p>2017年更新</p></blockquote><h1 id="1-摘要"><a href="#1-摘要" class="headerlink" title="1 摘要"></a>1 摘要</h1><p>随着云存储和大数据技术的发展，存储系统面临越来越大的考验，主要体现在系统的可靠性方面。纠删码作为存储系统容错的主要方法越来越受到重视．本文介绍了最重要的一些纠删码。</p><p>目前冗余备份机制主要有两种，一种是数据完全备份机制，也就是通常所说的镜像方法，（mirrorred-method），又称为多副本技术，这类方法的优点是不需要专门的编码解码算法，缺点是磁盘利用率很低，适合于存储规模比较小的应用场景。另外一种就是纠删码方法（erasure code）。</p><h1 id="2-术语"><a href="#2-术语" class="headerlink" title="2 术语"></a>2 术语</h1><h2 id="2-1-存储效率和存储冗余度"><a href="#2-1-存储效率和存储冗余度" class="headerlink" title="2.1 存储效率和存储冗余度"></a>2.1 存储效率和存储冗余度</h2><p>​    <strong>存储效率 = 数据空间 /（数据空间 + 校验空间）</strong></p><p>​    对于三副本存储，其效率为1/3。除了存储效率指标，冗余存储系统还要存储冗余度和存储开销。</p><p>​    存储冗余度 = 1/存储效率</p><p>​    存储开销 = 校验空间/数据空间</p><h2 id="2-2-RCW和RMW"><a href="#2-2-RCW和RMW" class="headerlink" title="2.2 RCW和RMW"></a>2.2 RCW和RMW</h2><p>RCW针对写数据较多。Read Construct Write</p><script type="math/tex; mode=display">P_{new} = D1_{new} \oplus D2_{old}\oplus D3_{old}\oplus D4_{old}</script><p>RMW针对读数据较少。Read Modify Write</p><script type="math/tex; mode=display">P_{new} = D1_{old}\oplus P_{old}\oplus D1_{new}</script><p>此外还有COW，覆盖写。</p><h2 id="2-3-节点重构"><a href="#2-3-节点重构" class="headerlink" title="2.3 节点重构"></a>2.3 节点重构</h2><p>如果碰到永久性失效，需要恢复失效数据。根据重构过程中存储系统是否响应用户I/O请求分为在线重构和离线重构。前者是指重构的过程中同时响应IO请求。后者指系统独立进行重构。</p><p>对于容错能力为r的存储系统的平均数据丢失时间(mean time to data loss, $MTTDL$) 与失效数据恢复时间的r次方成反比，即失效数据恢复时间越长，系统节点再次失效的概率就越大，系统的有效性越差。 </p><h2 id="2-4-条带"><a href="#2-4-条带" class="headerlink" title="2.4 条带"></a>2.4 条带</h2><p>条带(stripe) 指 相同纠删码的所有信息的集合，它相当于一个算法的实例。一个存储系统可以看成是很多条带的集合，可以通过条带之间的轮转来实现负载的均衡。另一个类似的概念，是条块(strip)，它是同一条带内包含的元素的个数。</p><p>目前企业中，已经有利用大条带降低校验码比例以实现降低存储开销的先例，但是如何高效的生成大条带并不是容易的，尤其是降低生成大条带的带宽。</p><pre><code>                                                                 表 1 几种纠删码存储集群系统的特征分析</code></pre><div class="table-container"><table><thead><tr><th style="text-align:center">存储方案</th><th style="text-align:center">设计目标</th><th style="text-align:center">纠删码</th><th style="text-align:center">网络</th></tr></thead><tbody><tr><td style="text-align:center">Microsoft Aure Storage</td><td style="text-align:center">可扩展云存储</td><td style="text-align:center">RS码（k=12，r=4）</td><td style="text-align:center">TCP/IP over VL2 Ethernet</td></tr><tr><td style="text-align:center">Google GFS II</td><td style="text-align:center">分布式存储</td><td style="text-align:center">RS码（k=6，r=3）</td><td style="text-align:center">TCP/IP over Ethernet</td></tr><tr><td style="text-align:center">Facebook HDFS-RAID</td><td style="text-align:center">数据仓库</td><td style="text-align:center">RS码（k=10，r=4）</td><td style="text-align:center">TCP/IP</td></tr><tr><td style="text-align:center">Tahoe</td><td style="text-align:center">长期存储</td><td style="text-align:center">Vandermonde RS码</td><td style="text-align:center">TCP/IP</td></tr><tr><td style="text-align:center">Hydrastor</td><td style="text-align:center">内容寻址存储</td><td style="text-align:center">Caucy RS码（k=9，r=3）</td><td style="text-align:center">TCP/IP</td></tr><tr><td style="text-align:center">Cleversafe</td><td style="text-align:center">归档存储</td><td style="text-align:center">Caucy RS码</td><td style="text-align:center">TCP/IP</td></tr><tr><td style="text-align:center">Quantcast</td><td style="text-align:center">分布式存储</td><td style="text-align:center">RS码（k=6，r=3）</td><td style="text-align:center">TCP/IP</td></tr></tbody></table></div><h1 id="3-纠删码理论基础"><a href="#3-纠删码理论基础" class="headerlink" title="3 纠删码理论基础"></a>3 纠删码理论基础</h1><p>纠删码是一种前向纠错码，一般由四元组表示$(k,n,b,k’)$，通常$(k+r,k)$纠删码存储开销为$r/k$, 纠错能力上限为$r \le d_{min}-1$,其中$d_{min}$为纠删码最小列距。</p><p>符合条件的$d_{min}=r+1$编码称为MDS码（Minimal Distance Seperable Code），其能获得Singleton下界而具有最优存储效率$k/(k+r)$.目前业界普遍采用的纠删编码有，RS码，低密度奇偶校验码（LDPC）和阵列编码RAID码。</p><h2 id="3-1-Reed-Solomon编码"><a href="#3-1-Reed-Solomon编码" class="headerlink" title="3.1 Reed Solomon编码"></a>3.1 Reed Solomon编码</h2><p>RS码最多允许r个数据块丢失, 属于横式编码。</p><script type="math/tex; mode=display">\begin{equation}       %开始数学环境\left[                 %左括号  \begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置    a11 & a12 & ... & a1k\\  %第一行元素    a21 & a22 & ... & a2k\\  %第二行元素    \vdots & \vdots &&\vdots \\    ar1 & ar2 & ... & ark  \end{array}\right]                 %右括号\end{equation} × \left[                 %左括号  \begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置  D_1\\D_2\\\vdots\\D_r  \end{array}\right] = \left[                 %左括号  \begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置  P_1\\P_2\\\vdots\\P_r  \end{array}\right]</script><p>其中$[a_{ij}]$为转置冗余矩阵，有$Vandermonde$矩阵以及$Caucy$矩阵。</p><blockquote><p>RS码重构过程有一个至关重要条件，就是未出错信息对应的残余生成矩阵必须满足$GF(2^w)$上可逆条件。</p></blockquote><h3 id="Vandermonde编码"><a href="#Vandermonde编码" class="headerlink" title="Vandermonde编码"></a>Vandermonde编码</h3><blockquote><p>参考文献：<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="ReedIS, Solomon G. Polynomial code sover certain infinite fields[J]. Journal of the Society for Industrial and Applied Mathmetics, 1960, 8(2):300.">[1]</span></a></sup></p></blockquote><script type="math/tex; mode=display">\begin{equation}       %开始数学环境\left[                 %左括号  \begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置    1 & 0 & ... & 0\\  %第一行元素    0 & 1 & ... & 0\\  %第二行元素    \vdots & \vdots &&\vdots \\    0 & 0 & ... & 1 \\    1 & 1 & ... & 1 \\    1 & 2 & ... & k \\    \vdots & \vdots &&\vdots \\    1 & 2^{r-1} & ... & k^{r-1} \\  \end{array}\right]                 %右括号\end{equation} × \left[                 %左括号  \begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置  D_1\\D_2\\\vdots\\D_r  \end{array}\right] = \left[                 %左括号  \begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置  D_1\\D_2\\\vdots\\D_k\\P_1\\P_2\\\vdots\\P_r  \end{array}\right]</script><script type="math/tex; mode=display">where, \ P_i = \sum \limits_{j=1}^{k}j^{i-1}D_j, \ for \ \ 1\le i \le m</script><p>上述即为编码原理，如果需要解码的话，利用存活数据所对应的剩余生成矩阵与存活数据对应的列向量在Galois域$GF(2^w)$进行乘法运算得到失效数据。数据解码算法成立的必要条件是生成矩阵任意k个行向量在域$GF(2^w)$上是线性无关的。</p><p>$vandermonde$矩阵编码收到时间复杂度为$O(kr)$，解码的时间复杂度为$O(r^3)$。</p><p>然而这种编码有很大的缺陷，及分布矩阵A并不具有删除任意m行仍科比的特性，在<sup><a href="#fn_5" id="reffn_5">5</a></sup> 中进行了修正。这里不再赘述。</p><h3 id="Caucy编码"><a href="#Caucy编码" class="headerlink" title="Caucy编码"></a>Caucy编码</h3><blockquote><p>参考文献：<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="Roth RM, LempelA. On MDS code via Caucy matrices[J]. IEEE Transformation Theory, 1989, 35(6):1314-1319.">[2]</span></a></sup>,<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="Plank J, Luo J, Schuman C, et al. A performance evaluation and examination of open-source erasure codign library for storage[C]. Proc of the 7th USENIC Conf on File and Storage Technologies. Berkeley, CA: USENIX Association. 2009:253-266.">[3]</span></a></sup>,<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="Plank J, Xu L. Optimizing Caucy Reed-Solomon codes for fault-tolerance network storage applications. Piscataway, NJ: IEEE, 2006:1 5:Plank J S , Ding Y . Note: Correction to the 1997 tutorial on Reed–Solomon coding[J]. Software Practice &amp; Experience, 2005, 35(2):189-194.">[4]</span></a></sup></p></blockquote><p>Vandermonde矩阵求逆的复杂度为$O(n^3)$，而柯西矩阵为了改善vandermonde的时间复杂度（最后可以优化到$O(n^2)$），①冗余矩阵采用了柯西矩阵，解码时间复杂度优化为$O(r^2)$；②将有限域中的每个数表示为比特位矩阵。注意柯西矩阵并不是唯一的。好的柯西矩阵一般性算法可以在<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="Plank J, Xu L. Optimizing Caucy Reed-Solomon codes for fault-tolerance network storage applications. Piscataway, NJ: IEEE, 2006:1 5:Plank J S , Ding Y . Note: Correction to the 1997 tutorial on Reed–Solomon coding[J]. Software Practice &amp; Experience, 2005, 35(2):189-194.">[4]</span></a></sup>中找到。</p><script type="math/tex; mode=display">\begin{equation}       %开始数学环境\left[                 %左括号  \begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置    1 & 0 & ... & 0\\  %第一行元素    0 & 1 & ... & 0\\  %第二行元素    \vdots & \vdots &&\vdots \\    0 & 0 & ... & 1 \\    \frac{1}{x_1+y_1} & \frac{1}{x_1+y_2} & ... & \frac{1}{x_1+y_k} \\    \frac{1}{x_2+y_1} & \frac{1}{x_2+y_2} & ... & \frac{1}{x_2+y_k} \\    \vdots & \vdots &&\vdots \\    \frac{1}{x_r+y_1} & \frac{1}{x_r+y_2} & ... & \frac{1}{x_r+y_k} \\  \end{array}\right]                 %右括号\end{equation} × \left[                 %左括号  \begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置  D_1\\D_2\\\vdots\\D_r  \end{array}\right] = \left[                 %左括号  \begin{array}{ccc}   %该矩阵一共3列，每一列都居中放置  D_1\\D_2\\\vdots\\D_k\\P_1\\P_2\\\vdots\\P_r  \end{array}\right]</script><p>解码过程类似。</p><p>假设数据块$D_1$失效，为了解码出失效数据分块，所有存活数据对应的 剩余生成矩阵 与所有存活数据对应列向量进行乘法运算，得到原始数据列。</p><blockquote><p>补充 Galois域上的四则运算：</p><p>1、域</p><p>一组元素的集合，以及在集合上的四则运算，构成一个域。其中加法和乘法必须满足交换、结合和分配的规律。加法和乘法具有封闭性，即加法和乘法结果仍然是域中的元素。  </p><p>域中必须有加法单位元和乘法单位元，且每一个元素都有对应的加法逆元和乘法逆元。但不要求域中的 0 有乘法逆元。  </p><p>2、有限域</p><p>仅含有限多个元素的域。因为它由伽罗华所发现，因而又称为伽罗华域。</p><p>所以当我们说伽罗华域的时候，就是指有限域。</p><p>$GF（2^w）$表示含有$2^w$个元素的有限域。因为计算机一个字节由8位，所以最常用的是$GF(2^8)$, </p><p>3、单位元</p><p>Identity Element，也叫幺元，通常使用e来表示单位元。单位元和其他元素结合时，并不会改变那些元素。</p><p>对于二元运算，若$a<em>e=a$，e称为右单位元；若$e</em>a=a$，e称为左单位元，若$a<em>e=e</em>a=a$，则e称为单位元。</p><p>4、逆元</p><p>对于二元运算，若$a<em>b=e$，则a称为b的左逆元素，反之b称为a的右逆元素。若$a</em>b=b*a=e$，则称a为b的逆元，b为a的逆元。</p><p>5、本原多项式</p><p>域中不可约多项式是不能够进行因子分解的多项式， 本原多项式 （primitive polynomial）是一种特殊的不可约多项式。当一个域上的本原多项式确定了，这个域上的运算也就确定了。本原多项式一般通过查表可得，同一个域往往有多个本原多项式。</p><p>通过将域中的元素化为多项式形式，可以将域上的乘法运算转化为普通的多项式乘法再模本原多项式。</p><p><strong>本源多项式</strong></p><p>伽罗华域的元素可以通过该域上的本原多项式生成。通过本原多项式得到的域，其加法单位元都是 0 ，乘法单位元是1。且满足：</p><ul><li>多项式系数全部来自$GF(2)$</li><li>多项式中系数相同的项，可以基于$GF(2)$中的加法进行合并。</li></ul><p>以$GF(2^3)$为例，指数小于3的多项式共8个：$ 0 ， 1， x， x+1， x^2， x^2+1， x^2 + x， x^2+x+1$。其系数刚好就是000,001, 010, 011, 100, 101, 110, 111，是 0 到7这8个数的二进制形式。</p><p>$GF(2^3)$上有不只一个本原多项式，选一个本原多项式$x^3+x+1$，这8个多项式进行四则运算后 $mod (x^3+x+1)$的结果都是8个之中的某一个。因此这8个多项式构成一个有限域。</p><p>对于$GF(2^3)$，取素多项式为$x^3 + x+1$，那么多项式$x^2+x$的乘法逆元就是x+1。系数对应的二进制分别为110和011。此时，我们就认为对应的十进制数6和3互为逆元。</p><p><img src="/img/poly.png" alt="img"></p><blockquote><p>​                                                                        常用的本原多项式</p></blockquote><p><strong>通过本原多项式生成元素</strong></p><p>设$P(x)$是$GF（2^w）$上的某一个本原多项式，$GF（2^w）$的元素产生步骤是：<br><strong>1、给定一个初始集合，{$ { 0,1,x }$}；</strong><br><strong>2、将这个集合中的最后一个元素，即$x$，乘以$x$，如果结果的度大于等于$w$，则将结果$mod   P(x)$后加入集合；</strong><br><strong>3、直到集合有$2^w$个元素，此时最后一个元素乘以$x$再$mod   P(x)$的值等于1。</strong></p><p>例如，$GF(2^4)$含有16个元素，本原多项式为$P(x)=x^4+x+1$，除了 0 、1外，另外14个符号均由本原多项式生成。</p><p>注意到$x^{14}=x^3+1$，此时计算$x^{15}=x^{14}<em>x=(x^3+1)</em>x=x^4+x=1$，生成结束。</p><p><strong>多项式计算</strong></p><p>Galois域上四则运算是基于多项式运算的，对于$GF(2^w)$多项式系数只能取0或1. 合并多项式时，进行的是<strong>异或</strong>运算 比如 $x^4+x^4=x^4$, 多项式减法等于加法运算$x^4-x^4=x^4$。</p><p>乘法和除法：</p><ul><li><ol><li>将被乘数和乘数的二进制转换位对应的多项式表示</li></ol></li><li><ol><li>执行多项式乘法，将得到的结构针对$P(x)$取模</li></ol></li><li><ol><li>将2 得到的结果转化为对应的二进制表示</li></ol></li></ul><p>例如 </p><script type="math/tex; mode=display">3×7 = (x+1)(x^2+x+1)=x^3+x^2+x+x^2+x+1=x^3+1=9\\</script><p>或者直接利用本原多项式：</p><script type="math/tex; mode=display">3×7=x^4.x^{10}=x^{14}=9</script><p><strong>查表法</strong></p><p>如果以$gflog$和$gfilog$分别表示$GF(2^w)$中对数运算及其逆运算，由对数运算的性质：</p><script type="math/tex; mode=display">MN = gfilog(gflog(MN)) = gfilog(gflog(M)+gflog(N)) mod (2^w-1)\\M/N = gfilog(gflog(M/N)) = gfilog(gflog(M)-gflog(N)) mod (2^w-1)\\</script><p>注意：多项式 0 ，是无法用生成元生成的。g^0等于多项式1，而不是 0 。</p><p>  根据上文的$GF(2^4)$的元素表示，生成gflog表和gfilog表如下：</p><p><img src="/img/gflog.png" alt="img"></p><p>例如：</p><script type="math/tex; mode=display">3×7 = gfilog(gflog(3)+gflog(7)) = gfilog(4+10)= 9 \\3/7 = gfilog(gflog(3)-gflog(7)) = gfilog(4-10+15)= gfilog(9)=10 \\</script></blockquote><h2 id="3-2-LRC码和Pyramid码"><a href="#3-2-LRC码和Pyramid码" class="headerlink" title="3.2 LRC码和Pyramid码"></a>3.2 LRC码和Pyramid码</h2><h1 id=""><a href="#" class="headerlink" title=" "></a> </h1><hr><p><strong><em>\</em>主要文献参考列表**</strong></p><p>[1] 罗象宏，舒继武. 存储系统中的纠删码研究综述[J].计算机研究与发展, 49(1),2012:1-11.</p><p>[2] ReedIS, Solomon G. Polynomial code sover certain infinite fields[J]. Journal of the Society for Industrial and Applied Mathmetics, 1960, 8(2):300. </p><p>[3] Roth RM, LempelA. On MDS code via Caucy matrices[J]. IEEE Transformation Theory, 1989, 35(6):1314-1319.</p><p>[4] Plank J, Luo J, Schuman C, et al. A performance evaluation and examination of open-source erasure codign library for storage[C]. Proc of the 7th USENIC Conf on File and Storage Technologies. Berkeley, CA: USENIX Association. 2009:253-266.</p><p>[5] Plank J, Xu L. Optimizing Caucy Reed-Solomon codes for fault-tolerance network storage applications. Piscataway, NJ: IEEE, 2006:1.</p><p>[6] Blaum M, Farrell P, Tilborg H. Array Codes[M]. Amsterdam, Netherlands: Elsevier Science BV,1998.</p><p>[7] Blaum M, Brady J, Bruck J, et al. EVENODD: An efficient scheme for toleranting double disk failures in RAID architectures[J]. IEEE Transon Computer, 1995, 44(2):192-202.</p><p>[8] Corbett P, English B, Goel A, et al. Row - diagnoal refundant for doubled disk failure correction [C]. Proc of the 3rd USENIC Conf on File and Storage Technologies. Berkeley, CA: USENIX Association. 2004:2-15.</p><p>[9]Pamies Juarez L, Datta A, Oggier F. <a href="http://www.researchgate.net/publication/230569691_RapidRAID_Pipelined_Erasure_Codes_for_Fast_Data_Archival_in_DistributedStorage_Systems?ev=auth_pub">RapidRAID: Pipelined Erasure Codes for Fast Data Archival in Distributed Storage Systems</a>// Proceedings of the 2013 IEEE INFOCOM. Turin, Italy, 2013:1294 - 1302.</p><p>[10]Huang C , Simitci H , Xu Y , et al. Erasure coding in windows azure storage[C]// Proceedings of the 2012 USENIX conference on Annual Technical Conference. USENIX Association, 2012.</p><p>[11]Huang C , Chen M , Li J . Pyramid Codes: Flexible Schemes to Trade Space for Access Efficiency in Reliable Data Storage Systems[C]// IEEE International Symposium on Network Computing &amp; Applications. IEEE, 2007.</p><p>[12]Sathiamoorthy M , Asteris M , Papailiopoulos D , et al. XORing Elephants: Novel Erasure Codes for Big Data[J]. 2013.</p><p>[13]王意洁, 许方亮, 裴晓强. 分布式存储中的纠删码容错技术研究[J]. 计算机学报, 2017(01):236-255.</p><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>ReedIS, Solomon G. Polynomial code sover certain infinite fields[J]. Journal of the Society for Industrial and Applied Mathmetics, 1960, 8(2):300.<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>Roth RM, LempelA. On MDS code via Caucy matrices[J]. IEEE Transformation Theory, 1989, 35(6):1314-1319.<a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>Plank J, Luo J, Schuman C, et al. A performance evaluation and examination of open-source erasure codign library for storage[C]. Proc of the 7th USENIC Conf on File and Storage Technologies. Berkeley, CA: USENIX Association. 2009:253-266.<a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span>Plank J, Xu L. Optimizing Caucy Reed-Solomon codes for fault-tolerance network storage applications. Piscataway, NJ: IEEE, 2006:1<br><sup><a href="#fn_ 5" id="reffn_ 5"> 5</a></sup>:Plank J S , Ding Y . Note: Correction to the 1997 tutorial on Reed–Solomon coding[J]. Software Practice &amp; Experience, 2005, 35(2):189-194.<a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;「综述」纠删码理论&quot;&gt;&lt;a href=&quot;#「综述」纠删码理论&quot; class=&quot;headerlink&quot; title=&quot;「综述」纠删码理论&quot;&gt;&lt;/a&gt;「综述」纠删码理论&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;2017年更新&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h1</summary>
      
    
    
    
    <category term="综述" scheme="http://durantthorvalds.top/categories/%E7%BB%BC%E8%BF%B0/"/>
    
    
    <category term="纠删码" scheme="http://durantthorvalds.top/tags/%E7%BA%A0%E5%88%A0%E7%A0%81/"/>
    
  </entry>
  
  <entry>
    <title>设计类问题如何解决</title>
    <link href="http://durantthorvalds.top/2020/11/05/2020-11-04-designing-ds/"/>
    <id>http://durantthorvalds.top/2020/11/05/2020-11-04-designing-ds/</id>
    <published>2020-11-04T16:00:00.000Z</published>
    <updated>2020-11-22T04:08:16.410Z</updated>
    
    <content type="html"><![CDATA[<h1 id="设计类题目如何解决"><a href="#设计类题目如何解决" class="headerlink" title="设计类题目如何解决"></a>设计类题目如何解决</h1><blockquote><p>设计类题目占比并不大，题目难度也不大。但是一旦碰到了，我们也要直到如何解决！</p><p>设计类问题会使我们对部分数据结构的内在实现由更深入的了解，类似于阅读java源码。</p></blockquote><h4 id="707-设计链表"><a href="#707-设计链表" class="headerlink" title="707. 设计链表"></a><a href="https://leetcode-cn.com/problems/design-linked-list/">707. 设计链表</a></h4><h4 id="622-设计循环队列"><a href="#622-设计循环队列" class="headerlink" title="622. 设计循环队列"></a><a href="https://leetcode-cn.com/problems/design-circular-queue/">622. 设计循环队列</a></h4><p><a href="https://leetcode-cn.com/problems/implement-trie-prefix-tree/">208. 实现 Trie (前缀树)</a> （※）</p><p><a href="https://leetcode-cn.com/problems/time-based-key-value-store/">981. 基于时间的键值存储 - 力扣（LeetCode）</a></p><p><a href="https://leetcode-cn.com/problems/lfu-cache/">460. LFU缓存 - 力扣（LeetCode）</a></p><h4 id="341-扁平化嵌套列表迭代器"><a href="#341-扁平化嵌套列表迭代器" class="headerlink" title="341. 扁平化嵌套列表迭代器"></a><a href="https://leetcode-cn.com/problems/flatten-nested-list-iterator/">341. 扁平化嵌套列表迭代器</a></h4><h4 id="385-迷你语法分析器"><a href="#385-迷你语法分析器" class="headerlink" title="385. 迷你语法分析器"></a><a href="https://leetcode-cn.com/problems/mini-parser/">385. 迷你语法分析器</a></h4><h4 id="1381-设计一个支持增量操作的栈"><a href="#1381-设计一个支持增量操作的栈" class="headerlink" title="1381. 设计一个支持增量操作的栈"></a><a href="https://leetcode-cn.com/problems/design-a-stack-with-increment-operation/">1381. 设计一个支持增量操作的栈</a></h4><p><strong>Hard</strong> </p><p>或许你还没见过hard的设计类问题，嘿嘿</p><h4 id="1206-设计跳表"><a href="#1206-设计跳表" class="headerlink" title="1206. 设计跳表"></a><a href="https://leetcode-cn.com/problems/design-skiplist/">1206. 设计跳表</a></h4><hr>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;设计类题目如何解决&quot;&gt;&lt;a href=&quot;#设计类题目如何解决&quot; class=&quot;headerlink&quot; title=&quot;设计类题目如何解决&quot;&gt;&lt;/a&gt;设计类题目如何解决&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;设计类题目占比并不大，题目难度也不大。但是一旦碰到了，我们</summary>
      
    
    
    
    <category term="算法" scheme="http://durantthorvalds.top/categories/%E7%AE%97%E6%B3%95/"/>
    
    
    <category term="设计" scheme="http://durantthorvalds.top/tags/%E8%AE%BE%E8%AE%A1/"/>
    
    <category term="数据结构" scheme="http://durantthorvalds.top/tags/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/"/>
    
  </entry>
  
  <entry>
    <title>【参考】Ceph-Mon 详解</title>
    <link href="http://durantthorvalds.top/2020/11/03/2020113-Ceph-Mon-%E8%AF%A6%E8%A7%A3/"/>
    <id>http://durantthorvalds.top/2020/11/03/2020113-Ceph-Mon-%E8%AF%A6%E8%A7%A3/</id>
    <published>2020-11-02T16:00:00.000Z</published>
    <updated>2020-12-15T11:38:17.234Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Ceph-Monitor剖析"><a href="#Ceph-Monitor剖析" class="headerlink" title="Ceph Monitor剖析"></a>Ceph Monitor剖析</h1><blockquote><p>参考：<a href="http://docs.ceph.org.cn/rados/configuration/mon-config-ref/#data">http://docs.ceph.org.cn/rados/configuration/mon-config-ref/#data</a></p></blockquote><p>监视器们维护着集群运行图的“主副本”，就是说客户端连到一个监视器并获取当前运行图就能确定所有监视器、 OSD 和元数据服务器的位置。 Ceph 客户端读写 OSD 或元数据服务器前，必须先连到一个监视器，靠当前集群运行图的副本和 CRUSH 算法，客户端能计算出任何对象的位置，故此客户端有能力直接连到 OSD ，这对 Ceph 的高伸缩性、高性能来说非常重要。更多信息见<a href="http://docs.ceph.org.cn/architecture#scalability-and-high-availability">伸缩性和高可用性</a>。</p><p>监视器的主要角色是<strong>维护集群运行图的主副本，它也提供认证和日志记录服务</strong>。 Ceph 监视器们把监视器服务的所有更改写入一个单独的 Paxos 例程，然后 Paxos 以键/值方式存储所有变更以实现高度一致性。同步期间， Ceph 监视器能查询集群运行图的近期版本，它们通过操作键/值存储快照和迭代器（用 leveldb ）来进行存储级同步。</p><p><img src="\img\ceph-mon.jpg" alt="img"></p><h3 id="集群运行图"><a href="#集群运行图" class="headerlink" title="集群运行图"></a>集群运行图</h3><p>集群运行图是多个图的组合，包括监视器图、 OSD 图、归置组图和元数据服务器图。集群运行图追踪几个重要事件：哪些进程在集群里（ <code>in</code> ）；哪些进程在集群里（ <code>in</code> ）是 <code>up</code> 且在运行、或 <code>down</code> ；归置组状态是 <code>active</code> 或 <code>inactive</code> 、 <code>clean</code> 或其他状态；和其他反映当前集群状态的信息，像总存储容量、和使用量。</p><p>当集群状态有明显变更时，如一 OSD 挂了、一归置组降级了等等，集群运行图会被更新以反映集群当前状态。另外，监视器也维护着集群的主要状态历史。监视器图、 OSD 图、归置组图和元数据服务器图各自维护着它们的运行图版本。我们把各图的版本称为一个 epoch 。</p><p>运营集群时，跟踪这些状态是系统管理任务的重要部分。详情见<a href="http://docs.ceph.org.cn/rados/operations/monitoring">监控集群</a>和<a href="http://docs.ceph.org.cn/rados/operations/monitoring-osd-pg">监控 OSD 和归置组</a>。</p><h3 id="监视器法定人数"><a href="#监视器法定人数" class="headerlink" title="监视器法定人数"></a>监视器法定人数</h3><p>本文入门部分提供了一个简陋的 <a href="http://docs.ceph.org.cn/start/quick-start/#add-a-configuration-file">Ceph 配置文件</a>，它提供了一个监视器用于测试。只用一个监视器集群可以良好地运行，然而<strong>单监视器是一个单故障点</strong>，生产集群要实现高可用性的话得配置多个监视器，这样单个监视器的失效才<strong>不会</strong>影响整个集群。</p><p>集群用多个监视器实现高可用性时，多个监视器用 <a href="http://en.wikipedia.org/wiki/Paxos_(computer_science">Paxos</a>) 算法对主集群运行图达成一致，这里的一致要求大多数监视器都在运行且够成法定人数（如 1 个、 3 之 2 在运行、 5 之 3 、 6 之 4 等等）。</p><h3 id="一致性"><a href="#一致性" class="headerlink" title="一致性"></a>一致性</h3><p>你把监视器加进 Ceph 配置文件时，得注意一些架构问题， Ceph 发现集群内的其他监视器时对其有着<strong>严格的一致性要求</strong>。尽管如此， Ceph 客户端和其他 Ceph 守护进程用配置文件发现监视器，监视器却用监视器图（ monmap ）相互发现而非配置文件。</p><p>一个监视器发现集群内的其他监视器时总是参考 monmap 的本地副本，用 monmap 而非 Ceph 配置文件避免了可能损坏集群的错误（如 <code>ceph.conf</code> 中指定地址或端口的拼写错误）。正因为监视器把 monmap 用于发现、并共享于客户端和其他 Ceph 守护进程间， <strong>monmap可严格地保证监视器的一致性是可靠的</strong>。</p><p>严格的一致性也适用于 monmap 的更新，因为关于监视器的任何更新、关于 monmap 的变更都是通过称为 <a href="http://en.wikipedia.org/wiki/Paxos_(computer_science">Paxos</a>) 的分布式一致性算法传递的。监视器们必须就 monmap 的每次更新达成一致，以确保法定人数里的每个监视器 monmap 版本相同，如增加、删除一个监视器。 monmap 的更新是增量的，所以监视器们都有最新的一致版本，以及一系列之前版本。历史版本的存在允许一个落后的监视器跟上集群当前状态。</p><p>如果监视器通过配置文件而非 monmap 相互发现，这会引进其他风险，因为 Ceph 配置文件不是自动更新并分发的，监视器有可能不小心用了较老的配置文件，以致于不认识某监视器、放弃法定人数、或者产生一种 <a href="http://en.wikipedia.org/wiki/Paxos_(computer_science">Paxos</a>) 不能确定当前系统状态的情形。</p><h3 id="初始化监视器"><a href="#初始化监视器" class="headerlink" title="初始化监视器"></a>初始化监视器</h3><p>在大多数配置和部署案例中，部署 Ceph 的工具可以帮你生成一个监视器图来初始化监视器（如 <code>ceph-deploy</code> 等），一个监视器需要 4 个选项：</p><ul><li><strong>文件系统标识符：</strong> <code>fsid</code> 是对象存储的唯一标识符。因为你可以在一套硬件上运行多个集群，所以在初始化监视器时必须指定对象存储的唯一标识符。部署工具通常可替你完成（如 <code>ceph-deploy</code> 会调用类似 <code>uuidgen</code> 的程序），但是你也可以手动指定 <code>fsid</code> 。</li><li><strong>监视器标识符：</strong> 监视器标识符是分配给集群内各监视器的唯一 ID ，它是一个字母数字组合，为方便起见，标识符通常以字母顺序结尾（如 <code>a</code> 、 <code>b</code> 等等），可以设置于 Ceph 配置文件（如 <code>[mon.a]</code> 、 <code>[mon.b]</code> 等等）、部署工具、或 <code>ceph</code> 命令行工具。</li><li><strong>密钥：</strong> 监视器必须有密钥。像 <code>ceph-deploy</code> 这样的部署工具通常会自动生成，也可以手动完成。见<a href="http://docs.ceph.org.cn/rados/operations/authentication#monitor-keyrings">监视器密钥环</a>。</li></ul><p>关于初始化的具体信息见<a href="http://docs.ceph.org.cn/dev/mon-bootstrap">初始化监视器</a>。</p><h2 id="监视器的配置"><a href="#监视器的配置" class="headerlink" title="监视器的配置"></a>监视器的配置</h2><p>要把配置应用到整个集群，把它们放到 <code>[global]</code> 下；要用于所有监视器，置于 <code>[mon]</code> 下；要用于某监视器，指定监视器例程，如 <code>[mon.a]</code> ）。按惯例，监视器例程用字母命名。</p><pre><code class="hljs json">[global][mon][mon.a][mon.b][mon.c]</code></pre><h3 id="最小配置"><a href="#最小配置" class="headerlink" title="最小配置"></a>最小配置</h3><p>Ceph 监视器的最简配置必须包括一主机名及其监视器地址，这些配置可置于 <code>[mon]</code> 下或某个监视器下。</p><pre><code class="hljs angelscript">[mon]        mon host = hostname1,hostname2,hostname3        mon addr = <span class="hljs-number">10.0</span><span class="hljs-number">.0</span><span class="hljs-number">.10</span>:<span class="hljs-number">6789</span>,<span class="hljs-number">10.0</span><span class="hljs-number">.0</span><span class="hljs-number">.11</span>:<span class="hljs-number">6789</span>,<span class="hljs-number">10.0</span><span class="hljs-number">.0</span><span class="hljs-number">.12</span>:<span class="hljs-number">6789</span>[mon.a]        host = hostname1        mon addr = <span class="hljs-number">10.0</span><span class="hljs-number">.0</span><span class="hljs-number">.10</span>:<span class="hljs-number">6789</span></code></pre><p>详情见<a href="http://docs.ceph.org.cn/rados/configuration/network-config-ref">网络配置参考</a>。</p><p>一旦部署了 Ceph 集群，监视器 IP 地址<strong>不应该</strong>更改。然而，如果你决意要改，必须严格按照<a href="http://docs.ceph.org.cn/rados/operations/add-or-rm-mons#changing-a-monitor-s-ip-address">更改监视器 IP 地址</a>来改。</p><h3 id="集群-ID"><a href="#集群-ID" class="headerlink" title="集群 ID"></a>集群 ID</h3><p>每个 Ceph 存储集群都有一个唯一标识符（ <code>fsid</code> ）。如果指定了，它应该出现在配置文件的 <code>[global]</code> 段下。部署工具通常会生成 <code>fsid</code> 并存于监视器图，所以不一定会写入配置文件， <code>fsid</code> 使得在一套硬件上运行多个集群成为可能。</p><pre><code class="hljs ebnf"><span class="hljs-attribute">fsid</span></code></pre><div class="table-container"><table><thead><tr><th style="text-align:left">描述:</th><th>集群 ID ，一集群一个。</th></tr></thead><tbody><tr><td style="text-align:left">类型:</td><td>UUID</td></tr><tr><td style="text-align:left">是否必需:</td><td>Yes.</td></tr><tr><td style="text-align:left">默认值:</td><td>无。若未指定，部署工具会生成。</td></tr></tbody></table></div><h3 id="初始成员"><a href="#初始成员" class="headerlink" title="初始成员"></a>初始成员</h3><p>我们建议在生产环境下最少部署 3 个监视器，以确保高可用性。运行多个监视器时，你可以指定为形成法定人数成员所需的初始监视器，这能减小集群上线时间。</p><pre><code class="hljs properties"><span class="hljs-attr">[mon]</span>        <span class="hljs-attr">mon</span> <span class="hljs-string">initial members = a,b,c</span><span class="hljs-attr">mon</span> <span class="hljs-string">initial members</span></code></pre><div class="table-container"><table><thead><tr><th style="text-align:left">描述:</th><th>集群启动时初始监视器的 ID ，若指定， Ceph 需要奇数个监视器来确定最初法定人数（如 3 ）。</th></tr></thead><tbody><tr><td style="text-align:left">类型:</td><td>String</td></tr><tr><td style="text-align:left">默认值:</td><td>None</td></tr></tbody></table></div><div class="note note-priamry">            <p>集群内的<em>大多数</em>监视器必须能互通以建立法定人数，你可以用此选项减小初始监视器数量来形成。</p>          </div>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Ceph-Monitor剖析&quot;&gt;&lt;a href=&quot;#Ceph-Monitor剖析&quot; class=&quot;headerlink&quot; title=&quot;Ceph Monitor剖析&quot;&gt;&lt;/a&gt;Ceph Monitor剖析&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;参考：&lt;a hre</summary>
      
    
    
    
    <category term="ceph" scheme="http://durantthorvalds.top/categories/ceph/"/>
    
    <category term="分布式存储" scheme="http://durantthorvalds.top/categories/ceph/%E5%88%86%E5%B8%83%E5%BC%8F%E5%AD%98%E5%82%A8/"/>
    
    
    <category term="系统架构" scheme="http://durantthorvalds.top/tags/%E7%B3%BB%E7%BB%9F%E6%9E%B6%E6%9E%84/"/>
    
    <category term="ceph" scheme="http://durantthorvalds.top/tags/ceph/"/>
    
  </entry>
  
  <entry>
    <title>Shell 从入门到放弃</title>
    <link href="http://durantthorvalds.top/2020/10/26/Shell/"/>
    <id>http://durantthorvalds.top/2020/10/26/Shell/</id>
    <published>2020-10-25T16:00:00.000Z</published>
    <updated>2020-11-03T08:34:18.883Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Shell-从入门到放弃"><a href="#Shell-从入门到放弃" class="headerlink" title="Shell 从入门到放弃"></a>Shell 从入门到放弃</h1><blockquote><p>Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。</p><p>Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。</p><p>Ken Thompson 的 sh 是第一种 Unix Shell，Windows Explorer 是一个典型的图形界面 Shell。</p></blockquote><p>Shell 编程跟 JavaScript、php 编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。</p><p>Linux 的 Shell 种类众多，常见的有：</p><ul><li>Bourne Shell（/usr/bin/sh或/bin/sh）</li><li>Bourne Again Shell（/bin/bash）</li><li>C Shell（/usr/bin/csh）</li><li>K Shell（/usr/bin/ksh）</li><li>Shell for Root（/sbin/sh）</li><li>……</li></ul><p>本教程关注的是 Bash，也就是 Bourne Again Shell，由于易用和免费，Bash 在日常工作中被广泛使用。同时，Bash 也是大多数Linux 系统默认的 Shell。</p><p>在一般情况下，人们并不区分 Bourne Shell 和 Bourne Again Shell，所以，像 <strong>#!/bin/sh</strong>，它同样也可以改为 <strong>#!/bin/bash</strong>。</p><p><strong>#!</strong> 告诉系统其后路径所指定的程序即是解释此脚本文件的 Shell 程序。</p><h3 id="第一个shell脚本"><a href="#第一个shell脚本" class="headerlink" title="第一个shell脚本"></a>第一个shell脚本</h3><p>打开文本编辑器(可以使用 vi/vim 命令来创建文件)，新建一个文件 test.sh，扩展名为 sh（sh代表shell），扩展名并不影响脚本执行，见名知意就好，如果你用 php 写 shell 脚本，扩展名就用 php 好了。</p><p>输入一些代码，第一行一般是这样：</p><h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span>echo &quot;Hello World !&quot;</code></pre><p><strong>#!</strong> 是一个约定的标记，它告诉系统这个脚本需要什么解释器来执行，即使用哪一种 Shell。</p><p>echo 命令用于向窗口输出文本。</p><h3 id="运行-Shell-脚本有两种方法："><a href="#运行-Shell-脚本有两种方法：" class="headerlink" title="运行 Shell 脚本有两种方法："></a>运行 Shell 脚本有两种方法：</h3><p><strong>1、作为可执行程序</strong></p><p>将上面的代码保存为 test.sh，并 cd 到相应目录：</p><pre><code class="hljs cmake">chmod +x ./<span class="hljs-keyword">test</span>.sh  <span class="hljs-comment">#使脚本具有执行权限</span>./<span class="hljs-keyword">test</span>.sh  <span class="hljs-comment">#执行脚本</span></code></pre><p>注意，一定要写成 <strong>./test.sh</strong>，而不是 <strong>test.sh</strong>，运行其它二进制的程序也一样，直接写 test.sh，linux 系统会去 PATH 里寻找有没有叫 test.sh 的，而只有 /bin, /sbin, /usr/bin，/usr/sbin 等在 PATH 里，你的当前目录通常不在 PATH 里，所以写成 test.sh 是会找不到命令的，要用 ./test.sh 告诉系统说，就在当前目录找。</p><p><strong>2、作为解释器参数</strong></p><p>这种运行方式是，直接运行解释器，其参数就是 shell 脚本的文件名，如：</p><pre><code class="hljs awk"><span class="hljs-regexp">/bin/</span>sh test.sh<span class="hljs-regexp">/bin/</span>php test.php</code></pre><p>这种方式运行的脚本，不需要在第一行指定解释器信息，写了也没用。</p><p>注意，<strong>变量名和等号之间不能有空格</strong>，这可能和你熟悉的所有编程语言都不一样。同时，变量名的命名须遵循如下规则：</p><ul><li>命名只能使用英文字母，数字和下划线，首个字符不能以数字开头。</li><li>中间不能有空格，可以使用下划线（_）。</li><li>不能使用标点符号。</li><li>不能使用bash里的关键字（可用help命令查看保留关键字）。</li></ul><h3 id="使用变量"><a href="#使用变量" class="headerlink" title="使用变量"></a>使用变量</h3><p>使用一个定义过的变量，只要在变量名前面加美元符号即可，如：</p><pre><code class="hljs bash">your_name=<span class="hljs-string">&quot;qinjx&quot;</span><span class="hljs-built_in">echo</span> <span class="hljs-variable">$your_name</span><span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;your_name&#125;</span></code></pre><h3 id="只读变量"><a href="#只读变量" class="headerlink" title="只读变量"></a>只读变量</h3><p>使用 readonly 命令可以将变量定义为只读变量，只读变量的值不能被改变。</p><p>下面的例子尝试更改只读变量，结果报错：</p><pre><code class="hljs shell"><span class="hljs-meta">#</span><span class="bash">!/bin/bash</span>myUrl=&quot;https://www.google.com&quot;readonly myUrlmyUrl=&quot;https://www.runoob.com&quot;</code></pre><h3 id="删除变量"><a href="#删除变量" class="headerlink" title="删除变量"></a>删除变量</h3><p>使用 unset 命令可以删除变量。语法：</p><pre><code class="hljs bash"><span class="hljs-built_in">unset</span> variable_name</code></pre><p>变量被删除后不能再次使用。unset 命令不能删除只读变量。</p><p><strong>实例</strong></p><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/sh</span>myUrl=<span class="hljs-string">&quot;https://www.runoob.com&quot;</span><span class="hljs-built_in">unset</span> myUrl<span class="hljs-built_in">echo</span> <span class="hljs-variable">$myUrl</span></code></pre><h3 id="变量类型"><a href="#变量类型" class="headerlink" title="变量类型"></a>变量类型</h3><p>运行shell时，会同时存在三种变量：</p><ul><li><strong>1) 局部变量</strong> 局部变量在脚本或命令中定义，仅在当前shell实例中有效，其他shell启动的程序不能访问局部变量。</li><li><strong>2) 环境变量</strong> 所有的程序，包括shell启动的程序，都能访问环境变量，有些程序需要环境变量来保证其正常运行。必要的时候shell脚本也可以定义环境变量。</li><li><strong>3) shell变量</strong> shell变量是由shell程序设置的特殊变量。shell变量中有一部分是环境变量，有一部分是局部变量，这些变量保证了shell的正常运行</li></ul><h1 id="Shell-字符串"><a href="#Shell-字符串" class="headerlink" title="Shell 字符串"></a>Shell 字符串</h1><p>字符串是shell编程中最常用最有用的数据类型（除了数字和字符串，也没啥其它类型好用了），字符串可以用单引号，也可以用双引号，也可以不用引号。</p><h3 id="单引号"><a href="#单引号" class="headerlink" title="单引号"></a>单引号</h3><pre><code class="hljs ini"><span class="hljs-attr">str</span>=<span class="hljs-string">&#x27;this is a string&#x27;</span></code></pre><p>单引号字符串的限制：</p><ul><li>单引号里的任何字符都会原样输出，单引号字符串中的变量是无效的；</li><li>单引号字串中不能出现单独一个的单引号（对单引号使用转义符后也不行），但可成对出现，作为字符串拼接使用。</li></ul><h3 id="双引号"><a href="#双引号" class="headerlink" title="双引号"></a>双引号</h3><pre><code class="hljs bash">your_name=<span class="hljs-string">&#x27;runoob&#x27;</span>str=<span class="hljs-string">&quot;Hello, I know you are \&quot;<span class="hljs-variable">$your_name</span>\&quot;! \n&quot;</span><span class="hljs-built_in">echo</span> -e <span class="hljs-variable">$str</span></code></pre><h3 id="拼接字符串"><a href="#拼接字符串" class="headerlink" title="拼接字符串"></a>拼接字符串</h3><pre><code class="hljs bash">your_name=<span class="hljs-string">&quot;runoob&quot;</span><span class="hljs-comment"># 使用双引号拼接</span>greeting=<span class="hljs-string">&quot;hello, &quot;</span><span class="hljs-variable">$your_name</span><span class="hljs-string">&quot; !&quot;</span>greeting_1=<span class="hljs-string">&quot;hello, <span class="hljs-variable">$&#123;your_name&#125;</span> !&quot;</span><span class="hljs-built_in">echo</span> <span class="hljs-variable">$greeting</span>  <span class="hljs-variable">$greeting_1</span></code></pre><h3 id="获取字符串长度"><a href="#获取字符串长度" class="headerlink" title="获取字符串长度"></a>获取字符串长度</h3><pre><code class="hljs bash">string=<span class="hljs-string">&quot;abcd&quot;</span><span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;#string&#125;</span> <span class="hljs-comment">#输出 4</span></code></pre><h3 id="提取子字符串"><a href="#提取子字符串" class="headerlink" title="提取子字符串"></a>提取子字符串</h3><p>以下实例从字符串第 <strong>2</strong> 个字符开始截取 <strong>4</strong> 个字符：</p><pre><code class="hljs bash">string=<span class="hljs-string">&quot;runoob is a great site&quot;</span><span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;string:1:4&#125;</span> <span class="hljs-comment"># 输出 unoo</span></code></pre><h3 id="查找子字符串"><a href="#查找子字符串" class="headerlink" title="查找子字符串"></a>查找子字符串</h3><p>查找字符 <strong>i</strong> 或 <strong>o</strong> 的位置(哪个字母先出现就计算哪个)：</p><pre><code class="hljs bash">string=<span class="hljs-string">&quot;runoob is a great site&quot;</span><span class="hljs-built_in">echo</span> `expr index <span class="hljs-string">&quot;<span class="hljs-variable">$string</span>&quot;</span> io`  <span class="hljs-comment"># 输出 4</span></code></pre><p><strong>注意：</strong> 以上脚本中 <strong>`</strong> 是反引号，而不是单引号 <strong>‘</strong>，不要看错了哦。</p><h2 id="Shell-数组"><a href="#Shell-数组" class="headerlink" title="Shell 数组"></a>Shell 数组</h2><p>bash支持一维数组（不支持多维数组），并且没有限定数组的大小。</p><p>类似于 C 语言，数组元素的下标由 0 开始编号。获取数组中的元素要利用下标，下标可以是整数或算术表达式，其值应大于或等于 0。</p><h3 id="定义数组"><a href="#定义数组" class="headerlink" title="定义数组"></a>定义数组</h3><p>在 Shell 中，用括号来表示数组，数组元素用”空格”符号分割开。定义数组的一般形式为：</p><pre><code class="hljs angelscript">数组名=(值<span class="hljs-number">1</span> 值<span class="hljs-number">2</span> ... 值n)</code></pre><p>例如：</p><pre><code class="hljs apache"><span class="hljs-attribute">array_name</span>=(value<span class="hljs-number">0</span> value<span class="hljs-number">1</span> value<span class="hljs-number">2</span> value<span class="hljs-number">3</span>)</code></pre><p>或者</p><pre><code class="hljs ceylon">array<span class="hljs-number">_n</span>ame=(<span class="hljs-keyword">value</span><span class="hljs-number">0</span><span class="hljs-keyword">value</span><span class="hljs-number">1</span><span class="hljs-keyword">value</span><span class="hljs-number">2</span><span class="hljs-keyword">value</span><span class="hljs-number">3</span>)</code></pre><p>还可以单独定义数组的各个分量：</p><pre><code class="hljs angelscript"><span class="hljs-built_in">array</span>_name[<span class="hljs-number">0</span>]=value0<span class="hljs-built_in">array</span>_name[<span class="hljs-number">1</span>]=value1<span class="hljs-built_in">array</span>_name[n]=valuen</code></pre><p>可以不使用连续的下标，而且下标的范围没有限制。</p><h3 id="读取数组"><a href="#读取数组" class="headerlink" title="读取数组"></a>读取数组</h3><p>读取数组元素值的一般格式是：</p><pre><code class="hljs awk"><span class="hljs-variable">$&#123;数组名[下标]&#125;</span></code></pre><p>例如：</p><pre><code class="hljs ini"><span class="hljs-attr">valuen</span>=<span class="hljs-variable">$&#123;array_name[n]&#125;</span></code></pre><p>使用 <strong>@</strong> 符号可以获取数组中的所有元素，例如：</p><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-variable">$&#123;array_name[@]&#125;</span></code></pre><h3 id="获取数组的长度"><a href="#获取数组的长度" class="headerlink" title="获取数组的长度"></a>获取数组的长度</h3><p>获取数组长度的方法与获取字符串长度的方法相同，例如：</p><pre><code class="hljs bash"><span class="hljs-comment"># 取得数组元素的个数</span>length=<span class="hljs-variable">$&#123;#array_name[@]&#125;</span><span class="hljs-comment"># 或者</span>length=<span class="hljs-variable">$&#123;#array_name[*]&#125;</span><span class="hljs-comment"># 取得数组单个元素的长度</span>lengthn=<span class="hljs-variable">$&#123;#array_name[n]&#125;</span></code></pre><p>单行注释 #</p><p>多行注释</p><pre><code class="hljs bash">:&lt;&lt;EOF sssEOF</code></pre><p>EOF也可以换成别的符号</p><h1 id="Shell-传递参数"><a href="#Shell-传递参数" class="headerlink" title="Shell 传递参数"></a>Shell 传递参数</h1><p>我们可以在执行 Shell 脚本时，向脚本传递参数，脚本内获取参数的格式为：<strong>$n</strong>。<strong>n</strong> 代表一个数字，1 为执行脚本的第一个参数，2 为执行脚本的第二个参数，以此类推……</p><h3 id="实例-1"><a href="#实例-1" class="headerlink" title="实例"></a>实例</h3><p>以下实例我们向脚本传递三个参数，并分别输出，其中 <strong>$0</strong> 为执行的文件名（包含文件路径）：</p><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><span class="hljs-comment"># author:菜鸟教程</span><span class="hljs-comment"># url:www.runoob.com</span><span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;Shell 传递参数实例！&quot;</span>;<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;执行的文件名：<span class="hljs-variable">$0</span>&quot;</span>;<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;第一个参数为：<span class="hljs-variable">$1</span>&quot;</span>;<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;第二个参数为：<span class="hljs-variable">$2</span>&quot;</span>;<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;第三个参数为：<span class="hljs-variable">$3</span>&quot;</span>;</code></pre><p>为脚本设置可执行权限，并执行脚本，输出结果如下所示：</p><pre><code class="hljs sh">$ chmod +x test.sh $ ./test.sh 1 2 3Shell 传递参数实例！执行的文件名：./test.sh第一个参数为：1第二个参数为：2第三个参数为：3</code></pre><p>另外，还有几个特殊字符用来处理参数：</p><div class="table-container"><table><thead><tr><th style="text-align:left">参数处理</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">$#</td><td style="text-align:left">传递到脚本的参数个数</td></tr><tr><td style="text-align:left">$*</td><td style="text-align:left">以一个单字符串显示所有向脚本传递的参数。 如”$*”用「”」括起来的情况、以”$1 $2 … $n”的形式输出所有参数。</td></tr><tr><td style="text-align:left">$$</td><td style="text-align:left">脚本运行的当前进程ID号</td></tr><tr><td style="text-align:left">$!</td><td style="text-align:left">后台运行的最后一个进程的ID号</td></tr><tr><td style="text-align:left">$@</td><td style="text-align:left">与\$*相同，但是使用时加引号，并在引号中返回每个参数。 如”\$@”用「”」括起来的情况、以”\$1” “$2” … “$n” 的形式输出所有参数。</td></tr><tr><td style="text-align:left">$-</td><td style="text-align:left">显示Shell使用的当前选项，与<a href="https://www.runoob.com/linux/linux-comm-set.html">set命令</a>功能相同。</td></tr><tr><td style="text-align:left">$?</td><td style="text-align:left">显示最后命令的退出状态。0表示没有错误，其他任何值表明有错误。</td></tr></tbody></table></div><h1 id="Shell-基本运算符"><a href="#Shell-基本运算符" class="headerlink" title="Shell 基本运算符"></a>Shell 基本运算符</h1><p>Shell 和其他编程语言一样，支持多种运算符，包括：</p><ul><li>算数运算符</li><li>关系运算符</li><li>布尔运算符</li><li>字符串运算符</li><li>文件测试运算符</li></ul><p>原生bash不支持简单的数学运算，但是可以通过其他命令来实现，例如 awk 和 expr，expr 最常用。</p><p>expr 是一款表达式计算工具，使用它能完成表达式的求值操作。</p><p>例如，两个数相加(<strong>注意使用的是反引号 \</strong>`*<em> 而不是单引号 *<em>‘**</em></em>)：</p><h3 id="实例-2"><a href="#实例-2" class="headerlink" title="实例"></a>实例</h3><p><em>#!/bin/bash</em></p><p>val=<strong>`**</strong>expr<strong> 2 + 2</strong>`<strong></strong>echo** “两数之和为 : $val”</p><p>两点注意：</p><ul><li>表达式和运算符之间要有空格，例如 2+2 是不对的，必须写成 2 + 2，这与我们熟悉的大多数编程语言不一样。</li><li>完整的表达式要被 <strong><code> </code></strong> 包含，注意这个字符不是常用的单引号，在 Esc 键下边。</li></ul><h2 id="算术运算符"><a href="#算术运算符" class="headerlink" title="算术运算符"></a>算术运算符</h2><p>下表列出了常用的算术运算符，假定变量 a 为 10，变量 b 为 20：</p><div class="table-container"><table><thead><tr><th style="text-align:left">运算符</th><th style="text-align:left">说明</th><th style="text-align:left">举例</th></tr></thead><tbody><tr><td style="text-align:left">+</td><td style="text-align:left">加法</td><td style="text-align:left"><code>expr $a + $b</code> 结果为 30。</td></tr><tr><td style="text-align:left">-</td><td style="text-align:left">减法</td><td style="text-align:left"><code>expr $a - $b</code> 结果为 -10。</td></tr><tr><td style="text-align:left">*</td><td style="text-align:left">乘法</td><td style="text-align:left"><code>expr $a \* $b</code> 结果为  200。</td></tr><tr><td style="text-align:left">/</td><td style="text-align:left">除法</td><td style="text-align:left"><code>expr $b / $a</code> 结果为 2。</td></tr><tr><td style="text-align:left">%</td><td style="text-align:left">取余</td><td style="text-align:left"><code>expr $b % $a</code> 结果为 0。</td></tr><tr><td style="text-align:left">=</td><td style="text-align:left">赋值</td><td style="text-align:left">a=$b 将把变量 b 的值赋给 a。</td></tr><tr><td style="text-align:left">==</td><td style="text-align:left">相等。用于比较两个数字，相同则返回 true。</td><td style="text-align:left">[ $a == $b ] 返回 false。</td></tr><tr><td style="text-align:left">!=</td><td style="text-align:left">不相等。用于比较两个数字，不相同则返回 true。</td><td style="text-align:left">[ $a != $b ] 返回 true。</td></tr></tbody></table></div><p><strong>注意：</strong>条件表达式要放在方括号之间，并且要有空格，例如: <strong>[$a==$b]</strong> 是错误的，必须写成 <strong>[ $a == $b ]</strong>。</p><h2 id="关系运算符"><a href="#关系运算符" class="headerlink" title="关系运算符"></a>关系运算符</h2><p>关系运算符只支持数字，不支持字符串，除非字符串的值是数字。</p><p>下表列出了常用的关系运算符，假定变量 a 为 10，变量 b 为 20：</p><div class="table-container"><table><thead><tr><th style="text-align:left">运算符</th><th style="text-align:left">说明</th><th style="text-align:left">举例</th></tr></thead><tbody><tr><td style="text-align:left">-eq</td><td style="text-align:left">检测两个数是否相等，相等返回 true。</td><td style="text-align:left">[ $a -eq $b ] 返回 false。</td></tr><tr><td style="text-align:left">-ne</td><td style="text-align:left">检测两个数是否不相等，不相等返回 true。</td><td style="text-align:left">[ $a -ne $b ] 返回 true。</td></tr><tr><td style="text-align:left">-gt</td><td style="text-align:left">检测左边的数是否大于右边的，如果是，则返回 true。</td><td style="text-align:left">[ $a -gt $b ] 返回 false。</td></tr><tr><td style="text-align:left">-lt</td><td style="text-align:left">检测左边的数是否小于右边的，如果是，则返回 true。</td><td style="text-align:left">[ $a -lt $b ] 返回 true。</td></tr><tr><td style="text-align:left">-ge</td><td style="text-align:left">检测左边的数是否大于等于右边的，如果是，则返回 true。</td><td style="text-align:left">[ $a -ge $b ] 返回 false。</td></tr><tr><td style="text-align:left">-le</td><td style="text-align:left">检测左边的数是否小于等于右边的，如果是，则返回 true。</td><td style="text-align:left">[ $a -le $b ] 返回 true。</td></tr></tbody></table></div><h2 id="布尔运算符"><a href="#布尔运算符" class="headerlink" title="布尔运算符"></a>布尔运算符</h2><p>下表列出了常用的布尔运算符，假定变量 a 为 10，变量 b 为 20：</p><div class="table-container"><table><thead><tr><th style="text-align:left">运算符</th><th style="text-align:left">说明</th><th style="text-align:left">举例</th></tr></thead><tbody><tr><td style="text-align:left">!</td><td style="text-align:left">非运算，表达式为 true 则返回 false，否则返回 true。</td><td style="text-align:left">[ ! false ] 返回 true。</td></tr><tr><td style="text-align:left">-o</td><td style="text-align:left">或运算，有一个表达式为 true 则返回 true。</td><td style="text-align:left">[ \$a -lt  20 -o $b -gt 100 ] 返回 true。</td></tr><tr><td style="text-align:left">-a</td><td style="text-align:left">与运算，两个表达式都为 true 才返回 true。</td><td style="text-align:left">[ \$a -lt 20 -a $b -gt 100 ] 返回 false。</td></tr></tbody></table></div><h2 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h2><p>以下介绍 Shell 的逻辑运算符，假定变量 a 为 10，变量 b 为 20:</p><div class="table-container"><table><thead><tr><th style="text-align:left">运算符</th><th style="text-align:left">说明</th><th style="text-align:left">举例</th></tr></thead><tbody><tr><td style="text-align:left">&amp;&amp;</td><td style="text-align:left">逻辑的 AND</td><td style="text-align:left">[[\$a -lt 100 \&amp;\&amp; $b -gt 100 ]] 返回 false</td></tr><tr><td style="text-align:left">\</td><td style="text-align:left">\</td><td style="text-align:left"></td><td>逻辑的 OR</td><td>[[ \$a -lt 100 \</td><td>\</td><td>$b -gt 100 ]] 返回 true</td></tr></tbody></table></div><h2 id="字符串运算符"><a href="#字符串运算符" class="headerlink" title="字符串运算符"></a>字符串运算符</h2><p>下表列出了常用的字符串运算符，假定变量 a 为 “abc”，变量 b 为 “efg”：</p><div class="table-container"><table><thead><tr><th style="text-align:left">运算符</th><th style="text-align:left">说明</th><th style="text-align:left">举例</th></tr></thead><tbody><tr><td style="text-align:left">=</td><td style="text-align:left">检测两个字符串是否相等，相等返回 true。</td><td style="text-align:left">[ $a = $b ] 返回 false。</td></tr><tr><td style="text-align:left">!=</td><td style="text-align:left">检测两个字符串是否相等，不相等返回 true。</td><td style="text-align:left">[ $a != $b ] 返回 true。</td></tr><tr><td style="text-align:left">-z</td><td style="text-align:left">检测字符串长度是否为0，为0返回 true。</td><td style="text-align:left">[ -z $a ] 返回 false。</td></tr><tr><td style="text-align:left">-n</td><td style="text-align:left">检测字符串长度是否不为 0，不为 0 返回 true。</td><td style="text-align:left">[ -n “$a” ] 返回 true。</td></tr><tr><td style="text-align:left">$</td><td style="text-align:left">检测字符串是否为空，不为空返回 true。</td><td style="text-align:left">[ $a ] 返回 true。</td></tr></tbody></table></div><h2 id="文件测试运算符"><a href="#文件测试运算符" class="headerlink" title="文件测试运算符"></a>文件测试运算符</h2><p>文件测试运算符用于检测 Unix 文件的各种属性。</p><p>属性检测描述如下：</p><div class="table-container"><table><thead><tr><th style="text-align:left">操作符</th><th style="text-align:left">说明</th><th style="text-align:left">举例</th></tr></thead><tbody><tr><td style="text-align:left">-b file</td><td style="text-align:left">检测文件是否是块设备文件，如果是，则返回 true。</td><td style="text-align:left">[ -b $file ] 返回 false。</td></tr><tr><td style="text-align:left">-c file</td><td style="text-align:left">检测文件是否是字符设备文件，如果是，则返回 true。</td><td style="text-align:left">[ -c $file ] 返回 false。</td></tr><tr><td style="text-align:left">-d file</td><td style="text-align:left">检测文件是否是目录，如果是，则返回 true。</td><td style="text-align:left">[ -d $file ] 返回 false。</td></tr><tr><td style="text-align:left">-f file</td><td style="text-align:left">检测文件是否是普通文件（既不是目录，也不是设备文件），如果是，则返回 true。</td><td style="text-align:left">[ -f $file ] 返回 true。</td></tr><tr><td style="text-align:left">-g file</td><td style="text-align:left">检测文件是否设置了 SGID 位，如果是，则返回 true。</td><td style="text-align:left">[ -g $file ] 返回 false。</td></tr><tr><td style="text-align:left">-k file</td><td style="text-align:left">检测文件是否设置了粘着位(Sticky Bit)，如果是，则返回 true。</td><td style="text-align:left">[ -k $file ] 返回 false。</td></tr><tr><td style="text-align:left">-p file</td><td style="text-align:left">检测文件是否是有名管道，如果是，则返回 true。</td><td style="text-align:left">[ -p $file ] 返回 false。</td></tr><tr><td style="text-align:left">-u file</td><td style="text-align:left">检测文件是否设置了 SUID 位，如果是，则返回 true。</td><td style="text-align:left">[ -u $file ] 返回 false。</td></tr><tr><td style="text-align:left">-r file</td><td style="text-align:left">检测文件是否可读，如果是，则返回 true。</td><td style="text-align:left">[ -r $file ] 返回 true。</td></tr><tr><td style="text-align:left">-w file</td><td style="text-align:left">检测文件是否可写，如果是，则返回 true。</td><td style="text-align:left">[ -w $file ] 返回 true。</td></tr><tr><td style="text-align:left">-x file</td><td style="text-align:left">检测文件是否可执行，如果是，则返回 true。</td><td style="text-align:left">[ -x $file ] 返回 true。</td></tr><tr><td style="text-align:left">-s file</td><td style="text-align:left">检测文件是否为空（文件大小是否大于0），不为空返回 true。</td><td style="text-align:left">[ -s $file ] 返回 true。</td></tr><tr><td style="text-align:left">-e file</td><td style="text-align:left">检测文件（包括目录）是否存在，如果是，则返回 true。</td><td style="text-align:left">[ -e $file ] 返回 true。</td></tr></tbody></table></div><p>其他检查符：</p><ul><li><strong>-S</strong>: 判断某文件是否 socket。</li><li><strong>-L</strong>: 检测文件是否存在并且是一个符号链接。</li></ul><h1 id="Shell-流程控制"><a href="#Shell-流程控制" class="headerlink" title="Shell 流程控制"></a>Shell 流程控制</h1><p>和Java、PHP等语言不一样，sh的流程控制不可为空，如(以下为PHP流程控制写法)：</p><pre><code class="hljs php"><span class="hljs-meta">&lt;?php</span><span class="hljs-keyword">if</span> (<span class="hljs-keyword">isset</span>($_GET[<span class="hljs-string">&quot;q&quot;</span>])) &#123;    search(q);&#125;<span class="hljs-keyword">else</span> &#123;    <span class="hljs-comment">// 不做任何事情</span>&#125;</code></pre><p>在sh/bash里可不能这么写，如果else分支没有语句执行，就不要写这个else。</p><hr><h2 id="if-else"><a href="#if-else" class="headerlink" title="if else"></a>if else</h2><h3 id="if"><a href="#if" class="headerlink" title="if"></a>if</h3><p>if 语句语法格式：</p><pre><code class="hljs jboss-cli"><span class="hljs-keyword">if</span> conditionthen    <span class="hljs-keyword">command</span>1     <span class="hljs-keyword">command</span>2    <span class="hljs-string">...</span>    <span class="hljs-keyword">command</span>N fi</code></pre><p>写成一行（适用于终端命令提示符）：</p><pre><code class="hljs bash"><span class="hljs-keyword">if</span> [ $(ps -ef | grep -c <span class="hljs-string">&quot;ssh&quot;</span>) -gt 1 ]; <span class="hljs-keyword">then</span> <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;true&quot;</span>; <span class="hljs-keyword">fi</span></code></pre><p>末尾的fi就是if倒过来拼写，后面还会遇到类似的。</p><h3 id="if-else-1"><a href="#if-else-1" class="headerlink" title="if else"></a>if else</h3><p>if else 语法格式：</p><pre><code class="hljs jboss-cli"><span class="hljs-keyword">if</span> conditionthen    <span class="hljs-keyword">command</span>1     <span class="hljs-keyword">command</span>2    <span class="hljs-string">...</span>    <span class="hljs-keyword">command</span>Nelse    <span class="hljs-keyword">command</span>fi</code></pre><h3 id="if-else-if-else"><a href="#if-else-if-else" class="headerlink" title="if else-if else"></a>if else-if else</h3><p>if else-if else 语法格式：</p><pre><code class="hljs bash"><span class="hljs-keyword">if</span> condition1<span class="hljs-keyword">then</span>    command1<span class="hljs-keyword">elif</span> condition2 <span class="hljs-keyword">then</span>     command2<span class="hljs-keyword">else</span>    commandN<span class="hljs-keyword">fi</span></code></pre><h2 id="while-语句"><a href="#while-语句" class="headerlink" title="while 语句"></a>while 语句</h2><p>while循环用于不断执行一系列命令，也用于从输入文件中读取数据；命令通常为测试条件。其格式为：</p><pre><code class="hljs bash"><span class="hljs-keyword">while</span> condition<span class="hljs-keyword">do</span>    <span class="hljs-built_in">command</span><span class="hljs-keyword">done</span></code></pre><p>以下是一个基本的while循环，测试条件是：如果int小于等于5，那么条件返回真。int从0开始，每次循环处理时，int加1。运行上述脚本，返回数字1到5，然后终止。</p><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span>int=1<span class="hljs-keyword">while</span>(( <span class="hljs-variable">$int</span>&lt;=5 ))<span class="hljs-keyword">do</span>    <span class="hljs-built_in">echo</span> <span class="hljs-variable">$int</span>    <span class="hljs-built_in">let</span> <span class="hljs-string">&quot;int++&quot;</span><span class="hljs-keyword">done</span></code></pre><p>运行脚本，输出：</p><pre><code class="hljs angelscript"><span class="hljs-number">1</span><span class="hljs-number">2</span><span class="hljs-number">3</span><span class="hljs-number">4</span><span class="hljs-number">5</span></code></pre><p>以上实例使用了 Bash let 命令，它用于执行一个或多个表达式，变量计算中不需要加上 $ 来表示变量，具体可查阅：<a href="https://www.runoob.com/linux/linux-comm-let.html">Bash let 命令</a></p><p>。</p><p>while循环可用于读取键盘信息。下面的例子中，输入信息被设置为变量FILM，按<Ctrl-D>结束循环。</p><pre><code class="hljs bash"><span class="hljs-built_in">echo</span> <span class="hljs-string">&#x27;按下 &lt;CTRL-D&gt; 退出&#x27;</span><span class="hljs-built_in">echo</span> -n <span class="hljs-string">&#x27;输入你最喜欢的网站名: &#x27;</span><span class="hljs-keyword">while</span> <span class="hljs-built_in">read</span> FILM<span class="hljs-keyword">do</span>    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;是的！<span class="hljs-variable">$FILM</span> 是一个好网站&quot;</span><span class="hljs-keyword">done</span></code></pre><h2 id="until-循环"><a href="#until-循环" class="headerlink" title="until 循环"></a>until 循环</h2><p>until 循环执行一系列命令直至条件为 true 时停止。</p><p>until 循环与 while 循环在处理方式上刚好相反。</p><p>一般 while 循环优于 until 循环，但在某些时候—也只是极少数情况下，until 循环更加有用。</p><p>until 语法格式:</p><pre><code class="hljs livecodeserver"><span class="hljs-keyword">until</span> condition<span class="hljs-built_in">do</span>    <span class="hljs-keyword">command</span>done</code></pre><p>condition 一般为条件表达式，如果返回值为 false，则继续执行循环体内的语句，否则跳出循环。</p><p>以下实例我们使用 until 命令来输出 0 ~ 9 的数字：</p><h1 id="Shell-函数"><a href="#Shell-函数" class="headerlink" title="Shell 函数"></a>Shell 函数</h1><p>linux shell 可以用户定义函数，然后在shell脚本中可以随便调用。</p><p>shell中函数的定义格式如下：</p><pre><code class="hljs ada">[ <span class="hljs-keyword">function</span> <span class="hljs-title">]</span> funname [()]&#123;    action;    [<span class="hljs-keyword">return</span> <span class="hljs-type">int</span>;]&#125;</code></pre><p>说明：</p><ul><li>1、可以带function fun() 定义，也可以直接fun() 定义,不带任何参数。</li><li>2、参数返回，可以显示加：return 返回，如果不加，将以最后一条命令运行结果，作为返回值。 return后跟数值n(0-255</li></ul><p>下面的例子定义了一个函数并进行调用：</p><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><span class="hljs-comment"># author:菜鸟教程</span><span class="hljs-comment"># url:www.runoob.com</span><span class="hljs-function"><span class="hljs-title">demoFun</span></span>()&#123;    <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;这是我的第一个 shell 函数!&quot;</span>&#125;<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;-----函数开始执行-----&quot;</span>demoFun<span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;-----函数执行完毕-----&quot;</span></code></pre><h1 id="Shell-输入-输出重定向"><a href="#Shell-输入-输出重定向" class="headerlink" title="Shell 输入/输出重定向"></a>Shell 输入/输出重定向</h1><p>大多数 UNIX 系统命令从你的终端接受输入并将所产生的输出发送回到您的终端。一个命令通常从一个叫标准输入的地方读取输入，默认情况下，这恰好是你的终端。同样，一个命令通常将其输出写入到标准输出，默认情况下，这也是你的终端。</p><p>重定向命令列表如下：</p><div class="table-container"><table><thead><tr><th style="text-align:left">命令</th><th style="text-align:left">说明</th></tr></thead><tbody><tr><td style="text-align:left">command &gt; file</td><td style="text-align:left">将输出重定向到 file。</td></tr><tr><td style="text-align:left">command &lt; file</td><td style="text-align:left">将输入重定向到 file。</td></tr><tr><td style="text-align:left">command &gt;&gt; file</td><td style="text-align:left">将输出以追加的方式重定向到 file。</td></tr><tr><td style="text-align:left">n &gt; file</td><td style="text-align:left">将文件描述符为 n 的文件重定向到 file。</td></tr><tr><td style="text-align:left">n &gt;&gt; file</td><td style="text-align:left">将文件描述符为 n 的文件以追加的方式重定向到 file。</td></tr><tr><td style="text-align:left">n &gt;&amp; m</td><td style="text-align:left">将输出文件 m 和 n 合并。</td></tr><tr><td style="text-align:left">n &lt;&amp; m</td><td style="text-align:left">将输入文件 m 和 n 合并。</td></tr><tr><td style="text-align:left">&lt;&lt; tag</td><td style="text-align:left">将开始标记 tag 和结束标记 tag 之间的内容作为输入。</td></tr></tbody></table></div><blockquote><p>需要注意的是文件描述符 0 通常是标准输入（STDIN），1 是标准输出（STDOUT），2 是标准错误输出（STDERR）。</p></blockquote><h2 id="输入重定向"><a href="#输入重定向" class="headerlink" title="输入重定向"></a>输入重定向</h2><p>和输出重定向一样，Unix 命令也可以从文件获取输入，语法为：</p><pre><code class="hljs apache"><span class="hljs-attribute">command1</span> &lt; file<span class="hljs-number">1</span></code></pre><p>这样，本来需要从键盘获取输入的命令会转移到文件读取内容。</p><p>注意：输出重定向是大于号(&gt;)，输入重定向是小于号(&lt;)。</p><h3 id="实例-3"><a href="#实例-3" class="headerlink" title="实例"></a>实例</h3><p>接着以上实例，我们需要统计 users 文件的行数,执行以下命令：</p><pre><code class="hljs routeros">$ wc -l users       2 users</code></pre><p>也可以将输入重定向到 users 文件：</p><pre><code class="hljs routeros">$  wc -l &lt; users       2</code></pre><p>注意：上面两个例子的结果不同：第一个例子，会输出文件名；第二个不会，因为它仅仅知道从标准输入读取内容。</p><pre><code class="hljs stata">command1 &lt; <span class="hljs-keyword">infile</span> &gt; <span class="hljs-keyword">outfile</span></code></pre><p>同时替换输入和输出，执行command1，从文件infile读取内容，然后将输出写入到outfile中。</p><h3 id="重定向深入讲解"><a href="#重定向深入讲解" class="headerlink" title="重定向深入讲解"></a>重定向深入讲解</h3><p>一般情况下，每个 Unix/Linux 命令运行时都会打开三个文件：</p><ul><li>标准输入文件(stdin)：stdin的文件描述符为0，Unix程序默认从stdin读取数据。</li><li>标准输出文件(stdout)：stdout 的文件描述符为1，Unix程序默认向stdout输出数据。</li><li>标准错误文件(stderr)：stderr的文件描述符为2，Unix程序会向stderr流中写入错误信息。</li></ul><p>默认情况下，command &gt; file 将 stdout 重定向到 file，command &lt; file 将stdin 重定向到 file。</p><p>如果希望 stderr 重定向到 file，可以这样写：</p><pre><code class="hljs cmake">$ <span class="hljs-keyword">command</span> <span class="hljs-number">2</span> &gt; <span class="hljs-keyword">file</span></code></pre><p>如果希望 stderr 追加到 file 文件末尾，可以这样写：</p><pre><code class="hljs cmake">$ <span class="hljs-keyword">command</span> <span class="hljs-number">2</span> &gt;&gt; <span class="hljs-keyword">file</span></code></pre><p><strong>2</strong> 表示标准错误文件(stderr)。</p><p>如果希望将 stdout 和 stderr 合并后重定向到 file，可以这样写：</p><pre><code class="hljs angelscript">$ command &gt; file <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span>或者$ command &gt;&gt; file <span class="hljs-number">2</span>&gt;&amp;<span class="hljs-number">1</span></code></pre><p>如果希望对 stdin 和 stdout 都重定向，可以这样写：</p><pre><code class="hljs livecodeserver">$ <span class="hljs-keyword">command</span> &lt; <span class="hljs-title">file1</span> &gt;<span class="hljs-title">file2</span></code></pre><p>command 命令将 stdin 重定向到 file1，将 stdout 重定向到 file2。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Shell-从入门到放弃&quot;&gt;&lt;a href=&quot;#Shell-从入门到放弃&quot; class=&quot;headerlink&quot; title=&quot;Shell 从入门到放弃&quot;&gt;&lt;/a&gt;Shell 从入门到放弃&lt;/h1&gt;&lt;blockquote&gt;
&lt;p&gt;Shell 是一个用 C 语言编写</summary>
      
    
    
    
    <category term="shell" scheme="http://durantthorvalds.top/categories/shell/"/>
    
    <category term="CLI" scheme="http://durantthorvalds.top/categories/shell/CLI/"/>
    
    
    <category term="shell" scheme="http://durantthorvalds.top/tags/shell/"/>
    
  </entry>
  
</feed>
